{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5c3fb815",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import glob\n",
    "import torch\n",
    "import clip\n",
    "from tqdm import tqdm\n",
    "from clip import tokenize\n",
    "from clip_utils import build_zero_shot_classifier\n",
    "from imagenet_metadata import IMAGENET_CLASSNAMES, OPENAI_IMAGENET_TEMPLATES\n",
    "\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from torchvision.transforms import Resize\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from generate_emap import clipmodel, preprocess, imgprocess_keepsize, mm_clipmodel, mm_interpret, \\\n",
    "    clip_encode_dense, grad_eclip, grad_cam, mask_clip, compute_rollout_attention, surgery_model, clip_surgery_map, \\\n",
    "    m2ib_model, m2ib_clip_map\n",
    "import Game_MM_CLIP.clip as mm_clip\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "29e30353",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(output, target, topk=(1,)):\n",
    "    pred = output.topk(max(topk), 1, True, True)[1].t()\n",
    "    # print(\"pred:\", pred.shape) # [5, 10] \n",
    "    correct = pred.eq(target.view(1, -1).expand_as(pred))\n",
    "    acc = [correct[:k,:].float().sum(0).cpu() for k in topk]\n",
    "    pred_top1 = pred[0,:]\n",
    "    return acc, pred_top1\n",
    "\n",
    "def make_grids(h, w):\n",
    "    shifts_x = torch.arange(\n",
    "        0, w, 1)\n",
    "    shifts_y = torch.arange(\n",
    "        0, h, 1)\n",
    "    shift_y, shift_x = torch.meshgrid(shifts_y, shifts_x, indexing='ij')\n",
    "    shift_x = shift_x.reshape(-1)\n",
    "    shift_y = shift_y.reshape(-1)\n",
    "    grids = torch.stack((shift_x, shift_y), dim=1)\n",
    "    return grids\n",
    "\n",
    "def add_pixel(image, input_img, poses):\n",
    "    xs, ys = zip(*poses)\n",
    "    input_img[ys, xs,:] = image[ys, xs, :]\n",
    "    return input_img\n",
    "\n",
    "\n",
    "def insertion_process(image, heatmap, L, cal_gap, ins_path, img_name):\n",
    "    image_array = np.array(image).copy()\n",
    "    h, w = heatmap.shape\n",
    "    grids = make_grids(h, w)\n",
    "    order = np.argsort(-heatmap.reshape(-1))\n",
    "    area = h*w\n",
    "    pixel_once = max(1, int(area/(2*L)))\n",
    "    input_img = np.zeros(image_array.shape)\n",
    "\n",
    "    insert_imgs = []\n",
    "    for step in range(1,L+1):\n",
    "        input_img = add_pixel(image_array, input_img, grids[order[(step-1)*pixel_once:step*pixel_once]])\n",
    "        if step%cal_gap == 0:\n",
    "            pil_image = Image.fromarray(np.uint8(input_img))\n",
    "            img_clipreprocess = preprocess(pil_image).to(device).unsqueeze(0)\n",
    "            insert_imgs.append(img_clipreprocess)\n",
    "            # pil_image.save(ins_path+'/{}_{}.jpg'.format(img_name, step))\n",
    "    return torch.cat(insert_imgs, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e94e3562",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def generate_hm(hm_type, img, gt, pred, resize):\n",
    "    img_keepsized = imgprocess_keepsize(img).to(device).unsqueeze(0)\n",
    "    outputs, v_final, last_input, v, q_out, k_out,\\\n",
    "        attn, att_output, map_size = clip_encode_dense(img_keepsized)\n",
    "    img_embedding = F.normalize(outputs[:,0], dim=-1)\n",
    "    if \"gt\" in hm_type:\n",
    "        exp_target = gt\n",
    "        txt_embedding = zero_shot_weights[:, gt]\n",
    "        cosine = (img_embedding @ txt_embedding)[0]\n",
    "    elif \"pred\" in hm_type:\n",
    "        exp_target = pred\n",
    "        txt_embedding = zero_shot_weights[:, pred]\n",
    "        cosine = (img_embedding @ txt_embedding)[0]\n",
    "    else:\n",
    "        None\n",
    "\n",
    "    if hm_type == \"selfattn\":\n",
    "        emap = attn[0,:1,1:].detach().reshape(*map_size)\n",
    "    elif \"gradcam\" in hm_type:\n",
    "        emap = grad_cam(cosine, last_input, map_size)\n",
    "    elif \"maskclip\" in hm_type:\n",
    "        emap = mask_clip(txt_embedding.unsqueeze(-1), v_final, k_out, map_size)[0]\n",
    "    elif \"eclip\" in hm_type:\n",
    "        emap = grad_eclip(cosine, q_out, k_out, v, att_output, map_size, withksim=False) \\\n",
    "            if \"wo-ksim\" in hm_type else grad_eclip(cosine, q_out, k_out, v, att_output, map_size, withksim=True)\n",
    "    elif \"game\" in hm_type:\n",
    "        img_clipreprocess = preprocess(img).to(device).unsqueeze(0)\n",
    "        text_tokenized = mm_clip.tokenize(IMAGENET_CLASSNAMES[exp_target]).to(device)\n",
    "        emap = mm_interpret(model=mm_clipmodel, image=img_clipreprocess, texts=text_tokenized, device=device)       \n",
    "    elif \"rollout\" in hm_type:\n",
    "        img_clipreprocess = preprocess(img).to(device).unsqueeze(0)\n",
    "        text_tokenized = mm_clip.tokenize(IMAGENET_CLASSNAMES[exp_target]).to(device)   \n",
    "        attentions = mm_interpret(model=mm_clipmodel, image=img_clipreprocess, texts=text_tokenized, device=device, rollout=True)      \n",
    "        emap = compute_rollout_attention(attentions)[0]\n",
    "    elif \"surgery\" in hm_type:\n",
    "        img_clipreprocess = preprocess(img).to(device).unsqueeze(0)\n",
    "        all_texts = ['airplane', 'bag', 'bed', 'bedclothes', 'bench', 'bicycle', 'bird', 'boat', 'book', 'bottle', 'building', 'bus', 'cabinet', 'car', 'cat', 'ceiling', 'chair', 'cloth', 'computer', 'cow', 'cup', 'curtain', 'dog', 'door', 'fence', 'floor', 'flower', 'food', 'grass', 'ground', 'horse', 'keyboard', 'light', 'motorbike', 'mountain', 'mouse', 'person', 'plate', 'platform', 'potted plant', 'road', 'rock', 'sheep', 'shelves', 'sidewalk', 'sign', 'sky', 'snow', 'sofa', 'table', 'track', 'train', 'tree', 'truck', 'tv monitor', 'wall', 'water', 'window', 'wood']\n",
    "        all_texts.insert(0, IMAGENET_CLASSNAMES[exp_target])\n",
    "        emap = clip_surgery_map(model=surgery_model, image=img_clipreprocess, texts=all_texts, device=device)[0,:,:,0]\n",
    "    elif \"m2ib\" in hm_type:\n",
    "        img_clipreprocess = preprocess(img).to(device).unsqueeze(0)\n",
    "        emap = m2ib_clip_map(model=m2ib_model, image=img_clipreprocess, texts=IMAGENET_CLASSNAMES[exp_target], device=device)\n",
    "        emap = torch.tensor(emap)\n",
    "\n",
    "\n",
    "    emap -= emap.min()\n",
    "    emap /= emap.max()\n",
    "    emap = resize(emap.unsqueeze(0))[0].cpu().numpy()\n",
    "    return emap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f09da12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hm type: eclip_gt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:20<00:00, 48.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[class name embeddings]: torch.Size([512, 1000])\n",
      "Start: Processing the 0th folder, target class name: tench\n",
      "[clip accuracy] Top1:\n",
      "[eclip_gt]: [np.float32(0.24), np.float32(0.4), np.float32(0.66), np.float32(0.86), np.float32(0.9), np.float32(0.88), np.float32(0.9), np.float32(0.9), np.float32(0.92), np.float32(0.96), np.float32(0.98)]\n",
      "[clip accuracy] Top5:\n",
      "[eclip_gt]: [np.float32(0.44), np.float32(0.66), np.float32(0.88), np.float32(0.94), np.float32(0.98), np.float32(0.96), np.float32(1.0), np.float32(1.0), np.float32(1.0), np.float32(1.0), np.float32(1.0)]\n",
      "[clip accuracy] Top10:\n",
      "[eclip_gt]: [np.float32(0.62), np.float32(0.76), np.float32(0.94), np.float32(0.98), np.float32(0.98), np.float32(0.98), np.float32(1.0), np.float32(1.0), np.float32(1.0), np.float32(1.0), np.float32(1.0)]\n",
      "Start: Processing the 1th folder, target class name: goldfish\n",
      "[clip accuracy] Top1:\n",
      "[eclip_gt]: [np.float32(0.3), np.float32(0.46), np.float32(0.6), np.float32(0.77), np.float32(0.8), np.float32(0.83), np.float32(0.84), np.float32(0.9), np.float32(0.89), np.float32(0.92), np.float32(0.96)]\n",
      "[clip accuracy] Top5:\n",
      "[eclip_gt]: [np.float32(0.59), np.float32(0.67), np.float32(0.84), np.float32(0.9), np.float32(0.94), np.float32(0.94), np.float32(0.98), np.float32(0.98), np.float32(0.98), np.float32(1.0), np.float32(1.0)]\n",
      "[clip accuracy] Top10:\n",
      "[eclip_gt]: [np.float32(0.75), np.float32(0.8), np.float32(0.9), np.float32(0.92), np.float32(0.94), np.float32(0.98), np.float32(0.99), np.float32(1.0), np.float32(1.0), np.float32(1.0), np.float32(1.0)]\n",
      "top1 hits: tensor([30., 46., 60., 77., 80., 83., 84., 90., 89., 92., 96.])\n",
      "top5 hits: tensor([ 59.,  67.,  84.,  90.,  94.,  94.,  98.,  98.,  98., 100., 100.])\n",
      "top10 hits: tensor([ 75.,  80.,  90.,  92.,  94.,  98.,  99., 100., 100., 100., 100.])\n",
      "n: tensor([100., 100., 100., 100., 100., 100., 100., 100., 100., 100., 100.])\n",
      "[clip accuracy] Top1:\n",
      "[eclip_gt]: [np.float32(0.3), np.float32(0.46), np.float32(0.6), np.float32(0.77), np.float32(0.8), np.float32(0.83), np.float32(0.84), np.float32(0.9), np.float32(0.89), np.float32(0.92), np.float32(0.96)]\n",
      "[clip accuracy] Top5:\n",
      "[eclip_gt]: [np.float32(0.59), np.float32(0.67), np.float32(0.84), np.float32(0.9), np.float32(0.94), np.float32(0.94), np.float32(0.98), np.float32(0.98), np.float32(0.98), np.float32(1.0), np.float32(1.0)]\n",
      "[clip accuracy] Top10:\n",
      "[eclip_gt]: [np.float32(0.75), np.float32(0.8), np.float32(0.9), np.float32(0.92), np.float32(0.94), np.float32(0.98), np.float32(0.99), np.float32(1.0), np.float32(1.0), np.float32(1.0), np.float32(1.0)]\n"
     ]
    }
   ],
   "source": [
    "data_path = \"/home/infres/pmbathe-24/Projet-IA-Fairness/Grad-Eclip-main/data/val/\"\n",
    "ins_path = '/home/infres/pmbathe-24/Projet-IA-Fairness/Grad-Eclip-main/data/ins_samples/'  ### for debug, saving insertion samples\n",
    "\n",
    "# hm_types = ['eclip-wo-ksim_gt', 'eclip-wo-ksim_pred', 'eclip_gt', 'eclip_pred', 'game_gt', 'game_pred',\n",
    "#         'gradcam_gt', 'gradcam_pred', 'maskclip_gt', 'maskclip_pred', 'selfattn', 'surgery_gt', 'surgery_pred', 'm2ib_gt', 'm2ib_pred']\n",
    "\n",
    "hm_type = 'eclip_gt'\n",
    "print(\"hm type:\", hm_type)\n",
    "\n",
    "zero_shot_weights = build_zero_shot_classifier(\n",
    "    clipmodel,\n",
    "    classnames=IMAGENET_CLASSNAMES,\n",
    "    templates=OPENAI_IMAGENET_TEMPLATES,\n",
    "    num_classes_per_batch=10,\n",
    "    device=device,\n",
    "    use_tqdm=True\n",
    "    )\n",
    "print(\"[class name embeddings]:\", zero_shot_weights.shape)  # [512, 1000]\n",
    "\n",
    "\n",
    "top1 = torch.zeros([11])\n",
    "top5 = torch.zeros([11])\n",
    "top10 = torch.zeros([11])\n",
    "n = torch.zeros([11])\n",
    "\n",
    "L = 100\n",
    "cal_gap = 10\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Define all heatmap types to evaluate\n",
    "hm_types = ['eclip', 'gradcam', 'maskclip', 'eclip', 'game', 'rollout', 'clipsurgery']\n",
    "\n",
    "extention =[\"gt\",\"pred\"]\n",
    "\n",
    "# Method name mapping for display\n",
    "method_names = {\n",
    "    'raw_attention': 'Raw Attention',\n",
    "    'gradcam': 'Grad-CAM', \n",
    "    'maskclip': 'MaskCLIP',\n",
    "    'eclip': 'ECLIP',\n",
    "    'game': 'GAME',\n",
    "    'rollout': 'Rollout',\n",
    "    'clipsurgery': 'CLIPSurgery'\n",
    "}\n",
    "\n",
    "\n",
    "# Storage for results\n",
    "all_results = {}\n",
    "insertion_curves = {}\n",
    "\n",
    "\n",
    "for ex in extention: \n",
    "    for hm_type_old in hm_types:\n",
    "        hm_type = f\"{hm_type_old}_{ex}\"\n",
    "        print(f\"Evaluating {method_names[hm_type]}...\")\n",
    "        \n",
    "        # Initialize storage for this method\n",
    "        gt_top1_scores = []\n",
    "        gt_top5_scores = []\n",
    "        pred_top1_scores = []\n",
    "        pred_top5_scores = []\n",
    "        \n",
    "        # Storage for insertion curves\n",
    "        insertion_steps = list(range(0, L + 1, cal_gap))\n",
    "        gt_top1_curve = []\n",
    "        gt_top5_curve = []\n",
    "        pred_top1_curve = []\n",
    "        pred_top5_curve = []\n",
    "\n",
    "\n",
    "\n",
    "        with open(\"imagenet_class_index.json\", \"r\") as ff:\n",
    "            class_dict = json.load(ff)\n",
    "            for label, values in list(class_dict.items())[0:2]:  # only process the first 100 classes\n",
    "                label = int(label)\n",
    "                folder = values[0]\n",
    "                # files = os.listdir(data_path+folder)\n",
    "                print(\"Start: Processing the {}th folder, target class name: {}\".format(label, IMAGENET_CLASSNAMES[label]))\n",
    "\n",
    "                # if not os.path.exists(ins_path+folder):\n",
    "                #     os.makedirs(ins_path+folder)\n",
    "\n",
    "                files = os.listdir(data_path+folder)\n",
    "\n",
    "                for f in files:\n",
    "                    img_name = f.split(\".\")[0]\n",
    "                    img = Image.open(os.path.join(data_path, folder, f )).convert(\"RGB\")\n",
    "                    w, h = img.size\n",
    "                    # in case there is too large image\n",
    "                    if min(w,h) > 640:\n",
    "                        scale = min(w,h) / 640\n",
    "                        hs = int(h/scale)\n",
    "                        ws = int(w/scale)\n",
    "                        # print(img_name, w, h, ws, hs)\n",
    "                        img = img.resize((ws,hs))\n",
    "                    w, h = img.size\n",
    "                    resize = Resize((h,w))\n",
    "                    # make prediction\n",
    "                    with torch.no_grad():\n",
    "                        img_clipreprocess = preprocess(img).to(device).unsqueeze(0)\n",
    "                        img_clip_embedding = clipmodel.encode_image(img_clipreprocess)\n",
    "                        logits = 100. * img_clip_embedding @ zero_shot_weights\n",
    "                        target = torch.tensor([label]).to(device)\n",
    "                        [acc1, acc5, acc10], pred_top1 = accuracy(logits, target, topk=(1, 5, 10))\n",
    "                        top1[-1:] += acc1\n",
    "                        top5[-1:] += acc5\n",
    "                        top10[-1:] += acc10\n",
    "                        n[0] += 1\n",
    "\n",
    "                    hm = generate_hm(hm_type, img.copy(), label, pred_top1.item(), resize)\n",
    "                    ins_imgs = insertion_process(img, hm, L, cal_gap, ins_path+folder, '{}_{}'.format(img_name, hm_type)) # 10 deletion steps\n",
    "                    # 10, 3, 224, 224\n",
    "                    img_clip_embedding = clipmodel.encode_image(ins_imgs)\n",
    "                    logits = 100. * img_clip_embedding @ zero_shot_weights\n",
    "                    target = torch.tensor([label]).repeat(len(img_clip_embedding)).to(device)\n",
    "                    [acc1, acc5, acc10], _ = accuracy(logits, target, topk=(1, 5, 10))\n",
    "                    top1[:-1] += acc1\n",
    "                    top5[:-1] += acc5\n",
    "                    top10[:-1] += acc10\n",
    "                    n[1:] += 1\n",
    "\n",
    "                print(\"[clip accuracy] Top1:\")\n",
    "                print(\"[{}]:\".format(hm_type), list((top1 / n).numpy()))\n",
    "\n",
    "                print(\"[clip accuracy] Top5:\")\n",
    "                print(\"[{}]:\".format(hm_type), list((top5 / n).numpy()))  \n",
    "\n",
    "                print(\"[clip accuracy] Top10:\")\n",
    "                print(\"[{}]:\".format(hm_type), list((top10 / n).numpy()))       \n",
    "\n",
    "        print(\"top1 hits:\", top1)\n",
    "        print(\"top5 hits:\", top5)\n",
    "        print(\"top10 hits:\", top10)\n",
    "        print(\"n:\", n)\n",
    "        top1 = top1 / n\n",
    "        top5 = top5 / n\n",
    "        top10 = top10 / n\n",
    "        \n",
    "        \n",
    "        insertion_curves[hm_type] = {\n",
    "            'steps': insertion_steps,\n",
    "            'gt_top1': top1,\n",
    "            'gt_top5': top5,\n",
    "            'pred_top1': top1,\n",
    "            'pred_top5': top5\n",
    "        }\n",
    "\n",
    "        print(\"[clip accuracy] Top1:\")\n",
    "        print(\"[{}]:\".format(hm_type), list(top1.numpy()))\n",
    "\n",
    "        print(\"[clip accuracy] Top5:\")\n",
    "        print(\"[{}]:\".format(hm_type), list(top5.numpy()))  \n",
    "\n",
    "        print(\"[clip accuracy] Top10:\")\n",
    "        print(\"[{}]:\".format(hm_type), list(top10.numpy())) \n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c41d8eb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "\n",
    "\n",
    "# Storage for results\n",
    "all_results = {}\n",
    "insertion_curves = {}\n",
    "\n",
    "# Parameters\n",
    "cal_gap = 10  # Calculate accuracy every 10 steps\n",
    "max_steps = 100\n",
    "\n",
    "# ...existing code...\n",
    "\n",
    "# Main evaluation loop\n",
    "for hm_type in hm_types:\n",
    "    print(f\"Evaluating {method_names[hm_type]}...\")\n",
    "    \n",
    "    # Initialize storage for this method\n",
    "    gt_top1_scores = []\n",
    "    gt_top5_scores = []\n",
    "    pred_top1_scores = []\n",
    "    pred_top5_scores = []\n",
    "    \n",
    "    # Storage for insertion curves\n",
    "    insertion_steps = list(range(0, max_steps + 1, cal_gap))\n",
    "    gt_top1_curve = []\n",
    "    gt_top5_curve = []\n",
    "    pred_top1_curve = []\n",
    "    pred_top5_curve = []\n",
    "    \n",
    "    # ...existing evaluation code for each sample...\n",
    "    # This should include your existing loop over the dataset\n",
    "    \n",
    "    for step in insertion_steps:\n",
    "        # Calculate accuracy at this insertion step\n",
    "        # ...existing insertion evaluation code...\n",
    "        \n",
    "        # Store intermediate results for curves\n",
    "        gt_top1_curve.append(current_gt_top1_acc)\n",
    "        gt_top5_curve.append(current_gt_top5_acc)\n",
    "        pred_top1_curve.append(current_pred_top1_acc)\n",
    "        pred_top5_curve.append(current_pred_top5_acc)\n",
    "    \n",
    "    # Store final results\n",
    "    all_results[hm_type] = {\n",
    "        'gt_top1': final_gt_top1_acc,\n",
    "        'gt_top5': final_gt_top5_acc,\n",
    "        'pred_top1': final_pred_top1_acc,\n",
    "        'pred_top5': final_pred_top5_acc\n",
    "    }\n",
    "    \n",
    "    # Store insertion curves\n",
    "    insertion_curves[hm_type] = {\n",
    "        'steps': insertion_steps,\n",
    "        'gt_top1': gt_top1_curve,\n",
    "        'gt_top5': gt_top5_curve,\n",
    "        'pred_top1': pred_top1_curve,\n",
    "        'pred_top5': pred_top5_curve\n",
    "    }\n",
    "\n",
    "# Create results table\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"INSERTION EVALUATION RESULTS\")\n",
    "print(\"=\"*60)\n",
    "print(f\"{'Method':<15} {'Ground-truth':<20} {'Prediction':<20}\")\n",
    "print(f\"{'':15} {'@1':<10} {'@5':<10} {'@1':<10} {'@5':<10}\")\n",
    "print(\"-\"*60)\n",
    "\n",
    "for hm_type in hm_types:\n",
    "    method_name = method_names[hm_type]\n",
    "    results = all_results[hm_type]\n",
    "    print(f\"{method_name:<15} {results['gt_top1']:<10.4f} {results['gt_top5']:<10.4f} \"\n",
    "          f\"{results['pred_top1']:<10.4f} {results['pred_top5']:<10.4f}\")\n",
    "\n",
    "# Save results to CSV\n",
    "results_df = pd.DataFrame({\n",
    "    'Method': [method_names[hm_type] for hm_type in hm_types],\n",
    "    'GT_Top1': [all_results[hm_type]['gt_top1'] for hm_type in hm_types],\n",
    "    'GT_Top5': [all_results[hm_type]['gt_top5'] for hm_type in hm_types],\n",
    "    'Pred_Top1': [all_results[hm_type]['pred_top1'] for hm_type in hm_types],\n",
    "    'Pred_Top5': [all_results[hm_type]['pred_top5'] for hm_type in hm_types]\n",
    "})\n",
    "\n",
    "results_df.to_csv('insertion_evaluation_results.csv', index=False)\n",
    "print(f\"\\nResults saved to insertion_evaluation_results.csv\")\n",
    "\n",
    "# Plot insertion curves\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(15, 10))\n",
    "\n",
    "# Ground-truth Top-1\n",
    "for hm_type in hm_types:\n",
    "    curve_data = insertion_curves[hm_type]\n",
    "    ax1.plot(curve_data['steps'], curve_data['gt_top1'], \n",
    "             label=method_names[hm_type], marker='o', markersize=4)\n",
    "ax1.set_title('Ground-truth Top-1 Insertion')\n",
    "ax1.set_xlabel('Insertion Step')\n",
    "ax1.set_ylabel('Accuracy')\n",
    "ax1.legend()\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# Ground-truth Top-5\n",
    "for hm_type in hm_types:\n",
    "    curve_data = insertion_curves[hm_type]\n",
    "    ax2.plot(curve_data['steps'], curve_data['gt_top5'], \n",
    "             label=method_names[hm_type], marker='o', markersize=4)\n",
    "ax2.set_title('Ground-truth Top-5 Insertion')\n",
    "ax2.set_xlabel('Insertion Step')\n",
    "ax2.set_ylabel('Accuracy')\n",
    "ax2.legend()\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "# Prediction Top-1\n",
    "for hm_type in hm_types:\n",
    "    curve_data = insertion_curves[hm_type]\n",
    "    ax3.plot(curve_data['steps'], curve_data['pred_top1'], \n",
    "             label=method_names[hm_type], marker='o', markersize=4)\n",
    "ax3.set_title('Prediction Top-1 Insertion')\n",
    "ax3.set_xlabel('Insertion Step')\n",
    "ax3.set_ylabel('Accuracy')\n",
    "ax3.legend()\n",
    "ax3.grid(True, alpha=0.3)\n",
    "\n",
    "# Prediction Top-5\n",
    "for hm_type in hm_types:\n",
    "    curve_data = insertion_curves[hm_type]\n",
    "    ax4.plot(curve_data['steps'], curve_data['pred_top5'], \n",
    "             label=method_names[hm_type], marker='o', markersize=4)\n",
    "ax4.set_title('Prediction Top-5 Insertion')\n",
    "ax4.set_xlabel('Insertion Step')\n",
    "ax4.set_ylabel('Accuracy')\n",
    "ax4.legend()\n",
    "ax4.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('insertion_curves_comparison.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nInsertion curves saved to insertion_curves_comparison.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "039d073b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:20<00:00, 49.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[class name embeddings]: torch.Size([512, 1000])\n",
      "Evaluating eclip_gt...\n",
      "Start: Processing the 0th folder, target class name: tench\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "data_path = \"/home/infres/pmbathe-24/Projet-IA-Fairness/Grad-Eclip-main/data/val/\"\n",
    "ins_path = '/home/infres/pmbathe-24/Projet-IA-Fairness/Grad-Eclip-main/data/ins_samples/'  ### for debug, saving insertion samples\n",
    "\n",
    "zero_shot_weights = build_zero_shot_classifier(\n",
    "    clipmodel,\n",
    "    classnames=IMAGENET_CLASSNAMES,\n",
    "    templates=OPENAI_IMAGENET_TEMPLATES,\n",
    "    num_classes_per_batch=10,\n",
    "    device=device,\n",
    "    use_tqdm=True\n",
    "    )\n",
    "print(\"[class name embeddings]:\", zero_shot_weights.shape)  # [512, 1000]\n",
    "\n",
    "L = 100\n",
    "cal_gap = 10\n",
    "\n",
    "# Define all heatmap types to evaluate\n",
    "hm_types = ['eclip', 'gradcam', 'maskclip', 'game', 'rollout', 'clipsurgery']\n",
    "extensions = [\"gt\", \"pred\"]\n",
    "\n",
    "# Method name mapping for display\n",
    "method_names = {\n",
    "    'gradcam': 'Grad-CAM', \n",
    "    'maskclip': 'MaskCLIP',\n",
    "    'eclip': 'ECLIP',\n",
    "    'game': 'GAME',\n",
    "    'rollout': 'Rollout',\n",
    "    'clipsurgery': 'CLIPSurgery'\n",
    "}\n",
    "\n",
    "# Storage for results\n",
    "all_results = {}\n",
    "insertion_curves = {}\n",
    "\n",
    "for ex in extensions: \n",
    "    for hm_type_old in hm_types:\n",
    "        hm_type = f\"{hm_type_old}_{ex}\"\n",
    "        print(f\"Evaluating {hm_type}...\")\n",
    "        \n",
    "        # Initialize metrics for each insertion step\n",
    "        top1 = torch.zeros([11])  # 11 steps: 0, 10, 20, ..., 100\n",
    "        top5 = torch.zeros([11])\n",
    "        top10 = torch.zeros([11])\n",
    "        n = torch.zeros([11])\n",
    "        \n",
    "        # Storage for insertion curves\n",
    "        insertion_steps = list(range(0, L + 1, cal_gap))\n",
    "\n",
    "        with open(\"imagenet_class_index.json\", \"r\") as ff:\n",
    "            class_dict = json.load(ff)\n",
    "            for label, values in list(class_dict.items())[0:100]:  # process first 100 classes\n",
    "                label = int(label)\n",
    "                folder = values[0]\n",
    "                print(\"Start: Processing the {}th folder, target class name: {}\".format(label, IMAGENET_CLASSNAMES[label]))\n",
    "\n",
    "                files = os.listdir(data_path+folder)\n",
    "\n",
    "                for f in files:\n",
    "                    img_name = f.split(\".\")[0]\n",
    "                    img = Image.open(os.path.join(data_path, folder, f)).convert(\"RGB\")\n",
    "                    w, h = img.size\n",
    "                    # in case there is too large image\n",
    "                    if min(w,h) > 640:\n",
    "                        scale = min(w,h) / 640\n",
    "                        hs = int(h/scale)\n",
    "                        ws = int(w/scale)\n",
    "                        img = img.resize((ws,hs))\n",
    "                    w, h = img.size\n",
    "                    resize = Resize((h,w))\n",
    "                    \n",
    "                    # make prediction\n",
    "                    with torch.no_grad():\n",
    "                        img_clipreprocess = preprocess(img).to(device).unsqueeze(0)\n",
    "                        img_clip_embedding = clipmodel.encode_image(img_clipreprocess)\n",
    "                        logits = 100. * img_clip_embedding @ zero_shot_weights\n",
    "                        target = torch.tensor([label]).to(device)\n",
    "                        [acc1, acc5, acc10], pred_top1 = accuracy(logits, target, topk=(1, 5, 10))\n",
    "                        top1[-1:] += acc1  # Original image accuracy\n",
    "                        top5[-1:] += acc5\n",
    "                        top10[-1:] += acc10\n",
    "                        n[-1] += 1\n",
    "\n",
    "                    hm = generate_hm(hm_type, img.copy(), label, pred_top1.item(), resize)\n",
    "                    ins_imgs = insertion_process(img, hm, L, cal_gap, ins_path+folder, '{}_{}'.format(img_name, hm_type))\n",
    "                    \n",
    "                    # Evaluate insertion steps\n",
    "                    img_clip_embedding = clipmodel.encode_image(ins_imgs)\n",
    "                    logits = 100. * img_clip_embedding @ zero_shot_weights\n",
    "                    target = torch.tensor([label]).repeat(len(img_clip_embedding)).to(device)\n",
    "                    [acc1, acc5, acc10], _ = accuracy(logits, target, topk=(1, 5, 10))\n",
    "                    top1[:-1] += acc1  # Insertion steps accuracy\n",
    "                    top5[:-1] += acc5\n",
    "                    top10[:-1] += acc10\n",
    "                    n[:-1] += 1\n",
    "\n",
    "        # Calculate final accuracies\n",
    "        top1_acc = (top1 / n).numpy()\n",
    "        top5_acc = (top5 / n).numpy()\n",
    "        top10_acc = (top10 / n).numpy()\n",
    "        \n",
    "        print(f\"[{hm_type}] Final accuracies:\")\n",
    "        print(\"Top1:\", top1_acc)\n",
    "        print(\"Top5:\", top5_acc)\n",
    "        print(\"Top10:\", top10_acc)\n",
    "        \n",
    "        # Store results for this method\n",
    "        if ex == \"gt\":\n",
    "            gt_suffix = \"_gt\"\n",
    "        else:\n",
    "            gt_suffix = \"_pred\" \n",
    "            \n",
    "        base_method = hm_type_old\n",
    "        \n",
    "        if base_method not in all_results:\n",
    "            all_results[base_method] = {}\n",
    "            \n",
    "        # Store final accuracy (at step 100)\n",
    "        all_results[base_method][f'{ex}_top1'] = top1_acc[-1]  # Last step (100%)\n",
    "        all_results[base_method][f'{ex}_top5'] = top5_acc[-1]\n",
    "        \n",
    "        # Store insertion curves\n",
    "        insertion_curves[hm_type] = {\n",
    "            'steps': insertion_steps,\n",
    "            'top1': top1_acc,\n",
    "            'top5': top5_acc,\n",
    "            'top10': top10_acc\n",
    "        }\n",
    "\n",
    "# Create results table\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"INSERTION EVALUATION RESULTS\")\n",
    "print(\"=\"*70)\n",
    "print(f\"{'Method':<15} {'Ground-truth':<20} {'Prediction':<20}\")\n",
    "print(f\"{'':15} {'@1':<10} {'@5':<10} {'@1':<10} {'@5':<10}\")\n",
    "print(\"-\"*70)\n",
    "\n",
    "for method in hm_types:\n",
    "    if method in all_results:\n",
    "        method_name = method_names.get(method, method)\n",
    "        results = all_results[method]\n",
    "        gt_top1 = results.get('gt_top1', 0)\n",
    "        gt_top5 = results.get('gt_top5', 0)\n",
    "        pred_top1 = results.get('pred_top1', 0)\n",
    "        pred_top5 = results.get('pred_top5', 0)\n",
    "        \n",
    "        print(f\"{method_name:<15} {gt_top1:<10.4f} {gt_top5:<10.4f} \"\n",
    "              f\"{pred_top1:<10.4f} {pred_top5:<10.4f}\")\n",
    "\n",
    "# Save results to CSV\n",
    "results_data = []\n",
    "for method in hm_types:\n",
    "    if method in all_results:\n",
    "        method_name = method_names.get(method, method)\n",
    "        results = all_results[method]\n",
    "        results_data.append({\n",
    "            'Method': method_name,\n",
    "            'GT_Top1': results.get('gt_top1', 0),\n",
    "            'GT_Top5': results.get('gt_top5', 0),\n",
    "            'Pred_Top1': results.get('pred_top1', 0),\n",
    "            'Pred_Top5': results.get('pred_top5', 0)\n",
    "        })\n",
    "\n",
    "results_df = pd.DataFrame(results_data)\n",
    "results_df.to_csv('insertion_evaluation_results.csv', index=False)\n",
    "print(f\"\\nResults saved to insertion_evaluation_results.csv\")\n",
    "\n",
    "# Plot insertion curves\n",
    "fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(15, 10))\n",
    "\n",
    "# Ground-truth curves\n",
    "for method in hm_types:\n",
    "    gt_key = f\"{method}_gt\"\n",
    "    pred_key = f\"{method}_pred\"\n",
    "    \n",
    "    if gt_key in insertion_curves:\n",
    "        curve_data = insertion_curves[gt_key]\n",
    "        method_name = method_names.get(method, method)\n",
    "        \n",
    "        # GT Top-1\n",
    "        ax1.plot(curve_data['steps'], curve_data['top1'], \n",
    "                label=method_name, marker='o', markersize=4)\n",
    "        \n",
    "        # GT Top-5\n",
    "        ax2.plot(curve_data['steps'], curve_data['top5'], \n",
    "                label=method_name, marker='o', markersize=4)\n",
    "\n",
    "# Prediction curves\n",
    "for method in hm_types:\n",
    "    pred_key = f\"{method}_pred\"\n",
    "    \n",
    "    if pred_key in insertion_curves:\n",
    "        curve_data = insertion_curves[pred_key]\n",
    "        method_name = method_names.get(method, method)\n",
    "        \n",
    "        # Pred Top-1\n",
    "        ax3.plot(curve_data['steps'], curve_data['top1'], \n",
    "                label=method_name, marker='o', markersize=4)\n",
    "        \n",
    "        # Pred Top-5\n",
    "        ax4.plot(curve_data['steps'], curve_data['top5'], \n",
    "                label=method_name, marker='o', markersize=4)\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "data_path = \"/home/infres/pmbathe-24/Projet-IA-Fairness/Grad-Eclip-main/data/val/\"\n",
    "ins_path = '/home/infres/pmbathe-24/Projet-IA-Fairness/Grad-Eclip-main/data/ins_samples/'  ### for debug, saving insertion samples\n",
    "\n",
    "zero_shot_weights = build_zero_shot_classifier(\n",
    "    clipmodel,\n",
    "    classnames=IMAGENET_CLASSNAMES,\n",
    "    templates=OPENAI_IMAGENET_TEMPLATES,\n",
    "    num_classes_per_batch=10,\n",
    "    device=device,\n",
    "    use_tqdm=True\n",
    "    )\n",
    "print(\"[class name embeddings]:\", zero_shot_weights.shape)  # [512, 1000]\n",
    "\n",
    "L = 100\n",
    "cal_gap = 10\n",
    "\n",
    "# Define all heatmap types to evaluate\n",
    "hm_types = ['eclip', 'gradcam', 'maskclip', 'game', 'rollout', 'clipsurgery']\n",
    "extensions = [\"gt\", \"pred\"]\n",
    "\n",
    "# Method name mapping for display\n",
    "method_names = {\n",
    "    'gradcam': 'Grad-CAM', \n",
    "    'maskclip': 'MaskCLIP',\n",
    "    'eclip': 'ECLIP',\n",
    "    'game': 'GAME',\n",
    "    'rollout': 'Rollout',\n",
    "    'clipsurgery': 'CLIPSurgery'\n",
    "}\n",
    "\n",
    "# Storage for results\n",
    "all_results = {}\n",
    "insertion_curves = {}\n",
    "\n",
    "for ex in extensions: \n",
    "    for hm_type_old in hm_types:\n",
    "        hm_type = f\"{hm_type_old}_{ex}\"\n",
    "        print(f\"Evaluating {hm_type}...\")\n",
    "        \n",
    "        # Initialize metrics for each insertion step\n",
    "        top1 = torch.zeros([11])  # 11 steps: 0, 10, 20, ..., 100\n",
    "        top5 = torch.zeros([11])\n",
    "        top10 = torch.zeros([11])\n",
    "        n = torch.zeros([11])\n",
    "        \n",
    "        # Storage for insertion curves\n",
    "        insertion_steps = list(range(0, L + 1, cal_gap))\n",
    "\n",
    "        with open(\"imagenet_class_index.json\", \"r\") as ff:\n",
    "            class_dict = json.load(ff)\n",
    "            for label, values in list(class_dict.items())[0:100]:  # process first 100 classes\n",
    "                label = int(label)\n",
    "                folder = values[0]\n",
    "                print(\"Start: Processing the {}th folder, target class name: {}\".format(label, IMAGENET_CLASSNAMES[label]))\n",
    "\n",
    "                files = os.listdir(data_path+folder)\n",
    "\n",
    "                for f in files:\n",
    "                    img_name = f.split(\".\")[0]\n",
    "                    img = Image.open(os.path.join(data_path, folder, f)).convert(\"RGB\")\n",
    "                    w, h = img.size\n",
    "                    # in case there is too large image\n",
    "                    if min(w,h) > 640:\n",
    "                        scale = min(w,h) / 640\n",
    "                        hs = int(h/scale)\n",
    "                        ws = int(w/scale)\n",
    "                        img = img.resize((ws,hs))\n",
    "                    w, h = img.size\n",
    "                    resize = Resize((h,w))\n",
    "                    \n",
    "                    # make prediction\n",
    "                    with torch.no_grad():\n",
    "                        img_clipreprocess = preprocess(img).to(device).unsqueeze(0)\n",
    "                        img_clip_embedding = clipmodel.encode_image(img_clipreprocess)\n",
    "                        logits = 100. * img_clip_embedding @ zero_shot_weights\n",
    "                        target = torch.tensor([label]).to(device)\n",
    "                        [acc1, acc5, acc10], pred_top1 = accuracy(logits, target, topk=(1, 5, 10))\n",
    "                        top1[-1:] += acc1  # Original image accuracy\n",
    "                        top5[-1:] += acc5\n",
    "                        top10[-1:] += acc10\n",
    "                        n[-1] += 1\n",
    "\n",
    "                    hm = generate_hm(hm_type, img.copy(), label, pred_top1.item(), resize)\n",
    "                    ins_imgs = insertion_process(img, hm, L, cal_gap, ins_path+folder, '{}_{}'.format(img_name, hm_type))\n",
    "                    \n",
    "                    # Evaluate insertion steps\n",
    "                    img_clip_embedding = clipmodel.encode_image(ins_imgs)\n",
    "                    logits = 100. * img_clip_embedding @ zero_shot_weights\n",
    "                    target = torch.tensor([label]).repeat(len(img_clip_embedding)).to(device)\n",
    "                    [acc1, acc5, acc10], _ = accuracy(logits, target, topk=(1, 5, 10))\n",
    "                    top1[:-1] += acc1  # Insertion steps accuracy\n",
    "                    top5[:-1] += acc5\n",
    "                    top10[:-1] += acc10\n",
    "                    n[:-1] += 1\n",
    "\n",
    "        # Calculate final accuracies\n",
    "        top1_acc = (top1 / n).numpy()\n",
    "        top5_acc = (top5 / n).numpy()\n",
    "        top10_acc = (top10 / n).numpy()\n",
    "        \n",
    "        print(f\"[{hm_type}] Final accuracies:\")\n",
    "        print(\"Top1:\", top1_acc)\n",
    "        print(\"Top5:\", top5_acc)\n",
    "        print(\"Top10:\", top10_acc)\n",
    "        \n",
    "        # Store results for this method\n",
    "        if ex == \"gt\":\n",
    "            gt_suffix = \"_gt\"\n",
    "        else:\n",
    "            gt_suffix = \"_pred\" \n",
    "            \n",
    "        base_method = hm_type_old\n",
    "        \n",
    "        if base_method not in all_results:\n",
    "            all_results[base_method] = {}\n",
    "            \n",
    "        # Store final accuracy (at step 100)\n",
    "        all_results[base_method][f'{ex}_top1'] = top1_acc[-1]  # Last step (100%)\n",
    "        all_results[base_method][f'{ex}_top5'] = top5_acc[-1]\n",
    "        \n",
    "        # Store insertion curves\n",
    "        insertion_curves[hm_type] = {\n",
    "            'steps': insertion_steps,\n",
    "            'top1': top1_acc,\n",
    "            'top5': top5_acc,\n",
    "            'top10': top10_acc\n",
    "        }\n",
    "\n",
    "# Create results table\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"INSERTION EVALUATION RESULTS\")\n",
    "print(\"=\"*70)\n",
    "print(f\"{'Method':<15} {'Ground-truth':<20} {'Prediction':<20}\")\n",
    "print(f\"{'':15} {'@1':<10} {'@5':<10} {'@1':<10} {'@5':<10}\")\n",
    "print(\"-\"*70)\n",
    "\n",
    "for method in hm_types:\n",
    "    if method in all_results:\n",
    "        method_name = method_names.get(method, method)\n",
    "        results = all_results[method]\n",
    "        gt_top1 = results.get('gt_top1', 0)\n",
    "        gt_top5 = results.get('gt_top5', 0)\n",
    "        pred_top1 = results.get('pred_top1', 0)\n",
    "        pred_top5 = results.get('pred_top5', 0)\n",
    "        \n",
    "        print(f\"{method_name:<15} {gt_top1:<10.4f} {gt_top5:<10.4f} \"\n",
    "              f\"{pred_top1:<10.4f} {pred_top5:<10.4f}\")\n",
    "\n",
    "# Save results to CSV\n",
    "results_data = []\n",
    "for method in hm_types:\n",
    "    if method in all_results:\n",
    "        method_name = method_names.get(method, method)\n",
    "        results = all_results[method]\n",
    "        results_data.append({\n",
    "            'Method': method_name,\n",
    "            'GT_Top1': results.get('gt_top1', 0),\n",
    "            'GT_Top5': results.get('gt_top5', 0),\n",
    "            'Pred_Top1': results.get('pred_top1', 0),\n",
    "            'Pred_Top5': results.get('pred_top5', 0)\n",
    "        })\n",
    "\n",
    "results_df = pd.DataFrame(results_data)\n",
    "results_df.to_csv('insertion_evaluation_results.csv', index=False)\n",
    "print(f\"\\nResults saved to insertion_evaluation_results.csv\")\n",
    "\n",
    "# Plot insertion curves\n",
    "fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(15, 10))\n",
    "\n",
    "# Ground-truth curves\n",
    "for method in hm_types:\n",
    "    gt_key = f\"{method}_gt\"\n",
    "    pred_key = f\"{method}_pred\"\n",
    "    \n",
    "    if gt_key in insertion_curves:\n",
    "        curve_data = insertion_curves[gt_key]\n",
    "        method_name = method_names.get(method, method)\n",
    "        \n",
    "        # GT Top-1\n",
    "        ax1.plot(curve_data['steps'], curve_data['top1'], \n",
    "                label=method_name, marker='o', markersize=4)\n",
    "        \n",
    "        # GT Top-5\n",
    "        ax2.plot(curve_data['steps'], curve_data['top5'], \n",
    "                label=method_name, marker='o', markersize=4)\n",
    "\n",
    "# Prediction curves\n",
    "for method in hm_types:\n",
    "    pred_key = f\"{method}_pred\"\n",
    "    \n",
    "    if pred_key in insertion_curves:\n",
    "        curve_data = insertion_curves[pred_key]\n",
    "        method_name = method_names.get(method, method)\n",
    "        \n",
    "        # Pred Top-1\n",
    "        ax3.plot(curve_data['steps'], curve_data['top1'], \n",
    "                label=method_name, marker='o', markersize=4)\n",
    "        \n",
    "        # Pred Top-5\n",
    "        ax4.plot(curve_data['steps'], curve_data['top5'], \n",
    "                label=method_name, marker='o', markersize=4)\n",
    "\n",
    "# Configure subplots\n",
    "ax1.set_title('Ground-truth Top-1 Insertion')\n",
    "ax1.set_xlabel('Insertion Step')\n",
    "ax1.set_ylabel('Accuracy')\n",
    "ax1.legend()\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "ax2.set_title('Ground-truth Top-5 Insertion')\n",
    "ax2.set_xlabel('Insertion Step')\n",
    "ax2.set_ylabel('Accuracy')\n",
    "ax2.legend()\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "ax3.set_title('Prediction Top-1 Insertion')\n",
    "ax3.set_xlabel('Insertion Step')\n",
    "ax3.set_ylabel('Accuracy')\n",
    "ax3.legend()\n",
    "ax3.grid(True, alpha=0.3)\n",
    "\n",
    "ax4.set_title('Prediction Top-5 Insertion')\n",
    "ax4.set_xlabel('Insertion Step')\n",
    "ax4.set_ylabel('Accuracy')\n",
    "ax4.legend()\n",
    "ax4.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('insertion_curves_comparison.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nInsertion curves saved to insertion_curves_comparison.png\")\n",
    "# Configure subplots\n",
    "ax1.set_title('Ground-truth Top-1 Insertion')\n",
    "ax1.set_xlabel('Insertion Step')\n",
    "ax1.set_ylabel('Accuracy')\n",
    "ax1.legend()\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "ax2.set_title('Ground-truth Top-5 Insertion')\n",
    "ax2.set_xlabel('Insertion Step')\n",
    "ax2.set_ylabel('Accuracy')\n",
    "ax2.legend()\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "ax3.set_title('Prediction Top-1 Insertion')\n",
    "ax3.set_xlabel('Insertion Step')\n",
    "ax3.set_ylabel('Accuracy')\n",
    "ax3.legend()\n",
    "ax3.grid(True, alpha=0.3)\n",
    "\n",
    "ax4.set_title('Prediction Top-5 Insertion')\n",
    "ax4.set_xlabel('Insertion Step')\n",
    "ax4.set_ylabel('Accuracy')\n",
    "ax4.legend()\n",
    "ax4.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('insertion_curves_comparison.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nInsertion curves saved to insertion_curves_comparison.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58e56dd6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
