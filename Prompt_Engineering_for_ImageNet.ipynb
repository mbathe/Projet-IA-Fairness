{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "53N4k0pj_9qL"
      },
      "source": [
        "# Preparation for Colab\n",
        "\n",
        "Make sure you're running a GPU runtime; if not, select \"GPU\" as the hardware accelerator in Runtime > Change Runtime Type in the menu. The next cells will install the `clip` package and its dependencies, and check if PyTorch 1.7.1 or later is installed."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0BpdJkdBssk9",
        "outputId": "41a4070f-5321-4fc4-bd4d-0b5c1f476d56"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting ftfy\n",
            "  Downloading ftfy-6.3.1-py3-none-any.whl.metadata (7.3 kB)\n",
            "Collecting regex\n",
            "  Downloading regex-2024.11.6-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (40 kB)\n",
            "Collecting tqdm\n",
            "  Downloading tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n",
            "Requirement already satisfied: wcwidth in ./.venv/lib/python3.12/site-packages (from ftfy) (0.2.13)\n",
            "Downloading ftfy-6.3.1-py3-none-any.whl (44 kB)\n",
            "Downloading regex-2024.11.6-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (796 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m796.9/796.9 kB\u001b[0m \u001b[31m10.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
            "Installing collected packages: tqdm, regex, ftfy\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3/3\u001b[0m [ftfy][32m1/3\u001b[0m [regex]\n",
            "\u001b[1A\u001b[2KSuccessfully installed ftfy-6.3.1 regex-2024.11.6 tqdm-4.67.1\n",
            "Collecting git+https://github.com/openai/CLIP.git\n",
            "  Cloning https://github.com/openai/CLIP.git to /tmp/pip-req-build-al9q4ci9\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/openai/CLIP.git /tmp/pip-req-build-al9q4ci9\n",
            "  Resolved https://github.com/openai/CLIP.git to commit dcba3cb2e2827b402d2701e7e1c7d9fed8a20ef1\n",
            "  Installing build dependencies ... \u001b[?25ldone\n",
            "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
            "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
            "\u001b[?25hRequirement already satisfied: ftfy in ./.venv/lib/python3.12/site-packages (from clip==1.0) (6.3.1)\n",
            "Requirement already satisfied: packaging in ./.venv/lib/python3.12/site-packages (from clip==1.0) (25.0)\n",
            "Requirement already satisfied: regex in ./.venv/lib/python3.12/site-packages (from clip==1.0) (2024.11.6)\n",
            "Requirement already satisfied: tqdm in ./.venv/lib/python3.12/site-packages (from clip==1.0) (4.67.1)\n",
            "Collecting torch (from clip==1.0)\n",
            "  Downloading torch-2.7.1-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (29 kB)\n",
            "Collecting torchvision (from clip==1.0)\n",
            "  Downloading torchvision-0.22.1-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (6.1 kB)\n",
            "Requirement already satisfied: wcwidth in ./.venv/lib/python3.12/site-packages (from ftfy->clip==1.0) (0.2.13)\n",
            "Collecting filelock (from torch->clip==1.0)\n",
            "  Downloading filelock-3.18.0-py3-none-any.whl.metadata (2.9 kB)\n",
            "Collecting typing-extensions>=4.10.0 (from torch->clip==1.0)\n",
            "  Downloading typing_extensions-4.14.0-py3-none-any.whl.metadata (3.0 kB)\n",
            "Collecting setuptools (from torch->clip==1.0)\n",
            "  Using cached setuptools-80.9.0-py3-none-any.whl.metadata (6.6 kB)\n",
            "Collecting sympy>=1.13.3 (from torch->clip==1.0)\n",
            "  Downloading sympy-1.14.0-py3-none-any.whl.metadata (12 kB)\n",
            "Collecting networkx (from torch->clip==1.0)\n",
            "  Downloading networkx-3.5-py3-none-any.whl.metadata (6.3 kB)\n",
            "Collecting jinja2 (from torch->clip==1.0)\n",
            "  Downloading jinja2-3.1.6-py3-none-any.whl.metadata (2.9 kB)\n",
            "Collecting fsspec (from torch->clip==1.0)\n",
            "  Downloading fsspec-2025.5.1-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.6.77 (from torch->clip==1.0)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.6.77-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.6.77 (from torch->clip==1.0)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.6.77-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.6.80 (from torch->clip==1.0)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.6.80-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.5.1.17 (from torch->clip==1.0)\n",
            "  Downloading nvidia_cudnn_cu12-9.5.1.17-py3-none-manylinux_2_28_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.6.4.1 (from torch->clip==1.0)\n",
            "  Downloading nvidia_cublas_cu12-12.6.4.1-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.3.0.4 (from torch->clip==1.0)\n",
            "  Downloading nvidia_cufft_cu12-11.3.0.4-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.7.77 (from torch->clip==1.0)\n",
            "  Downloading nvidia_curand_cu12-10.3.7.77-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.7.1.2 (from torch->clip==1.0)\n",
            "  Downloading nvidia_cusolver_cu12-11.7.1.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.5.4.2 (from torch->clip==1.0)\n",
            "  Downloading nvidia_cusparse_cu12-12.5.4.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparselt-cu12==0.6.3 (from torch->clip==1.0)\n",
            "  Downloading nvidia_cusparselt_cu12-0.6.3-py3-none-manylinux2014_x86_64.whl.metadata (6.8 kB)\n",
            "Collecting nvidia-nccl-cu12==2.26.2 (from torch->clip==1.0)\n",
            "  Downloading nvidia_nccl_cu12-2.26.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (2.0 kB)\n",
            "Collecting nvidia-nvtx-cu12==12.6.77 (from torch->clip==1.0)\n",
            "  Downloading nvidia_nvtx_cu12-12.6.77-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-nvjitlink-cu12==12.6.85 (from torch->clip==1.0)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.6.85-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufile-cu12==1.11.1.6 (from torch->clip==1.0)\n",
            "  Downloading nvidia_cufile_cu12-1.11.1.6-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting triton==3.3.1 (from torch->clip==1.0)\n",
            "  Downloading triton-3.3.1-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting mpmath<1.4,>=1.1.0 (from sympy>=1.13.3->torch->clip==1.0)\n",
            "  Downloading mpmath-1.3.0-py3-none-any.whl.metadata (8.6 kB)\n",
            "Collecting MarkupSafe>=2.0 (from jinja2->torch->clip==1.0)\n",
            "  Downloading MarkupSafe-3.0.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.0 kB)\n",
            "Collecting numpy (from torchvision->clip==1.0)\n",
            "  Downloading numpy-2.3.0-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (62 kB)\n",
            "Collecting pillow!=8.3.*,>=5.3.0 (from torchvision->clip==1.0)\n",
            "  Downloading pillow-11.2.1-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (8.9 kB)\n",
            "Downloading torch-2.7.1-cp312-cp312-manylinux_2_28_x86_64.whl (821.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m821.0/821.0 MB\u001b[0m \u001b[31m95.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.6.4.1-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (393.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m393.1/393.1 MB\u001b[0m \u001b[31m140.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.6.80-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (8.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.9/8.9 MB\u001b[0m \u001b[31m145.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.6.77-py3-none-manylinux2014_x86_64.whl (23.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m146.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.6.77-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (897 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m897.7/897.7 kB\u001b[0m \u001b[31m58.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.5.1.17-py3-none-manylinux_2_28_x86_64.whl (571.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m571.0/571.0 MB\u001b[0m \u001b[31m115.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.3.0.4-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (200.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m200.2/200.2 MB\u001b[0m \u001b[31m169.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufile_cu12-1.11.1.6-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (1.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m79.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.7.77-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m160.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.7.1.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (158.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m158.2/158.2 MB\u001b[0m \u001b[31m158.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.5.4.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (216.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m216.6/216.6 MB\u001b[0m \u001b[31m173.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparselt_cu12-0.6.3-py3-none-manylinux2014_x86_64.whl (156.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m156.8/156.8 MB\u001b[0m \u001b[31m155.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nccl_cu12-2.26.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (201.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m201.3/201.3 MB\u001b[0m \u001b[31m164.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.6.85-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl (19.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.7/19.7 MB\u001b[0m \u001b[31m160.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvtx_cu12-12.6.77-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (89 kB)\n",
            "Downloading triton-3.3.1-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (155.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m155.7/155.7 MB\u001b[0m \u001b[31m166.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
            "\u001b[?25hUsing cached setuptools-80.9.0-py3-none-any.whl (1.2 MB)\n",
            "Downloading sympy-1.14.0-py3-none-any.whl (6.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.3/6.3 MB\u001b[0m \u001b[31m133.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m536.2/536.2 kB\u001b[0m \u001b[31m33.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading typing_extensions-4.14.0-py3-none-any.whl (43 kB)\n",
            "Downloading filelock-3.18.0-py3-none-any.whl (16 kB)\n",
            "Downloading fsspec-2025.5.1-py3-none-any.whl (199 kB)\n",
            "Downloading jinja2-3.1.6-py3-none-any.whl (134 kB)\n",
            "Downloading MarkupSafe-3.0.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (23 kB)\n",
            "Downloading networkx-3.5-py3-none-any.whl (2.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m114.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading torchvision-0.22.1-cp312-cp312-manylinux_2_28_x86_64.whl (7.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.5/7.5 MB\u001b[0m \u001b[31m130.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pillow-11.2.1-cp312-cp312-manylinux_2_28_x86_64.whl (4.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.6/4.6 MB\u001b[0m \u001b[31m135.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading numpy-2.3.0-cp312-cp312-manylinux_2_28_x86_64.whl (16.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.6/16.6 MB\u001b[0m \u001b[31m159.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: clip\n",
            "  Building wheel for clip (pyproject.toml) ... \u001b[?25ldone\n",
            "\u001b[?25h  Created wheel for clip: filename=clip-1.0-py3-none-any.whl size=1369549 sha256=a0c88b64d628d01a77ff866a485bd054c77eaa10e140e91396420f148129d5bc\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-z8m9nvwe/wheels/35/3e/df/3d24cbfb3b6a06f17a2bfd7d1138900d4365d9028aa8f6e92f\n",
            "Successfully built clip\n",
            "Installing collected packages: nvidia-cusparselt-cu12, mpmath, typing-extensions, sympy, setuptools, pillow, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufile-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, numpy, networkx, MarkupSafe, fsspec, filelock, triton, nvidia-cusparse-cu12, nvidia-cufft-cu12, nvidia-cudnn-cu12, jinja2, nvidia-cusolver-cu12, torch, torchvision, clip\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m29/29\u001b[0m [clip]2m27/29\u001b[0m [torchvision]ver-cu12]2]\n",
            "\u001b[1A\u001b[2KSuccessfully installed MarkupSafe-3.0.2 clip-1.0 filelock-3.18.0 fsspec-2025.5.1 jinja2-3.1.6 mpmath-1.3.0 networkx-3.5 numpy-2.3.0 nvidia-cublas-cu12-12.6.4.1 nvidia-cuda-cupti-cu12-12.6.80 nvidia-cuda-nvrtc-cu12-12.6.77 nvidia-cuda-runtime-cu12-12.6.77 nvidia-cudnn-cu12-9.5.1.17 nvidia-cufft-cu12-11.3.0.4 nvidia-cufile-cu12-1.11.1.6 nvidia-curand-cu12-10.3.7.77 nvidia-cusolver-cu12-11.7.1.2 nvidia-cusparse-cu12-12.5.4.2 nvidia-cusparselt-cu12-0.6.3 nvidia-nccl-cu12-2.26.2 nvidia-nvjitlink-cu12-12.6.85 nvidia-nvtx-cu12-12.6.77 pillow-11.2.1 setuptools-80.9.0 sympy-1.14.0 torch-2.7.1 torchvision-0.22.1 triton-3.3.1 typing-extensions-4.14.0\n"
          ]
        }
      ],
      "source": [
        "! pip install ftfy regex tqdm\n",
        "! pip install git+https://github.com/openai/CLIP.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C1hkDT38hSaP",
        "outputId": "e10d4f17-8fa6-4b75-a18f-f0c38990b5a3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Torch version: 2.7.1+cu126\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipykernel_3746513/926775896.py:5: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
            "  from pkg_resources import packaging\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import clip\n",
        "from tqdm.notebook import tqdm\n",
        "from pkg_resources import packaging\n",
        "\n",
        "print(\"Torch version:\", torch.__version__)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eFxgLV5HAEEw"
      },
      "source": [
        "# Loading the model\n",
        "\n",
        "Download and instantiate a CLIP model using the `clip` module that we just installed."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uLFS29hnhlY4",
        "outputId": "09abb234-693e-4efb-953f-e1847ba95758"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['RN50',\n",
              " 'RN101',\n",
              " 'RN50x4',\n",
              " 'RN50x16',\n",
              " 'RN50x64',\n",
              " 'ViT-B/32',\n",
              " 'ViT-B/16',\n",
              " 'ViT-L/14',\n",
              " 'ViT-L/14@336px']"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "clip.available_models()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cboKZocQlSYX",
        "outputId": "240acdd0-ca62-45db-8418-9e4ef73e8aff"
      },
      "outputs": [],
      "source": [
        "model, preprocess = clip.load(\"ViT-B/32\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IBRVTY9lbGm8",
        "outputId": "785019a1-1f40-45b0-e349-b0d4ec3173bf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model parameters: 151,277,313\n",
            "Input resolution: 224\n",
            "Context length: 77\n",
            "Vocab size: 49408\n"
          ]
        }
      ],
      "source": [
        "input_resolution = model.visual.input_resolution\n",
        "context_length = model.context_length\n",
        "vocab_size = model.vocab_size\n",
        "\n",
        "print(\"Model parameters:\", f\"{np.sum([int(np.prod(p.shape)) for p in model.parameters()]):,}\")\n",
        "print(\"Input resolution:\", input_resolution)\n",
        "print(\"Context length:\", context_length)\n",
        "print(\"Vocab size:\", vocab_size)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LhO3OtOmF8M4"
      },
      "source": [
        "# Preparing ImageNet labels and prompts\n",
        "\n",
        "The following cell contains the 1,000 labels for the ImageNet dataset, followed by the text templates we'll use as \"prompt engineering\"."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "R2HbOZrqa0jF"
      },
      "outputs": [],
      "source": [
        "imagenet_classes = [ \"tench\", \"goldfish\", \"great white shark\", \"tiger shark\", \"hammerhead shark\", \"electric ray\",\n",
        "    \"stingray\", \"rooster\", \"hen\", \"ostrich\", \"brambling\", \"goldfinch\", \"house finch\", \"junco\",\n",
        "    \"indigo bunting\", \"American robin\", \"bulbul\", \"jay\", \"magpie\", \"chickadee\", \"American dipper\",\n",
        "    \"kite (bird of prey)\", \"bald eagle\", \"vulture\", \"great grey owl\", \"fire salamander\",\n",
        "    \"smooth newt\", \"newt\", \"spotted salamander\", \"axolotl\", \"American bullfrog\", \"tree frog\",\n",
        "    \"tailed frog\", \"loggerhead sea turtle\", \"leatherback sea turtle\", \"mud turtle\", \"terrapin\",\n",
        "    \"box turtle\", \"banded gecko\", \"green iguana\", \"Carolina anole\",\n",
        "    \"desert grassland whiptail lizard\", \"agama\", \"frilled-necked lizard\", \"alligator lizard\",\n",
        "    \"Gila monster\", \"European green lizard\", \"chameleon\", \"Komodo dragon\", \"Nile crocodile\",\n",
        "    \"American alligator\", \"triceratops\", \"worm snake\", \"ring-necked snake\",\n",
        "    \"eastern hog-nosed snake\", \"smooth green snake\", \"kingsnake\", \"garter snake\", \"water snake\",\n",
        "    \"vine snake\", \"night snake\", \"boa constrictor\", \"African rock python\", \"Indian cobra\",\n",
        "    \"green mamba\", \"sea snake\", \"Saharan horned viper\", \"eastern diamondback rattlesnake\",\n",
        "    \"sidewinder rattlesnake\", \"trilobite\", \"harvestman\", \"scorpion\", \"yellow garden spider\",\n",
        "    \"barn spider\", \"European garden spider\", \"southern black widow\", \"tarantula\", \"wolf spider\",\n",
        "    \"tick\", \"centipede\", \"black grouse\", \"ptarmigan\", \"ruffed grouse\", \"prairie grouse\", \"peafowl\",\n",
        "    \"quail\", \"partridge\", \"african grey parrot\", \"macaw\", \"sulphur-crested cockatoo\", \"lorikeet\",\n",
        "    \"coucal\", \"bee eater\", \"hornbill\", \"hummingbird\", \"jacamar\", \"toucan\", \"duck\",\n",
        "    \"red-breasted merganser\", \"goose\", \"black swan\", \"tusker\", \"echidna\", \"platypus\", \"wallaby\",\n",
        "    \"koala\", \"wombat\", \"jellyfish\", \"sea anemone\", \"brain coral\", \"flatworm\", \"nematode\", \"conch\",\n",
        "    \"snail\", \"slug\", \"sea slug\", \"chiton\", \"chambered nautilus\", \"Dungeness crab\", \"rock crab\",\n",
        "    \"fiddler crab\", \"red king crab\", \"American lobster\", \"spiny lobster\", \"crayfish\", \"hermit crab\",\n",
        "    \"isopod\", \"white stork\", \"black stork\", \"spoonbill\", \"flamingo\", \"little blue heron\",\n",
        "    \"great egret\", \"bittern bird\", \"crane bird\", \"limpkin\", \"common gallinule\", \"American coot\",\n",
        "    \"bustard\", \"ruddy turnstone\", \"dunlin\", \"common redshank\", \"dowitcher\", \"oystercatcher\",\n",
        "    \"pelican\", \"king penguin\", \"albatross\", \"grey whale\", \"killer whale\", \"dugong\", \"sea lion\",\n",
        "    \"Chihuahua\", \"Japanese Chin\", \"Maltese\", \"Pekingese\", \"Shih Tzu\", \"King Charles Spaniel\",\n",
        "    \"Papillon\", \"toy terrier\", \"Rhodesian Ridgeback\", \"Afghan Hound\", \"Basset Hound\", \"Beagle\",\n",
        "    \"Bloodhound\", \"Bluetick Coonhound\", \"Black and Tan Coonhound\", \"Treeing Walker Coonhound\",\n",
        "    \"English foxhound\", \"Redbone Coonhound\", \"borzoi\", \"Irish Wolfhound\", \"Italian Greyhound\",\n",
        "    \"Whippet\", \"Ibizan Hound\", \"Norwegian Elkhound\", \"Otterhound\", \"Saluki\", \"Scottish Deerhound\",\n",
        "    \"Weimaraner\", \"Staffordshire Bull Terrier\", \"American Staffordshire Terrier\",\n",
        "    \"Bedlington Terrier\", \"Border Terrier\", \"Kerry Blue Terrier\", \"Irish Terrier\",\n",
        "    \"Norfolk Terrier\", \"Norwich Terrier\", \"Yorkshire Terrier\", \"Wire Fox Terrier\",\n",
        "    \"Lakeland Terrier\", \"Sealyham Terrier\", \"Airedale Terrier\", \"Cairn Terrier\",\n",
        "    \"Australian Terrier\", \"Dandie Dinmont Terrier\", \"Boston Terrier\", \"Miniature Schnauzer\",\n",
        "    \"Giant Schnauzer\", \"Standard Schnauzer\", \"Scottish Terrier\", \"Tibetan Terrier\",\n",
        "    \"Australian Silky Terrier\", \"Soft-coated Wheaten Terrier\", \"West Highland White Terrier\",\n",
        "    \"Lhasa Apso\", \"Flat-Coated Retriever\", \"Curly-coated Retriever\", \"Golden Retriever\",\n",
        "    \"Labrador Retriever\", \"Chesapeake Bay Retriever\", \"German Shorthaired Pointer\", \"Vizsla\",\n",
        "    \"English Setter\", \"Irish Setter\", \"Gordon Setter\", \"Brittany dog\", \"Clumber Spaniel\",\n",
        "    \"English Springer Spaniel\", \"Welsh Springer Spaniel\", \"Cocker Spaniel\", \"Sussex Spaniel\",\n",
        "    \"Irish Water Spaniel\", \"Kuvasz\", \"Schipperke\", \"Groenendael dog\", \"Malinois\", \"Briard\",\n",
        "    \"Australian Kelpie\", \"Komondor\", \"Old English Sheepdog\", \"Shetland Sheepdog\", \"collie\",\n",
        "    \"Border Collie\", \"Bouvier des Flandres dog\", \"Rottweiler\", \"German Shepherd Dog\", \"Dobermann\",\n",
        "    \"Miniature Pinscher\", \"Greater Swiss Mountain Dog\", \"Bernese Mountain Dog\",\n",
        "    \"Appenzeller Sennenhund\", \"Entlebucher Sennenhund\", \"Boxer\", \"Bullmastiff\", \"Tibetan Mastiff\",\n",
        "    \"French Bulldog\", \"Great Dane\", \"St. Bernard\", \"husky\", \"Alaskan Malamute\", \"Siberian Husky\",\n",
        "    \"Dalmatian\", \"Affenpinscher\", \"Basenji\", \"pug\", \"Leonberger\", \"Newfoundland dog\",\n",
        "    \"Great Pyrenees dog\", \"Samoyed\", \"Pomeranian\", \"Chow Chow\", \"Keeshond\", \"brussels griffon\",\n",
        "    \"Pembroke Welsh Corgi\", \"Cardigan Welsh Corgi\", \"Toy Poodle\", \"Miniature Poodle\",\n",
        "    \"Standard Poodle\", \"Mexican hairless dog (xoloitzcuintli)\", \"grey wolf\", \"Alaskan tundra wolf\",\n",
        "    \"red wolf or maned wolf\", \"coyote\", \"dingo\", \"dhole\", \"African wild dog\", \"hyena\", \"red fox\",\n",
        "    \"kit fox\", \"Arctic fox\", \"grey fox\", \"tabby cat\", \"tiger cat\", \"Persian cat\", \"Siamese cat\",\n",
        "    \"Egyptian Mau\", \"cougar\", \"lynx\", \"leopard\", \"snow leopard\", \"jaguar\", \"lion\", \"tiger\",\n",
        "    \"cheetah\", \"brown bear\", \"American black bear\", \"polar bear\", \"sloth bear\", \"mongoose\",\n",
        "    \"meerkat\", \"tiger beetle\", \"ladybug\", \"ground beetle\", \"longhorn beetle\", \"leaf beetle\",\n",
        "    \"dung beetle\", \"rhinoceros beetle\", \"weevil\", \"fly\", \"bee\", \"ant\", \"grasshopper\",\n",
        "    \"cricket insect\", \"stick insect\", \"cockroach\", \"praying mantis\", \"cicada\", \"leafhopper\",\n",
        "    \"lacewing\", \"dragonfly\", \"damselfly\", \"red admiral butterfly\", \"ringlet butterfly\",\n",
        "    \"monarch butterfly\", \"small white butterfly\", \"sulphur butterfly\", \"gossamer-winged butterfly\",\n",
        "    \"starfish\", \"sea urchin\", \"sea cucumber\", \"cottontail rabbit\", \"hare\", \"Angora rabbit\",\n",
        "    \"hamster\", \"porcupine\", \"fox squirrel\", \"marmot\", \"beaver\", \"guinea pig\", \"common sorrel horse\",\n",
        "    \"zebra\", \"pig\", \"wild boar\", \"warthog\", \"hippopotamus\", \"ox\", \"water buffalo\", \"bison\",\n",
        "    \"ram (adult male sheep)\", \"bighorn sheep\", \"Alpine ibex\", \"hartebeest\", \"impala (antelope)\",\n",
        "    \"gazelle\", \"arabian camel\", \"llama\", \"weasel\", \"mink\", \"European polecat\",\n",
        "    \"black-footed ferret\", \"otter\", \"skunk\", \"badger\", \"armadillo\", \"three-toed sloth\", \"orangutan\",\n",
        "    \"gorilla\", \"chimpanzee\", \"gibbon\", \"siamang\", \"guenon\", \"patas monkey\", \"baboon\", \"macaque\",\n",
        "    \"langur\", \"black-and-white colobus\", \"proboscis monkey\", \"marmoset\", \"white-headed capuchin\",\n",
        "    \"howler monkey\", \"titi monkey\", \"Geoffroy's spider monkey\", \"common squirrel monkey\",\n",
        "    \"ring-tailed lemur\", \"indri\", \"Asian elephant\", \"African bush elephant\", \"red panda\",\n",
        "    \"giant panda\", \"snoek fish\", \"eel\", \"silver salmon\", \"rock beauty fish\", \"clownfish\",\n",
        "    \"sturgeon\", \"gar fish\", \"lionfish\", \"pufferfish\", \"abacus\", \"abaya\", \"academic gown\",\n",
        "    \"accordion\", \"acoustic guitar\", \"aircraft carrier\", \"airliner\", \"airship\", \"altar\", \"ambulance\",\n",
        "    \"amphibious vehicle\", \"analog clock\", \"apiary\", \"apron\", \"trash can\", \"assault rifle\",\n",
        "    \"backpack\", \"bakery\", \"balance beam\", \"balloon\", \"ballpoint pen\", \"Band-Aid\", \"banjo\",\n",
        "    \"baluster / handrail\", \"barbell\", \"barber chair\", \"barbershop\", \"barn\", \"barometer\", \"barrel\",\n",
        "    \"wheelbarrow\", \"baseball\", \"basketball\", \"bassinet\", \"bassoon\", \"swimming cap\", \"bath towel\",\n",
        "    \"bathtub\", \"station wagon\", \"lighthouse\", \"beaker\", \"military hat (bearskin or shako)\",\n",
        "    \"beer bottle\", \"beer glass\", \"bell tower\", \"baby bib\", \"tandem bicycle\", \"bikini\",\n",
        "    \"ring binder\", \"binoculars\", \"birdhouse\", \"boathouse\", \"bobsleigh\", \"bolo tie\", \"poke bonnet\",\n",
        "    \"bookcase\", \"bookstore\", \"bottle cap\", \"hunting bow\", \"bow tie\", \"brass memorial plaque\", \"bra\",\n",
        "    \"breakwater\", \"breastplate\", \"broom\", \"bucket\", \"buckle\", \"bulletproof vest\",\n",
        "    \"high-speed train\", \"butcher shop\", \"taxicab\", \"cauldron\", \"candle\", \"cannon\", \"canoe\",\n",
        "    \"can opener\", \"cardigan\", \"car mirror\", \"carousel\", \"tool kit\", \"cardboard box / carton\",\n",
        "    \"car wheel\", \"automated teller machine\", \"cassette\", \"cassette player\", \"castle\", \"catamaran\",\n",
        "    \"CD player\", \"cello\", \"mobile phone\", \"chain\", \"chain-link fence\", \"chain mail\", \"chainsaw\",\n",
        "    \"storage chest\", \"chiffonier\", \"bell or wind chime\", \"china cabinet\", \"Christmas stocking\",\n",
        "    \"church\", \"movie theater\", \"cleaver\", \"cliff dwelling\", \"cloak\", \"clogs\", \"cocktail shaker\",\n",
        "    \"coffee mug\", \"coffeemaker\", \"spiral or coil\", \"combination lock\", \"computer keyboard\",\n",
        "    \"candy store\", \"container ship\", \"convertible\", \"corkscrew\", \"cornet\", \"cowboy boot\",\n",
        "    \"cowboy hat\", \"cradle\", \"construction crane\", \"crash helmet\", \"crate\", \"infant bed\",\n",
        "    \"Crock Pot\", \"croquet ball\", \"crutch\", \"cuirass\", \"dam\", \"desk\", \"desktop computer\",\n",
        "    \"rotary dial telephone\", \"diaper\", \"digital clock\", \"digital watch\", \"dining table\",\n",
        "    \"dishcloth\", \"dishwasher\", \"disc brake\", \"dock\", \"dog sled\", \"dome\", \"doormat\", \"drilling rig\",\n",
        "    \"drum\", \"drumstick\", \"dumbbell\", \"Dutch oven\", \"electric fan\", \"electric guitar\",\n",
        "    \"electric locomotive\", \"entertainment center\", \"envelope\", \"espresso machine\", \"face powder\",\n",
        "    \"feather boa\", \"filing cabinet\", \"fireboat\", \"fire truck\", \"fire screen\", \"flagpole\", \"flute\",\n",
        "    \"folding chair\", \"football helmet\", \"forklift\", \"fountain\", \"fountain pen\", \"four-poster bed\",\n",
        "    \"freight car\", \"French horn\", \"frying pan\", \"fur coat\", \"garbage truck\",\n",
        "    \"gas mask or respirator\", \"gas pump\", \"goblet\", \"go-kart\", \"golf ball\", \"golf cart\", \"gondola\",\n",
        "    \"gong\", \"gown\", \"grand piano\", \"greenhouse\", \"radiator grille\", \"grocery store\", \"guillotine\",\n",
        "    \"hair clip\", \"hair spray\", \"half-track\", \"hammer\", \"hamper\", \"hair dryer\", \"hand-held computer\",\n",
        "    \"handkerchief\", \"hard disk drive\", \"harmonica\", \"harp\", \"combine harvester\", \"hatchet\",\n",
        "    \"holster\", \"home theater\", \"honeycomb\", \"hook\", \"hoop skirt\", \"gymnastic horizontal bar\",\n",
        "    \"horse-drawn vehicle\", \"hourglass\", \"iPod\", \"clothes iron\", \"carved pumpkin\", \"jeans\", \"jeep\",\n",
        "    \"T-shirt\", \"jigsaw puzzle\", \"rickshaw\", \"joystick\", \"kimono\", \"knee pad\", \"knot\", \"lab coat\",\n",
        "    \"ladle\", \"lampshade\", \"laptop computer\", \"lawn mower\", \"lens cap\", \"letter opener\", \"library\",\n",
        "    \"lifeboat\", \"lighter\", \"limousine\", \"ocean liner\", \"lipstick\", \"slip-on shoe\", \"lotion\",\n",
        "    \"music speaker\", \"loupe magnifying glass\", \"sawmill\", \"magnetic compass\", \"messenger bag\",\n",
        "    \"mailbox\", \"tights\", \"one-piece bathing suit\", \"manhole cover\", \"maraca\", \"marimba\", \"mask\",\n",
        "    \"matchstick\", \"maypole\", \"maze\", \"measuring cup\", \"medicine cabinet\", \"megalith\", \"microphone\",\n",
        "    \"microwave oven\", \"military uniform\", \"milk can\", \"minibus\", \"miniskirt\", \"minivan\", \"missile\",\n",
        "    \"mitten\", \"mixing bowl\", \"mobile home\", \"ford model t\", \"modem\", \"monastery\", \"monitor\",\n",
        "    \"moped\", \"mortar and pestle\", \"graduation cap\", \"mosque\", \"mosquito net\", \"vespa\",\n",
        "    \"mountain bike\", \"tent\", \"computer mouse\", \"mousetrap\", \"moving van\", \"muzzle\", \"metal nail\",\n",
        "    \"neck brace\", \"necklace\", \"baby pacifier\", \"notebook computer\", \"obelisk\", \"oboe\", \"ocarina\",\n",
        "    \"odometer\", \"oil filter\", \"pipe organ\", \"oscilloscope\", \"overskirt\", \"bullock cart\",\n",
        "    \"oxygen mask\", \"product packet / packaging\", \"paddle\", \"paddle wheel\", \"padlock\", \"paintbrush\",\n",
        "    \"pajamas\", \"palace\", \"pan flute\", \"paper towel\", \"parachute\", \"parallel bars\", \"park bench\",\n",
        "    \"parking meter\", \"railroad car\", \"patio\", \"payphone\", \"pedestal\", \"pencil case\",\n",
        "    \"pencil sharpener\", \"perfume\", \"Petri dish\", \"photocopier\", \"plectrum\", \"Pickelhaube\",\n",
        "    \"picket fence\", \"pickup truck\", \"pier\", \"piggy bank\", \"pill bottle\", \"pillow\", \"ping-pong ball\",\n",
        "    \"pinwheel\", \"pirate ship\", \"drink pitcher\", \"block plane\", \"planetarium\", \"plastic bag\",\n",
        "    \"plate rack\", \"farm plow\", \"plunger\", \"Polaroid camera\", \"pole\", \"police van\", \"poncho\",\n",
        "    \"pool table\", \"soda bottle\", \"plant pot\", \"potter's wheel\", \"power drill\", \"prayer rug\",\n",
        "    \"printer\", \"prison\", \"missile\", \"projector\", \"hockey puck\", \"punching bag\", \"purse\", \"quill\",\n",
        "    \"quilt\", \"race car\", \"racket\", \"radiator\", \"radio\", \"radio telescope\", \"rain barrel\",\n",
        "    \"recreational vehicle\", \"fishing casting reel\", \"reflex camera\", \"refrigerator\",\n",
        "    \"remote control\", \"restaurant\", \"revolver\", \"rifle\", \"rocking chair\", \"rotisserie\", \"eraser\",\n",
        "    \"rugby ball\", \"ruler measuring stick\", \"sneaker\", \"safe\", \"safety pin\", \"salt shaker\", \"sandal\",\n",
        "    \"sarong\", \"saxophone\", \"scabbard\", \"weighing scale\", \"school bus\", \"schooner\", \"scoreboard\",\n",
        "    \"CRT monitor\", \"screw\", \"screwdriver\", \"seat belt\", \"sewing machine\", \"shield\", \"shoe store\",\n",
        "    \"shoji screen / room divider\", \"shopping basket\", \"shopping cart\", \"shovel\", \"shower cap\",\n",
        "    \"shower curtain\", \"ski\", \"balaclava ski mask\", \"sleeping bag\", \"slide rule\", \"sliding door\",\n",
        "    \"slot machine\", \"snorkel\", \"snowmobile\", \"snowplow\", \"soap dispenser\", \"soccer ball\", \"sock\",\n",
        "    \"solar thermal collector\", \"sombrero\", \"soup bowl\", \"keyboard space bar\", \"space heater\",\n",
        "    \"space shuttle\", \"spatula\", \"motorboat\", \"spider web\", \"spindle\", \"sports car\", \"spotlight\",\n",
        "    \"stage\", \"steam locomotive\", \"through arch bridge\", \"steel drum\", \"stethoscope\", \"scarf\",\n",
        "    \"stone wall\", \"stopwatch\", \"stove\", \"strainer\", \"tram\", \"stretcher\", \"couch\", \"stupa\",\n",
        "    \"submarine\", \"suit\", \"sundial\", \"sunglasses\", \"sunglasses\", \"sunscreen\", \"suspension bridge\",\n",
        "    \"mop\", \"sweatshirt\", \"swim trunks / shorts\", \"swing\", \"electrical switch\", \"syringe\",\n",
        "    \"table lamp\", \"tank\", \"tape player\", \"teapot\", \"teddy bear\", \"television\", \"tennis ball\",\n",
        "    \"thatched roof\", \"front curtain\", \"thimble\", \"threshing machine\", \"throne\", \"tile roof\",\n",
        "    \"toaster\", \"tobacco shop\", \"toilet seat\", \"torch\", \"totem pole\", \"tow truck\", \"toy store\",\n",
        "    \"tractor\", \"semi-trailer truck\", \"tray\", \"trench coat\", \"tricycle\", \"trimaran\", \"tripod\",\n",
        "    \"triumphal arch\", \"trolleybus\", \"trombone\", \"hot tub\", \"turnstile\", \"typewriter keyboard\",\n",
        "    \"umbrella\", \"unicycle\", \"upright piano\", \"vacuum cleaner\", \"vase\", \"vaulted or arched ceiling\",\n",
        "    \"velvet fabric\", \"vending machine\", \"vestment\", \"viaduct\", \"violin\", \"volleyball\",\n",
        "    \"waffle iron\", \"wall clock\", \"wallet\", \"wardrobe\", \"military aircraft\", \"sink\",\n",
        "    \"washing machine\", \"water bottle\", \"water jug\", \"water tower\", \"whiskey jug\", \"whistle\",\n",
        "    \"hair wig\", \"window screen\", \"window shade\", \"Windsor tie\", \"wine bottle\", \"airplane wing\",\n",
        "    \"wok\", \"wooden spoon\", \"wool\", \"split-rail fence\", \"shipwreck\", \"sailboat\", \"yurt\", \"website\",\n",
        "    \"comic book\", \"crossword\", \"traffic or street sign\", \"traffic light\", \"dust jacket\", \"menu\",\n",
        "    \"plate\", \"guacamole\", \"consomme\", \"hot pot\", \"trifle\", \"ice cream\", \"popsicle\", \"baguette\",\n",
        "    \"bagel\", \"pretzel\", \"cheeseburger\", \"hot dog\", \"mashed potatoes\", \"cabbage\", \"broccoli\",\n",
        "    \"cauliflower\", \"zucchini\", \"spaghetti squash\", \"acorn squash\", \"butternut squash\", \"cucumber\",\n",
        "    \"artichoke\", \"bell pepper\", \"cardoon\", \"mushroom\", \"Granny Smith apple\", \"strawberry\", \"orange\",\n",
        "    \"lemon\", \"fig\", \"pineapple\", \"banana\", \"jackfruit\", \"cherimoya (custard apple)\", \"pomegranate\",\n",
        "    \"hay\", \"carbonara\", \"chocolate syrup\", \"dough\", \"meatloaf\", \"pizza\", \"pot pie\", \"burrito\",\n",
        "    \"red wine\", \"espresso\", \"tea cup\", \"eggnog\", \"mountain\", \"bubble\", \"cliff\", \"coral reef\",\n",
        "    \"geyser\", \"lakeshore\", \"promontory\", \"sandbar\", \"beach\", \"valley\", \"volcano\", \"baseball player\",\n",
        "    \"bridegroom\", \"scuba diver\", \"rapeseed\", \"daisy\", \"yellow lady's slipper\", \"corn\", \"acorn\",\n",
        "    \"rose hip\", \"horse chestnut seed\", \"coral fungus\", \"agaric\", \"gyromitra\", \"stinkhorn mushroom\",\n",
        "    \"earth star fungus\", \"hen of the woods mushroom\", \"bolete\", \"corn cob\", \"toilet paper\"\n",
        "]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eMQSCuBta2G6"
      },
      "source": [
        "A subset of these class names are modified from the default ImageNet class names sourced from Anish Athalye's imagenet-simple-labels.\n",
        "\n",
        "These edits were made via trial and error and concentrated on the lowest performing classes according to top_1 and top_5 accuracy on the ImageNet training set for the RN50, RN101, and RN50x4 models. These tweaks improve top_1 by 1.5% on ViT-B/32 over using the default class names. Alec got bored somewhere along the way as gains started to diminish and never finished updating / tweaking the list. He also didn't revisit this with the better performing RN50x16, RN50x64, or any of the ViT models. He thinks it's likely another 0.5% to 1% top_1 could be gained from further work here. It'd be interesting to more rigorously study / understand this.\n",
        "\n",
        "Some examples beyond the crane/crane -> construction crane / bird crane issue mentioned in Section 3.1.4 of the paper include:\n",
        "\n",
        "- CLIP interprets \"nail\" as \"fingernail\" so we changed the label to \"metal nail\".\n",
        "- ImageNet kite class refers to the bird of prey, not the flying toy, so we changed \"kite\" to \"kite (bird of prey)\"\n",
        "- The ImageNet class for red wolf seems to include a lot of mislabeled maned wolfs so we changed \"red wolf\" to \"red wolf or maned wolf\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "toGtcd-Ji_MD",
        "outputId": "b6eb0753-2bee-4144-abe3-fbd23f35f555"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1000 classes, 80 templates\n"
          ]
        }
      ],
      "source": [
        "imagenet_templates = [\n",
        "    'a bad photo of a {}.',\n",
        "    'a photo of many {}.',\n",
        "    'a sculpture of a {}.',\n",
        "    'a photo of the hard to see {}.',\n",
        "    'a low resolution photo of the {}.',\n",
        "    'a rendering of a {}.',\n",
        "    'graffiti of a {}.',\n",
        "    'a bad photo of the {}.',\n",
        "    'a cropped photo of the {}.',\n",
        "    'a tattoo of a {}.',\n",
        "    'the embroidered {}.',\n",
        "    'a photo of a hard to see {}.',\n",
        "    'a bright photo of a {}.',\n",
        "    'a photo of a clean {}.',\n",
        "    'a photo of a dirty {}.',\n",
        "    'a dark photo of the {}.',\n",
        "    'a drawing of a {}.',\n",
        "    'a photo of my {}.',\n",
        "    'the plastic {}.',\n",
        "    'a photo of the cool {}.',\n",
        "    'a close-up photo of a {}.',\n",
        "    'a black and white photo of the {}.',\n",
        "    'a painting of the {}.',\n",
        "    'a painting of a {}.',\n",
        "    'a pixelated photo of the {}.',\n",
        "    'a sculpture of the {}.',\n",
        "    'a bright photo of the {}.',\n",
        "    'a cropped photo of a {}.',\n",
        "    'a plastic {}.',\n",
        "    'a photo of the dirty {}.',\n",
        "    'a jpeg corrupted photo of a {}.',\n",
        "    'a blurry photo of the {}.',\n",
        "    'a photo of the {}.',\n",
        "    'a good photo of the {}.',\n",
        "    'a rendering of the {}.',\n",
        "    'a {} in a video game.',\n",
        "    'a photo of one {}.',\n",
        "    'a doodle of a {}.',\n",
        "    'a close-up photo of the {}.',\n",
        "    'a photo of a {}.',\n",
        "    'the origami {}.',\n",
        "    'the {} in a video game.',\n",
        "    'a sketch of a {}.',\n",
        "    'a doodle of the {}.',\n",
        "    'a origami {}.',\n",
        "    'a low resolution photo of a {}.',\n",
        "    'the toy {}.',\n",
        "    'a rendition of the {}.',\n",
        "    'a photo of the clean {}.',\n",
        "    'a photo of a large {}.',\n",
        "    'a rendition of a {}.',\n",
        "    'a photo of a nice {}.',\n",
        "    'a photo of a weird {}.',\n",
        "    'a blurry photo of a {}.',\n",
        "    'a cartoon {}.',\n",
        "    'art of a {}.',\n",
        "    'a sketch of the {}.',\n",
        "    'a embroidered {}.',\n",
        "    'a pixelated photo of a {}.',\n",
        "    'itap of the {}.',\n",
        "    'a jpeg corrupted photo of the {}.',\n",
        "    'a good photo of a {}.',\n",
        "    'a plushie {}.',\n",
        "    'a photo of the nice {}.',\n",
        "    'a photo of the small {}.',\n",
        "    'a photo of the weird {}.',\n",
        "    'the cartoon {}.',\n",
        "    'art of the {}.',\n",
        "    'a drawing of the {}.',\n",
        "    'a photo of the large {}.',\n",
        "    'a black and white photo of a {}.',\n",
        "    'the plushie {}.',\n",
        "    'a dark photo of a {}.',\n",
        "    'itap of a {}.',\n",
        "    'graffiti of the {}.',\n",
        "    'a toy {}.',\n",
        "    'itap of my {}.',\n",
        "    'a photo of a cool {}.',\n",
        "    'a photo of a small {}.',\n",
        "    'a tattoo of the {}.',\n",
        "]\n",
        "\n",
        "print(f\"{len(imagenet_classes)} classes, {len(imagenet_templates)} templates\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aRB5OzgpHwqQ"
      },
      "source": [
        "A similar, intuition-guided trial and error based on the ImageNet training set was used for templates. This list is pretty haphazard and was gradually made / expanded over the course of about a year of the project and was revisited / tweaked every few months. A surprising / weird thing was adding templates intended to help ImageNet-R performance (specifying different possible renditions of an object) improved standard ImageNet accuracy too.\n",
        "\n",
        "After the 80 templates were \"locked\" for the paper, we ran sequential forward selection over the list of 80 templates. The search terminated after ensembling 7 templates and selected them in the order below.\n",
        "\n",
        "1. itap of a {}.\n",
        "2. a bad photo of the {}.\n",
        "3. a origami {}.\n",
        "4. a photo of the large {}.\n",
        "5. a {} in a video game.\n",
        "6. art of the {}.\n",
        "7. a photo of the small {}.\n",
        "\n",
        "Speculating, we think it's interesting to see different scales (large and small), a difficult view (a bad photo), and \"abstract\" versions (origami, video game, art), were all selected for, but we haven't studied this in any detail. This subset performs a bit better than the full 80 ensemble reported in the paper, especially for the smaller models."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4W8ARJVqBJXs"
      },
      "source": [
        "# Loading the Images\n",
        "\n",
        "The ILSVRC2012 datasets are no longer available for download publicly. We instead download the ImageNet-V2 dataset by [Recht et al.](https://arxiv.org/abs/1902.10811).\n",
        "\n",
        "If you have the ImageNet dataset downloaded, you can replace the dataset with the official torchvision loader, e.g.:\n",
        "\n",
        "```python\n",
        "images = torchvision.datasets.ImageNet(\"path/to/imagenet\", split='val', transform=preprocess)\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "moHR4UlHKsDc",
        "outputId": "40731297-edc7-4cd0-be75-ed426c8fb005"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting git+https://github.com/modestyachts/ImageNetV2_pytorch\n",
            "  Cloning https://github.com/modestyachts/ImageNetV2_pytorch to /tmp/pip-req-build-cxywdek7\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/modestyachts/ImageNetV2_pytorch /tmp/pip-req-build-cxywdek7\n",
            "  Resolved https://github.com/modestyachts/ImageNetV2_pytorch to commit 14d4456c39fe7f02a665544dd9fc37c1a5f8b635\n",
            "  Installing build dependencies ... \u001b[?25ldone\n",
            "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
            "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "! pip install git+https://github.com/modestyachts/ImageNetV2_pytorch\n",
        "\n",
        "from imagenetv2_pytorch import ImageNetV2Dataset\n",
        "\n",
        "images = ImageNetV2Dataset(transform=preprocess)\n",
        "loader = torch.utils.data.DataLoader(images, batch_size=32, num_workers=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting ipywidgets\n",
            "  Downloading ipywidgets-8.1.7-py3-none-any.whl.metadata (2.4 kB)\n",
            "Requirement already satisfied: comm>=0.1.3 in ./.venv/lib/python3.12/site-packages (from ipywidgets) (0.2.2)\n",
            "Requirement already satisfied: ipython>=6.1.0 in ./.venv/lib/python3.12/site-packages (from ipywidgets) (9.3.0)\n",
            "Requirement already satisfied: traitlets>=4.3.1 in ./.venv/lib/python3.12/site-packages (from ipywidgets) (5.14.3)\n",
            "Collecting widgetsnbextension~=4.0.14 (from ipywidgets)\n",
            "  Downloading widgetsnbextension-4.0.14-py3-none-any.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: jupyterlab_widgets~=3.0.15 in ./.venv/lib/python3.12/site-packages (from ipywidgets) (3.0.15)\n",
            "Requirement already satisfied: decorator in ./.venv/lib/python3.12/site-packages (from ipython>=6.1.0->ipywidgets) (5.2.1)\n",
            "Requirement already satisfied: ipython-pygments-lexers in ./.venv/lib/python3.12/site-packages (from ipython>=6.1.0->ipywidgets) (1.1.1)\n",
            "Requirement already satisfied: jedi>=0.16 in ./.venv/lib/python3.12/site-packages (from ipython>=6.1.0->ipywidgets) (0.19.2)\n",
            "Requirement already satisfied: matplotlib-inline in ./.venv/lib/python3.12/site-packages (from ipython>=6.1.0->ipywidgets) (0.1.7)\n",
            "Requirement already satisfied: pexpect>4.3 in ./.venv/lib/python3.12/site-packages (from ipython>=6.1.0->ipywidgets) (4.9.0)\n",
            "Requirement already satisfied: prompt_toolkit<3.1.0,>=3.0.41 in ./.venv/lib/python3.12/site-packages (from ipython>=6.1.0->ipywidgets) (3.0.51)\n",
            "Requirement already satisfied: pygments>=2.4.0 in ./.venv/lib/python3.12/site-packages (from ipython>=6.1.0->ipywidgets) (2.19.1)\n",
            "Requirement already satisfied: stack_data in ./.venv/lib/python3.12/site-packages (from ipython>=6.1.0->ipywidgets) (0.6.3)\n",
            "Requirement already satisfied: wcwidth in ./.venv/lib/python3.12/site-packages (from prompt_toolkit<3.1.0,>=3.0.41->ipython>=6.1.0->ipywidgets) (0.2.13)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.4 in ./.venv/lib/python3.12/site-packages (from jedi>=0.16->ipython>=6.1.0->ipywidgets) (0.8.4)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in ./.venv/lib/python3.12/site-packages (from pexpect>4.3->ipython>=6.1.0->ipywidgets) (0.7.0)\n",
            "Requirement already satisfied: executing>=1.2.0 in ./.venv/lib/python3.12/site-packages (from stack_data->ipython>=6.1.0->ipywidgets) (2.2.0)\n",
            "Requirement already satisfied: asttokens>=2.1.0 in ./.venv/lib/python3.12/site-packages (from stack_data->ipython>=6.1.0->ipywidgets) (3.0.0)\n",
            "Requirement already satisfied: pure-eval in ./.venv/lib/python3.12/site-packages (from stack_data->ipython>=6.1.0->ipywidgets) (0.2.3)\n",
            "Downloading ipywidgets-8.1.7-py3-none-any.whl (139 kB)\n",
            "Downloading widgetsnbextension-4.0.14-py3-none-any.whl (2.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m12.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: widgetsnbextension, ipywidgets\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2/2\u001b[0m [ipywidgets]2\u001b[0m [ipywidgets]\n",
            "\u001b[1A\u001b[2KSuccessfully installed ipywidgets-8.1.7 widgetsnbextension-4.0.14\n"
          ]
        }
      ],
      "source": [
        "!pip install ipywidgets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "usage: jupyter [-h] [--version] [--config-dir] [--data-dir] [--runtime-dir]\n",
            "               [--paths] [--json] [--debug]\n",
            "               [subcommand]\n",
            "\n",
            "Jupyter: Interactive Computing\n",
            "\n",
            "positional arguments:\n",
            "  subcommand     the subcommand to launch\n",
            "\n",
            "options:\n",
            "  -h, --help     show this help message and exit\n",
            "  --version      show the versions of core jupyter packages and exit\n",
            "  --config-dir   show Jupyter config dir\n",
            "  --data-dir     show Jupyter data dir\n",
            "  --runtime-dir  show Jupyter runtime dir\n",
            "  --paths        show all Jupyter paths. Add --json for machine-readable\n",
            "                 format.\n",
            "  --json         output paths as machine-readable json\n",
            "  --debug        output debug information about paths\n",
            "\n",
            "Available subcommands: kernel kernelspec migrate run troubleshoot\n",
            "\n",
            "Jupyter command `jupyter-nbextension` not found.\n"
          ]
        }
      ],
      "source": [
        "!jupyter nbextension enable --py widgetsnbextension\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fz6D-F-Wbrtp"
      },
      "source": [
        "# Creating zero-shot classifier weights"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67,
          "referenced_widgets": [
            "66a1639713ae441d8a9b873381f9d774",
            "610b775178c645e2b4663b77cc0c67b6",
            "412dd15f0d8542f5ab2730f8616fb582",
            "5e6315f36b4e4eeea5c6294b024e0c97",
            "085d5388abda4202bfa66d0c088452f8",
            "f75124b64aa147c693c67a78f8e3a231",
            "6e5676a054874243b55fc6d120a07d01",
            "dc6d1416c01a4047935ee15c3fd2eb1c"
          ]
        },
        "id": "sRqDoz1Gbsii",
        "outputId": "312b8ebf-3961-4903-d8cb-3b7a94cc97b6"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "fa5cf4c752e44537875b2b4c74cde644",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/1000 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "def zeroshot_classifier(classnames, templates):\n",
        "    with torch.no_grad():\n",
        "        zeroshot_weights = []\n",
        "        for classname in tqdm(classnames):\n",
        "            texts = [template.format(classname) for template in templates] #format with class\n",
        "            texts = clip.tokenize(texts).cuda() #tokenize\n",
        "            class_embeddings = model.encode_text(texts) #embed with text encoder\n",
        "            class_embeddings /= class_embeddings.norm(dim=-1, keepdim=True)\n",
        "            class_embedding = class_embeddings.mean(dim=0)\n",
        "            class_embedding /= class_embedding.norm()\n",
        "            zeroshot_weights.append(class_embedding)\n",
        "        zeroshot_weights = torch.stack(zeroshot_weights, dim=1).cuda()\n",
        "    return zeroshot_weights\n",
        "\n",
        "\n",
        "zeroshot_weights = zeroshot_classifier(imagenet_classes, imagenet_templates)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1fZo7hG8iJP5"
      },
      "source": [
        "# Zero-shot prediction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "j4kPSZoShQxN"
      },
      "outputs": [],
      "source": [
        "def accuracy(output, target, topk=(1,)):\n",
        "    pred = output.topk(max(topk), 1, True, True)[1].t()\n",
        "    correct = pred.eq(target.view(1, -1).expand_as(pred))\n",
        "    return [float(correct[:k].reshape(-1).float().sum(0, keepdim=True).cpu().numpy()) for k in topk]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102,
          "referenced_widgets": [
            "84f80a7f3e764346969a347b0f71b24e",
            "392656f01b2945f3bd7903783ed8cc96",
            "8e47a435519b4ce090879b4be2f61f99",
            "41b1ed6b0a9745c1a595377670b15ff4",
            "179b8ae1eb7f4a828f953e889b141725",
            "d8708e8414fd44f4abd6590c9b57996f",
            "800e30f5b4f24475a2b0046da0703631",
            "8764308b948745f1a677332fd21fcaf0"
          ]
        },
        "id": "wKJ7YsdlkDXo",
        "outputId": "ab824854-38e4-4d37-ad40-2a7ce3c5fd43"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f13dc721416c4c01a9c033d573eac7f1",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/313 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipykernel_3746513/2288536226.py:4: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
            "  return [float(correct[:k].reshape(-1).float().sum(0, keepdim=True).cpu().numpy()) for k in topk]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Top-1 accuracy: 55.90\n",
            "Top-5 accuracy: 83.42\n"
          ]
        }
      ],
      "source": [
        "with torch.no_grad():\n",
        "    top1, top5, n = 0., 0., 0.\n",
        "    for i, (images, target) in enumerate(tqdm(loader)):\n",
        "        images = images.cuda()\n",
        "        target = target.cuda()\n",
        "        \n",
        "        # predict\n",
        "        image_features = model.encode_image(images)\n",
        "        image_features /= image_features.norm(dim=-1, keepdim=True)\n",
        "        logits = 100. * image_features @ zeroshot_weights\n",
        "\n",
        "        # measure accuracy\n",
        "        acc1, acc5 = accuracy(logits, target, topk=(1, 5))\n",
        "        top1 += acc1\n",
        "        top5 += acc5\n",
        "        n += images.size(0)\n",
        "\n",
        "top1 = (top1 / n) * 100\n",
        "top5 = (top5 / n) * 100 \n",
        "\n",
        "print(f\"Top-1 accuracy: {top1:.2f}\")\n",
        "print(f\"Top-5 accuracy: {top5:.2f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting scipy\n",
            "  Downloading scipy-1.15.3-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
            "Requirement already satisfied: numpy<2.5,>=1.23.5 in ./.venv/lib/python3.12/site-packages (from scipy) (2.3.0)\n",
            "Downloading scipy-1.15.3-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (37.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m37.3/37.3 MB\u001b[0m \u001b[31m54.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: scipy\n",
            "Successfully installed scipy-1.15.3\n"
          ]
        }
      ],
      "source": [
        "!pip install scipy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "ename": "RuntimeError",
          "evalue": "The archive ILSVRC2012_devkit_t12.tar.gz is not present in the root directory or is corrupted. You need to download it externally and place it in ./data.",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorchvision\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m datasets, transforms\n\u001b[32m      3\u001b[39m \u001b[38;5;66;03m# Télécharge automatiquement ImageNet (nécessite un compte)\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m dataset = \u001b[43mdatasets\u001b[49m\u001b[43m.\u001b[49m\u001b[43mImageNet\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      5\u001b[39m \u001b[43m    \u001b[49m\u001b[43mroot\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43m./data\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[32m      6\u001b[39m \u001b[43m    \u001b[49m\u001b[43msplit\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mval\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      7\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdownload\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m      8\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtransform\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtransforms\u001b[49m\u001b[43m.\u001b[49m\u001b[43mToTensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      9\u001b[39m \u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Projet-IA-Fairness/.venv/lib/python3.12/site-packages/torchvision/datasets/imagenet.py:55\u001b[39m, in \u001b[36mImageNet.__init__\u001b[39m\u001b[34m(self, root, split, **kwargs)\u001b[39m\n\u001b[32m     52\u001b[39m root = \u001b[38;5;28mself\u001b[39m.root = os.path.expanduser(root)\n\u001b[32m     53\u001b[39m \u001b[38;5;28mself\u001b[39m.split = verify_str_arg(split, \u001b[33m\"\u001b[39m\u001b[33msplit\u001b[39m\u001b[33m\"\u001b[39m, (\u001b[33m\"\u001b[39m\u001b[33mtrain\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mval\u001b[39m\u001b[33m\"\u001b[39m))\n\u001b[32m---> \u001b[39m\u001b[32m55\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mparse_archives\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     56\u001b[39m wnid_to_classes = load_meta_file(\u001b[38;5;28mself\u001b[39m.root)[\u001b[32m0\u001b[39m]\n\u001b[32m     58\u001b[39m \u001b[38;5;28msuper\u001b[39m().\u001b[34m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m.split_folder, **kwargs)\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Projet-IA-Fairness/.venv/lib/python3.12/site-packages/torchvision/datasets/imagenet.py:68\u001b[39m, in \u001b[36mImageNet.parse_archives\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m     66\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mparse_archives\u001b[39m(\u001b[38;5;28mself\u001b[39m) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m     67\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m check_integrity(os.path.join(\u001b[38;5;28mself\u001b[39m.root, META_FILE)):\n\u001b[32m---> \u001b[39m\u001b[32m68\u001b[39m         \u001b[43mparse_devkit_archive\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mroot\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     70\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m os.path.isdir(\u001b[38;5;28mself\u001b[39m.split_folder):\n\u001b[32m     71\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.split == \u001b[33m\"\u001b[39m\u001b[33mtrain\u001b[39m\u001b[33m\"\u001b[39m:\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Projet-IA-Fairness/.venv/lib/python3.12/site-packages/torchvision/datasets/imagenet.py:149\u001b[39m, in \u001b[36mparse_devkit_archive\u001b[39m\u001b[34m(root, file)\u001b[39m\n\u001b[32m    146\u001b[39m     file = archive_meta[\u001b[32m0\u001b[39m]\n\u001b[32m    147\u001b[39m md5 = archive_meta[\u001b[32m1\u001b[39m]\n\u001b[32m--> \u001b[39m\u001b[32m149\u001b[39m \u001b[43m_verify_archive\u001b[49m\u001b[43m(\u001b[49m\u001b[43mroot\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmd5\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    151\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m get_tmp_dir() \u001b[38;5;28;01mas\u001b[39;00m tmp_dir:\n\u001b[32m    152\u001b[39m     extract_archive(os.path.join(root, file), tmp_dir)\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Projet-IA-Fairness/.venv/lib/python3.12/site-packages/torchvision/datasets/imagenet.py:105\u001b[39m, in \u001b[36m_verify_archive\u001b[39m\u001b[34m(root, file, md5)\u001b[39m\n\u001b[32m    100\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m check_integrity(os.path.join(root, file), md5):\n\u001b[32m    101\u001b[39m     msg = (\n\u001b[32m    102\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mThe archive \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[33m is not present in the root directory or is corrupted. \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    103\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mYou need to download it externally and place it in \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    104\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m105\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(msg.format(file, root))\n",
            "\u001b[31mRuntimeError\u001b[39m: The archive ILSVRC2012_devkit_t12.tar.gz is not present in the root directory or is corrupted. You need to download it externally and place it in ./data."
          ]
        }
      ],
      "source": [
        "from torchvision import datasets, transforms\n",
        "\n",
        "# Télécharge automatiquement ImageNet (nécessite un compte)\n",
        "dataset = datasets.ImageNet(\n",
        "    root='./data', \n",
        "    split='val',\n",
        "    download=True,\n",
        "    transform=transforms.ToTensor()\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting kaggle\n",
            "  Downloading kaggle-1.7.4.5-py3-none-any.whl.metadata (16 kB)\n",
            "Collecting bleach (from kaggle)\n",
            "  Downloading bleach-6.2.0-py3-none-any.whl.metadata (30 kB)\n",
            "Requirement already satisfied: certifi>=14.05.14 in ./.venv/lib/python3.12/site-packages (from kaggle) (2025.4.26)\n",
            "Requirement already satisfied: charset-normalizer in ./.venv/lib/python3.12/site-packages (from kaggle) (3.4.2)\n",
            "Requirement already satisfied: idna in ./.venv/lib/python3.12/site-packages (from kaggle) (3.10)\n",
            "Collecting protobuf (from kaggle)\n",
            "  Downloading protobuf-6.31.1-cp39-abi3-manylinux2014_x86_64.whl.metadata (593 bytes)\n",
            "Requirement already satisfied: python-dateutil>=2.5.3 in ./.venv/lib/python3.12/site-packages (from kaggle) (2.9.0.post0)\n",
            "Collecting python-slugify (from kaggle)\n",
            "  Downloading python_slugify-8.0.4-py2.py3-none-any.whl.metadata (8.5 kB)\n",
            "Requirement already satisfied: requests in ./.venv/lib/python3.12/site-packages (from kaggle) (2.32.4)\n",
            "Requirement already satisfied: setuptools>=21.0.0 in ./.venv/lib/python3.12/site-packages (from kaggle) (80.9.0)\n",
            "Requirement already satisfied: six>=1.10 in ./.venv/lib/python3.12/site-packages (from kaggle) (1.17.0)\n",
            "Collecting text-unidecode (from kaggle)\n",
            "  Downloading text_unidecode-1.3-py2.py3-none-any.whl.metadata (2.4 kB)\n",
            "Requirement already satisfied: tqdm in ./.venv/lib/python3.12/site-packages (from kaggle) (4.67.1)\n",
            "Requirement already satisfied: urllib3>=1.15.1 in ./.venv/lib/python3.12/site-packages (from kaggle) (2.4.0)\n",
            "Collecting webencodings (from kaggle)\n",
            "  Downloading webencodings-0.5.1-py2.py3-none-any.whl.metadata (2.1 kB)\n",
            "Downloading kaggle-1.7.4.5-py3-none-any.whl (181 kB)\n",
            "Downloading bleach-6.2.0-py3-none-any.whl (163 kB)\n",
            "Downloading protobuf-6.31.1-cp39-abi3-manylinux2014_x86_64.whl (321 kB)\n",
            "Downloading python_slugify-8.0.4-py2.py3-none-any.whl (10 kB)\n",
            "Downloading text_unidecode-1.3-py2.py3-none-any.whl (78 kB)\n",
            "Downloading webencodings-0.5.1-py2.py3-none-any.whl (11 kB)\n",
            "Installing collected packages: webencodings, text-unidecode, python-slugify, protobuf, bleach, kaggle\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6/6\u001b[0m [kaggle]2m5/6\u001b[0m [kaggle]f]\n",
            "\u001b[1A\u001b[2KSuccessfully installed bleach-6.2.0 kaggle-1.7.4.5 protobuf-6.31.1 python-slugify-8.0.4 text-unidecode-1.3 webencodings-0.5.1\n"
          ]
        }
      ],
      "source": [
        "!pip install kaggle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "^C\n"
          ]
        }
      ],
      "source": [
        "\n",
        "!kaggle competitions download -c imagenet-object-localization-challenge"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting git+https://github.com/username/Game_MM_CLIP.git\n",
            "  Cloning https://github.com/username/Game_MM_CLIP.git to /tmp/pip-req-build-7dj8o7qy\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/username/Game_MM_CLIP.git /tmp/pip-req-build-7dj8o7qy\n",
            "Username for 'https://github.com': \u001b[31mERROR: Operation cancelled by user\u001b[0m\u001b[31m\n",
            "\u001b[0m^C\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "pip install git+https://github.com/username/Game_MM_CLIP.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Sauvegardé 0 images...\n",
            "Sauvegardé 1000 images...\n",
            "Sauvegardé 2000 images...\n",
            "Sauvegardé 3000 images...\n",
            "Sauvegardé 4000 images...\n",
            "Sauvegardé 5000 images...\n",
            "Sauvegardé 6000 images...\n",
            "Sauvegardé 7000 images...\n",
            "Sauvegardé 8000 images...\n",
            "Sauvegardé 9000 images...\n",
            "Dataset sauvegardé dans imagenetv2_dataset\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torchvision.transforms as transforms\n",
        "from imagenetv2_pytorch import ImageNetV2Dataset\n",
        "import os\n",
        "from PIL import Image\n",
        "\n",
        "# Définir les transformations\n",
        "preprocess = transforms.Compose([\n",
        "    transforms.Resize(256),\n",
        "    transforms.CenterCrop(224),\n",
        "    transforms.ToTensor(),\n",
        "])\n",
        "\n",
        "# Créer le dataset\n",
        "dataset = ImageNetV2Dataset(transform=None)  # Pas de transform pour sauvegarder les images originales\n",
        "\n",
        "# Créer le dossier de destination\n",
        "save_dir = \"imagenetv2_dataset\"\n",
        "os.makedirs(save_dir, exist_ok=True)\n",
        "\n",
        "# Sauvegarder les images\n",
        "for i, (image, label) in enumerate(dataset):\n",
        "    # Créer un sous-dossier pour chaque classe si nécessaire\n",
        "    class_dir = os.path.join(save_dir, f\"class_{label}\")\n",
        "    os.makedirs(class_dir, exist_ok=True)\n",
        "    \n",
        "    # Sauvegarder l'image\n",
        "    image_path = os.path.join(class_dir, f\"image_{i}.jpg\")\n",
        "    image.save(image_path)\n",
        "    \n",
        "    if i % 1000 == 0:\n",
        "        print(f\"Sauvegardé {i} images...\")\n",
        "\n",
        "print(f\"Dataset sauvegardé dans {save_dir}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=== Recherche de poissons ===\n",
            "Classes contenant 'fish' (6 trouvées):\n",
            "    1: goldfish (n01443537)\n",
            "  107: jellyfish (n01910747)\n",
            "  124: crayfish (n01985128)\n",
            "  327: starfish (n02317335)\n",
            "  393: anemone_fish (n02607072)\n",
            "  396: lionfish (n02643566)\n",
            "\n",
            "=== Recherche d'oiseaux ===\n",
            "Classes contenant 'bird' (2 trouvées):\n",
            "   94: hummingbird (n01833805)\n",
            "  448: birdhouse (n02843684)\n",
            "\n",
            "=== Filtrage avec les classes: ['tench', 'goldfish', 'great white shark', 'tiger shark', 'hammerhead shark', 'electric ray', 'stingray', 'rooster', 'hen', 'ostrich', 'brambling', 'goldfinch', 'house finch', 'junco', 'indigo bunting', 'American robin', 'bulbul', 'jay', 'magpie', 'chickadee', 'American dipper', 'kite (bird of prey)', 'bald eagle', 'vulture', 'great grey owl', 'fire salamander', 'smooth newt', 'newt', 'spotted salamander', 'axolotl', 'American bullfrog', 'tree frog', 'tailed frog', 'loggerhead sea turtle', 'leatherback sea turtle', 'mud turtle', 'terrapin', 'box turtle', 'banded gecko', 'green iguana', 'Carolina anole', 'desert grassland whiptail lizard', 'agama', 'frilled-necked lizard', 'alligator lizard', 'Gila monster', 'European green lizard', 'chameleon', 'Komodo dragon', 'Nile crocodile', 'American alligator', 'triceratops', 'worm snake', 'ring-necked snake', 'eastern hog-nosed snake', 'smooth green snake', 'kingsnake', 'garter snake', 'water snake', 'vine snake', 'night snake', 'boa constrictor', 'African rock python', 'Indian cobra', 'green mamba', 'sea snake', 'Saharan horned viper', 'eastern diamondback rattlesnake', 'sidewinder rattlesnake', 'trilobite', 'harvestman', 'scorpion', 'yellow garden spider', 'barn spider', 'European garden spider', 'southern black widow', 'tarantula', 'wolf spider', 'tick', 'centipede', 'black grouse', 'ptarmigan', 'ruffed grouse', 'prairie grouse', 'peafowl', 'quail', 'partridge', 'african grey parrot', 'macaw', 'sulphur-crested cockatoo', 'lorikeet', 'coucal', 'bee eater', 'hornbill', 'hummingbird', 'jacamar', 'toucan', 'duck', 'red-breasted merganser', 'goose', 'black swan', 'tusker', 'echidna', 'platypus', 'wallaby', 'koala', 'wombat', 'jellyfish', 'sea anemone', 'brain coral', 'flatworm', 'nematode', 'conch', 'snail', 'slug', 'sea slug', 'chiton', 'chambered nautilus', 'Dungeness crab', 'rock crab', 'fiddler crab', 'red king crab', 'American lobster', 'spiny lobster', 'crayfish', 'hermit crab', 'isopod', 'white stork', 'black stork', 'spoonbill', 'flamingo', 'little blue heron', 'great egret', 'bittern bird', 'crane bird', 'limpkin', 'common gallinule', 'American coot', 'bustard', 'ruddy turnstone', 'dunlin', 'common redshank', 'dowitcher', 'oystercatcher', 'pelican', 'king penguin', 'albatross', 'grey whale', 'killer whale', 'dugong', 'sea lion', 'Chihuahua', 'Japanese Chin', 'Maltese', 'Pekingese', 'Shih Tzu', 'King Charles Spaniel', 'Papillon', 'toy terrier', 'Rhodesian Ridgeback', 'Afghan Hound', 'Basset Hound', 'Beagle', 'Bloodhound', 'Bluetick Coonhound', 'Black and Tan Coonhound', 'Treeing Walker Coonhound', 'English foxhound', 'Redbone Coonhound', 'borzoi', 'Irish Wolfhound', 'Italian Greyhound', 'Whippet', 'Ibizan Hound', 'Norwegian Elkhound', 'Otterhound', 'Saluki', 'Scottish Deerhound', 'Weimaraner', 'Staffordshire Bull Terrier', 'American Staffordshire Terrier', 'Bedlington Terrier', 'Border Terrier', 'Kerry Blue Terrier', 'Irish Terrier', 'Norfolk Terrier', 'Norwich Terrier', 'Yorkshire Terrier', 'Wire Fox Terrier', 'Lakeland Terrier', 'Sealyham Terrier', 'Airedale Terrier', 'Cairn Terrier', 'Australian Terrier', 'Dandie Dinmont Terrier', 'Boston Terrier', 'Miniature Schnauzer', 'Giant Schnauzer', 'Standard Schnauzer', 'Scottish Terrier', 'Tibetan Terrier', 'Australian Silky Terrier', 'Soft-coated Wheaten Terrier', 'West Highland White Terrier', 'Lhasa Apso', 'Flat-Coated Retriever', 'Curly-coated Retriever', 'Golden Retriever', 'Labrador Retriever', 'Chesapeake Bay Retriever', 'German Shorthaired Pointer', 'Vizsla', 'English Setter', 'Irish Setter', 'Gordon Setter', 'Brittany dog', 'Clumber Spaniel', 'English Springer Spaniel', 'Welsh Springer Spaniel', 'Cocker Spaniel', 'Sussex Spaniel', 'Irish Water Spaniel', 'Kuvasz', 'Schipperke', 'Groenendael dog', 'Malinois', 'Briard', 'Australian Kelpie', 'Komondor', 'Old English Sheepdog', 'Shetland Sheepdog', 'collie', 'Border Collie', 'Bouvier des Flandres dog', 'Rottweiler', 'German Shepherd Dog', 'Dobermann', 'Miniature Pinscher', 'Greater Swiss Mountain Dog', 'Bernese Mountain Dog', 'Appenzeller Sennenhund', 'Entlebucher Sennenhund', 'Boxer', 'Bullmastiff', 'Tibetan Mastiff', 'French Bulldog', 'Great Dane', 'St. Bernard', 'husky', 'Alaskan Malamute', 'Siberian Husky', 'Dalmatian', 'Affenpinscher', 'Basenji', 'pug', 'Leonberger', 'Newfoundland dog', 'Great Pyrenees dog', 'Samoyed', 'Pomeranian', 'Chow Chow', 'Keeshond', 'brussels griffon', 'Pembroke Welsh Corgi', 'Cardigan Welsh Corgi', 'Toy Poodle', 'Miniature Poodle', 'Standard Poodle', 'Mexican hairless dog (xoloitzcuintli)', 'grey wolf', 'Alaskan tundra wolf', 'red wolf or maned wolf', 'coyote', 'dingo', 'dhole', 'African wild dog', 'hyena', 'red fox', 'kit fox', 'Arctic fox', 'grey fox', 'tabby cat', 'tiger cat', 'Persian cat', 'Siamese cat', 'Egyptian Mau', 'cougar', 'lynx', 'leopard', 'snow leopard', 'jaguar', 'lion', 'tiger', 'cheetah', 'brown bear', 'American black bear', 'polar bear', 'sloth bear', 'mongoose', 'meerkat', 'tiger beetle', 'ladybug', 'ground beetle', 'longhorn beetle', 'leaf beetle', 'dung beetle', 'rhinoceros beetle', 'weevil', 'fly', 'bee', 'ant', 'grasshopper', 'cricket insect', 'stick insect', 'cockroach', 'praying mantis', 'cicada', 'leafhopper', 'lacewing', 'dragonfly', 'damselfly', 'red admiral butterfly', 'ringlet butterfly', 'monarch butterfly', 'small white butterfly', 'sulphur butterfly', 'gossamer-winged butterfly', 'starfish', 'sea urchin', 'sea cucumber', 'cottontail rabbit', 'hare', 'Angora rabbit', 'hamster', 'porcupine', 'fox squirrel', 'marmot', 'beaver', 'guinea pig', 'common sorrel horse', 'zebra', 'pig', 'wild boar', 'warthog', 'hippopotamus', 'ox', 'water buffalo', 'bison', 'ram (adult male sheep)', 'bighorn sheep', 'Alpine ibex', 'hartebeest', 'impala (antelope)', 'gazelle', 'arabian camel', 'llama', 'weasel', 'mink', 'European polecat', 'black-footed ferret', 'otter', 'skunk', 'badger', 'armadillo', 'three-toed sloth', 'orangutan', 'gorilla', 'chimpanzee', 'gibbon', 'siamang', 'guenon', 'patas monkey', 'baboon', 'macaque', 'langur', 'black-and-white colobus', 'proboscis monkey', 'marmoset', 'white-headed capuchin', 'howler monkey', 'titi monkey', \"Geoffroy's spider monkey\", 'common squirrel monkey', 'ring-tailed lemur', 'indri', 'Asian elephant', 'African bush elephant', 'red panda', 'giant panda', 'snoek fish', 'eel', 'silver salmon', 'rock beauty fish', 'clownfish', 'sturgeon', 'gar fish', 'lionfish', 'pufferfish', 'abacus', 'abaya', 'academic gown', 'accordion', 'acoustic guitar', 'aircraft carrier', 'airliner', 'airship', 'altar', 'ambulance', 'amphibious vehicle', 'analog clock', 'apiary', 'apron', 'trash can', 'assault rifle', 'backpack', 'bakery', 'balance beam', 'balloon', 'ballpoint pen', 'Band-Aid', 'banjo', 'baluster / handrail', 'barbell', 'barber chair', 'barbershop', 'barn', 'barometer', 'barrel', 'wheelbarrow', 'baseball', 'basketball', 'bassinet', 'bassoon', 'swimming cap', 'bath towel', 'bathtub', 'station wagon', 'lighthouse', 'beaker', 'military hat (bearskin or shako)', 'beer bottle', 'beer glass', 'bell tower', 'baby bib', 'tandem bicycle', 'bikini', 'ring binder', 'binoculars', 'birdhouse', 'boathouse', 'bobsleigh', 'bolo tie', 'poke bonnet', 'bookcase', 'bookstore', 'bottle cap', 'hunting bow', 'bow tie', 'brass memorial plaque', 'bra', 'breakwater', 'breastplate', 'broom', 'bucket', 'buckle', 'bulletproof vest', 'high-speed train', 'butcher shop', 'taxicab', 'cauldron', 'candle', 'cannon', 'canoe', 'can opener', 'cardigan', 'car mirror', 'carousel', 'tool kit', 'cardboard box / carton', 'car wheel', 'automated teller machine', 'cassette', 'cassette player', 'castle', 'catamaran', 'CD player', 'cello', 'mobile phone', 'chain', 'chain-link fence', 'chain mail', 'chainsaw', 'storage chest', 'chiffonier', 'bell or wind chime', 'china cabinet', 'Christmas stocking', 'church', 'movie theater', 'cleaver', 'cliff dwelling', 'cloak', 'clogs', 'cocktail shaker', 'coffee mug', 'coffeemaker', 'spiral or coil', 'combination lock', 'computer keyboard', 'candy store', 'container ship', 'convertible', 'corkscrew', 'cornet', 'cowboy boot', 'cowboy hat', 'cradle', 'construction crane', 'crash helmet', 'crate', 'infant bed', 'Crock Pot', 'croquet ball', 'crutch', 'cuirass', 'dam', 'desk', 'desktop computer', 'rotary dial telephone', 'diaper', 'digital clock', 'digital watch', 'dining table', 'dishcloth', 'dishwasher', 'disc brake', 'dock', 'dog sled', 'dome', 'doormat', 'drilling rig', 'drum', 'drumstick', 'dumbbell', 'Dutch oven', 'electric fan', 'electric guitar', 'electric locomotive', 'entertainment center', 'envelope', 'espresso machine', 'face powder', 'feather boa', 'filing cabinet', 'fireboat', 'fire truck', 'fire screen', 'flagpole', 'flute', 'folding chair', 'football helmet', 'forklift', 'fountain', 'fountain pen', 'four-poster bed', 'freight car', 'French horn', 'frying pan', 'fur coat', 'garbage truck', 'gas mask or respirator', 'gas pump', 'goblet', 'go-kart', 'golf ball', 'golf cart', 'gondola', 'gong', 'gown', 'grand piano', 'greenhouse', 'radiator grille', 'grocery store', 'guillotine', 'hair clip', 'hair spray', 'half-track', 'hammer', 'hamper', 'hair dryer', 'hand-held computer', 'handkerchief', 'hard disk drive', 'harmonica', 'harp', 'combine harvester', 'hatchet', 'holster', 'home theater', 'honeycomb', 'hook', 'hoop skirt', 'gymnastic horizontal bar', 'horse-drawn vehicle', 'hourglass', 'iPod', 'clothes iron', 'carved pumpkin', 'jeans', 'jeep', 'T-shirt', 'jigsaw puzzle', 'rickshaw', 'joystick', 'kimono', 'knee pad', 'knot', 'lab coat', 'ladle', 'lampshade', 'laptop computer', 'lawn mower', 'lens cap', 'letter opener', 'library', 'lifeboat', 'lighter', 'limousine', 'ocean liner', 'lipstick', 'slip-on shoe', 'lotion', 'music speaker', 'loupe magnifying glass', 'sawmill', 'magnetic compass', 'messenger bag', 'mailbox', 'tights', 'one-piece bathing suit', 'manhole cover', 'maraca', 'marimba', 'mask', 'matchstick', 'maypole', 'maze', 'measuring cup', 'medicine cabinet', 'megalith', 'microphone', 'microwave oven', 'military uniform', 'milk can', 'minibus', 'miniskirt', 'minivan', 'missile', 'mitten', 'mixing bowl', 'mobile home', 'ford model t', 'modem', 'monastery', 'monitor', 'moped', 'mortar and pestle', 'graduation cap', 'mosque', 'mosquito net', 'vespa', 'mountain bike', 'tent', 'computer mouse', 'mousetrap', 'moving van', 'muzzle', 'metal nail', 'neck brace', 'necklace', 'baby pacifier', 'notebook computer', 'obelisk', 'oboe', 'ocarina', 'odometer', 'oil filter', 'pipe organ', 'oscilloscope', 'overskirt', 'bullock cart', 'oxygen mask', 'product packet / packaging', 'paddle', 'paddle wheel', 'padlock', 'paintbrush', 'pajamas', 'palace', 'pan flute', 'paper towel', 'parachute', 'parallel bars', 'park bench', 'parking meter', 'railroad car', 'patio', 'payphone', 'pedestal', 'pencil case', 'pencil sharpener', 'perfume', 'Petri dish', 'photocopier', 'plectrum', 'Pickelhaube', 'picket fence', 'pickup truck', 'pier', 'piggy bank', 'pill bottle', 'pillow', 'ping-pong ball', 'pinwheel', 'pirate ship', 'drink pitcher', 'block plane', 'planetarium', 'plastic bag', 'plate rack', 'farm plow', 'plunger', 'Polaroid camera', 'pole', 'police van', 'poncho', 'pool table', 'soda bottle', 'plant pot', \"potter's wheel\", 'power drill', 'prayer rug', 'printer', 'prison', 'missile', 'projector', 'hockey puck', 'punching bag', 'purse', 'quill', 'quilt', 'race car', 'racket', 'radiator', 'radio', 'radio telescope', 'rain barrel', 'recreational vehicle', 'fishing casting reel', 'reflex camera', 'refrigerator', 'remote control', 'restaurant', 'revolver', 'rifle', 'rocking chair', 'rotisserie', 'eraser', 'rugby ball', 'ruler measuring stick', 'sneaker', 'safe', 'safety pin', 'salt shaker', 'sandal', 'sarong', 'saxophone', 'scabbard', 'weighing scale', 'school bus', 'schooner', 'scoreboard', 'CRT monitor', 'screw', 'screwdriver', 'seat belt', 'sewing machine', 'shield', 'shoe store', 'shoji screen / room divider', 'shopping basket', 'shopping cart', 'shovel', 'shower cap', 'shower curtain', 'ski', 'balaclava ski mask', 'sleeping bag', 'slide rule', 'sliding door', 'slot machine', 'snorkel', 'snowmobile', 'snowplow', 'soap dispenser', 'soccer ball', 'sock', 'solar thermal collector', 'sombrero', 'soup bowl', 'keyboard space bar', 'space heater', 'space shuttle', 'spatula', 'motorboat', 'spider web', 'spindle', 'sports car', 'spotlight', 'stage', 'steam locomotive', 'through arch bridge', 'steel drum', 'stethoscope', 'scarf', 'stone wall', 'stopwatch', 'stove', 'strainer', 'tram', 'stretcher', 'couch', 'stupa', 'submarine', 'suit', 'sundial', 'sunglasses', 'sunglasses', 'sunscreen', 'suspension bridge', 'mop', 'sweatshirt', 'swim trunks / shorts', 'swing', 'electrical switch', 'syringe', 'table lamp', 'tank', 'tape player', 'teapot', 'teddy bear', 'television', 'tennis ball', 'thatched roof', 'front curtain', 'thimble', 'threshing machine', 'throne', 'tile roof', 'toaster', 'tobacco shop', 'toilet seat', 'torch', 'totem pole', 'tow truck', 'toy store', 'tractor', 'semi-trailer truck', 'tray', 'trench coat', 'tricycle', 'trimaran', 'tripod', 'triumphal arch', 'trolleybus', 'trombone', 'hot tub', 'turnstile', 'typewriter keyboard', 'umbrella', 'unicycle', 'upright piano', 'vacuum cleaner', 'vase', 'vaulted or arched ceiling', 'velvet fabric', 'vending machine', 'vestment', 'viaduct', 'violin', 'volleyball', 'waffle iron', 'wall clock', 'wallet', 'wardrobe', 'military aircraft', 'sink', 'washing machine', 'water bottle', 'water jug', 'water tower', 'whiskey jug', 'whistle', 'hair wig', 'window screen', 'window shade', 'Windsor tie', 'wine bottle', 'airplane wing', 'wok', 'wooden spoon', 'wool', 'split-rail fence', 'shipwreck', 'sailboat', 'yurt', 'website', 'comic book', 'crossword', 'traffic or street sign', 'traffic light', 'dust jacket', 'menu', 'plate', 'guacamole', 'consomme', 'hot pot', 'trifle', 'ice cream', 'popsicle', 'baguette', 'bagel', 'pretzel', 'cheeseburger', 'hot dog', 'mashed potatoes', 'cabbage', 'broccoli', 'cauliflower', 'zucchini', 'spaghetti squash', 'acorn squash', 'butternut squash', 'cucumber', 'artichoke', 'bell pepper', 'cardoon', 'mushroom', 'Granny Smith apple', 'strawberry', 'orange', 'lemon', 'fig', 'pineapple', 'banana', 'jackfruit', 'cherimoya (custard apple)', 'pomegranate', 'hay', 'carbonara', 'chocolate syrup', 'dough', 'meatloaf', 'pizza', 'pot pie', 'burrito', 'red wine', 'espresso', 'tea cup', 'eggnog', 'mountain', 'bubble', 'cliff', 'coral reef', 'geyser', 'lakeshore', 'promontory', 'sandbar', 'beach', 'valley', 'volcano', 'baseball player', 'bridegroom', 'scuba diver', 'rapeseed', 'daisy', \"yellow lady's slipper\", 'corn', 'acorn', 'rose hip', 'horse chestnut seed', 'coral fungus', 'agaric', 'gyromitra', 'stinkhorn mushroom', 'earth star fungus', 'hen of the woods mushroom', 'bolete', 'corn cob', 'toilet paper'] ===\n",
            "ATTENTION: Classes non trouvées dans ImageNet: ['great white shark', 'tiger shark', 'hammerhead shark', 'electric ray', 'rooster', 'house finch', 'indigo bunting', 'American robin', 'American dipper', 'kite (bird of prey)', 'bald eagle', 'great grey owl', 'fire salamander', 'smooth newt', 'newt', 'spotted salamander', 'American bullfrog', 'tree frog', 'tailed frog', 'loggerhead sea turtle', 'leatherback sea turtle', 'mud turtle', 'box turtle', 'banded gecko', 'green iguana', 'Carolina anole', 'desert grassland whiptail lizard', 'frilled-necked lizard', 'alligator lizard', 'Gila monster', 'European green lizard', 'chameleon', 'Komodo dragon', 'Nile crocodile', 'American alligator', 'worm snake', 'ring-necked snake', 'eastern hog-nosed snake', 'smooth green snake', 'kingsnake', 'garter snake', 'water snake', 'vine snake', 'night snake', 'boa constrictor', 'African rock python', 'Indian cobra', 'green mamba', 'sea snake', 'Saharan horned viper', 'eastern diamondback rattlesnake', 'sidewinder rattlesnake', 'yellow garden spider', 'barn spider', 'European garden spider', 'southern black widow', 'wolf spider', 'black grouse', 'ruffed grouse', 'prairie grouse', 'peafowl', 'african grey parrot', 'sulphur-crested cockatoo', 'bee eater', 'duck', 'red-breasted merganser', 'black swan', 'sea anemone', 'brain coral', 'sea slug', 'chambered nautilus', 'Dungeness crab', 'rock crab', 'fiddler crab', 'red king crab', 'American lobster', 'spiny lobster', 'hermit crab', 'white stork', 'black stork', 'little blue heron', 'great egret', 'bittern bird', 'crane bird', 'common gallinule', 'American coot', 'ruddy turnstone', 'dunlin', 'common redshank', 'king penguin', 'grey whale', 'killer whale', 'sea lion', 'Japanese Chin', 'Maltese', 'Pekingese', 'Shih Tzu', 'King Charles Spaniel', 'Papillon', 'toy terrier', 'Rhodesian Ridgeback', 'Afghan Hound', 'Basset Hound', 'Beagle', 'Bloodhound', 'Bluetick Coonhound', 'Black and Tan Coonhound', 'Treeing Walker Coonhound', 'English foxhound', 'Redbone Coonhound', 'Irish Wolfhound', 'Italian Greyhound', 'Whippet', 'Ibizan Hound', 'Norwegian Elkhound', 'Otterhound', 'Scottish Deerhound', 'Staffordshire Bull Terrier', 'American Staffordshire Terrier', 'Bedlington Terrier', 'Border Terrier', 'Kerry Blue Terrier', 'Irish Terrier', 'Norfolk Terrier', 'Norwich Terrier', 'Yorkshire Terrier', 'Wire Fox Terrier', 'Lakeland Terrier', 'Sealyham Terrier', 'Airedale Terrier', 'Cairn Terrier', 'Australian Terrier', 'Dandie Dinmont Terrier', 'Boston Terrier', 'Miniature Schnauzer', 'Giant Schnauzer', 'Standard Schnauzer', 'Scottish Terrier', 'Tibetan Terrier', 'Australian Silky Terrier', 'Soft-coated Wheaten Terrier', 'West Highland White Terrier', 'Lhasa Apso', 'Flat-Coated Retriever', 'Curly-coated Retriever', 'Golden Retriever', 'Labrador Retriever', 'Chesapeake Bay Retriever', 'German Shorthaired Pointer', 'Vizsla', 'English Setter', 'Irish Setter', 'Gordon Setter', 'Brittany dog', 'Clumber Spaniel', 'English Springer Spaniel', 'Welsh Springer Spaniel', 'Cocker Spaniel', 'Sussex Spaniel', 'Irish Water Spaniel', 'Kuvasz', 'Schipperke', 'Groenendael dog', 'Malinois', 'Briard', 'Australian Kelpie', 'Komondor', 'Old English Sheepdog', 'Shetland Sheepdog', 'Border Collie', 'Bouvier des Flandres dog', 'German Shepherd Dog', 'Dobermann', 'Miniature Pinscher', 'Greater Swiss Mountain Dog', 'Bernese Mountain Dog', 'Appenzeller Sennenhund', 'Entlebucher Sennenhund', 'Boxer', 'Bullmastiff', 'Tibetan Mastiff', 'French Bulldog', 'Great Dane', 'St. Bernard', 'husky', 'Alaskan Malamute', 'Siberian Husky', 'Dalmatian', 'Affenpinscher', 'Basenji', 'Leonberger', 'Newfoundland dog', 'Great Pyrenees dog', 'Chow Chow', 'Keeshond', 'brussels griffon', 'Pembroke Welsh Corgi', 'Cardigan Welsh Corgi', 'Toy Poodle', 'Miniature Poodle', 'Standard Poodle', 'Mexican hairless dog (xoloitzcuintli)', 'grey wolf', 'Alaskan tundra wolf', 'red wolf or maned wolf', 'African wild dog', 'red fox', 'kit fox', 'Arctic fox', 'grey fox', 'tabby cat', 'tiger cat', 'Persian cat', 'Siamese cat', 'Egyptian Mau', 'snow leopard', 'brown bear', 'American black bear', 'polar bear', 'sloth bear', 'tiger beetle', 'ground beetle', 'longhorn beetle', 'leaf beetle', 'dung beetle', 'rhinoceros beetle', 'cricket insect', 'stick insect', 'praying mantis', 'red admiral butterfly', 'ringlet butterfly', 'monarch butterfly', 'small white butterfly', 'sulphur butterfly', 'gossamer-winged butterfly', 'sea urchin', 'sea cucumber', 'cottontail rabbit', 'Angora rabbit', 'fox squirrel', 'guinea pig', 'common sorrel horse', 'pig', 'wild boar', 'water buffalo', 'ram (adult male sheep)', 'bighorn sheep', 'Alpine ibex', 'impala (antelope)', 'arabian camel', 'European polecat', 'black-footed ferret', 'three-toed sloth', 'patas monkey', 'black-and-white colobus', 'proboscis monkey', 'white-headed capuchin', 'howler monkey', 'titi monkey', \"Geoffroy's spider monkey\", 'common squirrel monkey', 'ring-tailed lemur', 'Asian elephant', 'African bush elephant', 'red panda', 'giant panda', 'snoek fish', 'silver salmon', 'rock beauty fish', 'clownfish', 'gar fish', 'pufferfish', 'academic gown', 'acoustic guitar', 'aircraft carrier', 'amphibious vehicle', 'analog clock', 'trash can', 'assault rifle', 'balance beam', 'ballpoint pen', 'Band-Aid', 'baluster / handrail', 'barber chair', 'wheelbarrow', 'swimming cap', 'bath towel', 'station wagon', 'lighthouse', 'military hat (bearskin or shako)', 'beer bottle', 'beer glass', 'bell tower', 'baby bib', 'tandem bicycle', 'ring binder', 'bobsleigh', 'bolo tie', 'poke bonnet', 'bookstore', 'bottle cap', 'hunting bow', 'bow tie', 'brass memorial plaque', 'bra', 'bulletproof vest', 'high-speed train', 'butcher shop', 'taxicab', 'cauldron', 'can opener', 'car mirror', 'tool kit', 'cardboard box / carton', 'car wheel', 'automated teller machine', 'cassette player', 'CD player', 'mobile phone', 'chain-link fence', 'chain mail', 'chainsaw', 'storage chest', 'bell or wind chime', 'china cabinet', 'Christmas stocking', 'movie theater', 'cliff dwelling', 'clogs', 'cocktail shaker', 'coffee mug', 'coffeemaker', 'spiral or coil', 'combination lock', 'computer keyboard', 'candy store', 'container ship', 'cowboy boot', 'cowboy hat', 'construction crane', 'crash helmet', 'infant bed', 'Crock Pot', 'croquet ball', 'desktop computer', 'rotary dial telephone', 'digital clock', 'digital watch', 'dining table', 'dishcloth', 'disc brake', 'dog sled', 'drilling rig', 'Dutch oven', 'electric fan', 'electric guitar', 'electric locomotive', 'entertainment center', 'espresso machine', 'face powder', 'feather boa', 'filing cabinet', 'fire truck', 'fire screen', 'folding chair', 'football helmet', 'fountain pen', 'four-poster bed', 'freight car', 'French horn', 'frying pan', 'fur coat', 'garbage truck', 'gas mask or respirator', 'gas pump', 'golf ball', 'golf cart', 'grand piano', 'radiator grille', 'grocery store', 'hair clip', 'hair spray', 'half-track', 'hair dryer', 'hand-held computer', 'hard disk drive', 'combine harvester', 'home theater', 'hoop skirt', 'gymnastic horizontal bar', 'horse-drawn vehicle', 'clothes iron', 'carved pumpkin', 'jeans', 'T-shirt', 'jigsaw puzzle', 'rickshaw', 'knee pad', 'lab coat', 'laptop computer', 'lawn mower', 'lens cap', 'letter opener', 'ocean liner', 'slip-on shoe', 'music speaker', 'loupe magnifying glass', 'sawmill', 'magnetic compass', 'messenger bag', 'tights', 'one-piece bathing suit', 'manhole cover', 'measuring cup', 'medicine cabinet', 'microwave oven', 'military uniform', 'milk can', 'mixing bowl', 'mobile home', 'ford model t', 'mortar and pestle', 'graduation cap', 'mosquito net', 'vespa', 'mountain bike', 'tent', 'computer mouse', 'moving van', 'metal nail', 'neck brace', 'baby pacifier', 'notebook computer', 'oil filter', 'pipe organ', 'bullock cart', 'oxygen mask', 'product packet / packaging', 'paddle wheel', 'pajamas', 'pan flute', 'paper towel', 'parallel bars', 'park bench', 'parking meter', 'railroad car', 'payphone', 'pencil case', 'pencil sharpener', 'Petri dish', 'plectrum', 'Pickelhaube', 'picket fence', 'pickup truck', 'piggy bank', 'pill bottle', 'ping-pong ball', 'pirate ship', 'drink pitcher', 'block plane', 'plastic bag', 'plate rack', 'farm plow', 'Polaroid camera', 'police van', 'pool table', 'soda bottle', 'plant pot', \"potter's wheel\", 'power drill', 'prayer rug', 'hockey puck', 'punching bag', 'race car', 'radio telescope', 'rain barrel', 'recreational vehicle', 'fishing casting reel', 'reflex camera', 'remote control', 'rocking chair', 'eraser', 'rugby ball', 'ruler measuring stick', 'sneaker', 'safety pin', 'salt shaker', 'saxophone', 'weighing scale', 'school bus', 'CRT monitor', 'seat belt', 'sewing machine', 'shoe store', 'shoji screen / room divider', 'shopping basket', 'shopping cart', 'shower cap', 'shower curtain', 'balaclava ski mask', 'sleeping bag', 'slide rule', 'sliding door', 'slot machine', 'soap dispenser', 'soccer ball', 'solar thermal collector', 'soup bowl', 'keyboard space bar', 'space heater', 'space shuttle', 'motorboat', 'spider web', 'sports car', 'steam locomotive', 'through arch bridge', 'steel drum', 'scarf', 'stone wall', 'tram', 'couch', 'suspension bridge', 'mop', 'swim trunks / shorts', 'electrical switch', 'table lamp', 'tape player', 'teddy bear', 'tennis ball', 'thatched roof', 'front curtain', 'threshing machine', 'tile roof', 'tobacco shop', 'toilet seat', 'totem pole', 'tow truck', 'toy store', 'semi-trailer truck', 'trench coat', 'triumphal arch', 'hot tub', 'typewriter keyboard', 'upright piano', 'vacuum cleaner', 'vaulted or arched ceiling', 'velvet fabric', 'vending machine', 'waffle iron', 'wall clock', 'military aircraft', 'sink', 'washing machine', 'water bottle', 'water jug', 'water tower', 'whiskey jug', 'hair wig', 'window screen', 'window shade', 'Windsor tie', 'wine bottle', 'airplane wing', 'wooden spoon', 'split-rail fence', 'shipwreck', 'sailboat', 'website', 'comic book', 'crossword', 'traffic or street sign', 'traffic light', 'dust jacket', 'hot pot', 'ice cream', 'popsicle', 'baguette', 'hot dog', 'mashed potatoes', 'cabbage', 'spaghetti squash', 'acorn squash', 'butternut squash', 'bell pepper', 'Granny Smith apple', 'cherimoya (custard apple)', 'chocolate syrup', 'meatloaf', 'pot pie', 'red wine', 'tea cup', 'mountain', 'coral reef', 'lakeshore', 'beach', 'baseball player', 'bridegroom', 'scuba diver', \"yellow lady's slipper\", 'rose hip', 'horse chestnut seed', 'coral fungus', 'stinkhorn mushroom', 'earth star fungus', 'hen of the woods mushroom', 'corn cob', 'toilet paper']\n",
            "Classes disponibles similaires:\n",
            "  Pour 'newt': ['common_newt']\n",
            "  Pour 'chameleon': ['American_chameleon', 'African_chameleon']\n",
            "  Pour 'Maltese': ['Maltese_dog']\n",
            "  Pour 'Papillon': ['papillon']\n",
            "  Pour 'Beagle': ['beagle']\n",
            "  Pour 'Bloodhound': ['bloodhound']\n",
            "  Pour 'Whippet': ['whippet']\n",
            "  Pour 'Otterhound': ['otterhound']\n",
            "  Pour 'Vizsla': ['vizsla']\n",
            "  Pour 'Kuvasz': ['kuvasz']\n",
            "  Pour 'Schipperke': ['schipperke']\n",
            "  Pour 'Malinois': ['malinois']\n",
            "  Pour 'Briard': ['briard']\n",
            "  Pour 'Komondor': ['komondor']\n",
            "  Pour 'Boxer': ['boxer']\n",
            "  Pour 'husky': ['Siberian_husky']\n",
            "  Pour 'Dalmatian': ['dalmatian']\n",
            "  Pour 'Affenpinscher': ['affenpinscher']\n",
            "  Pour 'Basenji': ['basenji']\n",
            "  Pour 'Keeshond': ['keeshond']\n",
            "  Pour 'pig': ['guinea_pig', 'piggy_bank']\n",
            "  Pour 'bra': ['brambling', 'Indian_cobra', 'brain_coral', 'Labrador_retriever', 'Brabancon_griffon']\n",
            "  Pour 'tent': ['mountain_tent']\n",
            "  Pour 'Pickelhaube': ['pickelhaube']\n",
            "  Pour 'eraser': ['rubber_eraser']\n",
            "  Pour 'couch': ['studio_couch']\n",
            "  Pour 'mop': ['moped']\n",
            "  Pour 'crossword': ['crossword_puzzle']\n",
            "  Pour 'cabbage': ['cabbage_butterfly', 'head_cabbage']\n",
            "  Pour 'mountain': ['Greater_Swiss_Mountain_dog', 'Bernese_mountain_dog', 'mountain_bike', 'mountain_tent']\n",
            "  Pour 'beach': ['beach_wagon']\n",
            "Classes à filtrer: ['tench', 'goldfish', 'stingray', 'hen', 'ostrich', 'brambling', 'goldfinch', 'junco', 'bulbul', 'jay', 'magpie', 'chickadee', 'vulture', 'axolotl', 'terrapin', 'agama', 'triceratops', 'trilobite', 'harvestman', 'scorpion', 'tarantula', 'tick', 'centipede', 'ptarmigan', 'quail', 'partridge', 'macaw', 'lorikeet', 'coucal', 'hornbill', 'hummingbird', 'jacamar', 'toucan', 'goose', 'tusker', 'echidna', 'platypus', 'wallaby', 'koala', 'wombat', 'jellyfish', 'flatworm', 'nematode', 'conch', 'snail', 'slug', 'chiton', 'crayfish', 'isopod', 'spoonbill', 'flamingo', 'limpkin', 'bustard', 'dowitcher', 'oystercatcher', 'pelican', 'albatross', 'dugong', 'Chihuahua', 'borzoi', 'Saluki', 'Weimaraner', 'collie', 'Rottweiler', 'pug', 'Samoyed', 'Pomeranian', 'coyote', 'dingo', 'dhole', 'hyena', 'cougar', 'lynx', 'leopard', 'jaguar', 'lion', 'tiger', 'cheetah', 'mongoose', 'meerkat', 'ladybug', 'weevil', 'fly', 'bee', 'ant', 'grasshopper', 'cockroach', 'cicada', 'leafhopper', 'lacewing', 'dragonfly', 'damselfly', 'starfish', 'hare', 'hamster', 'porcupine', 'marmot', 'beaver', 'zebra', 'warthog', 'hippopotamus', 'ox', 'bison', 'hartebeest', 'gazelle', 'llama', 'weasel', 'mink', 'otter', 'skunk', 'badger', 'armadillo', 'orangutan', 'gorilla', 'chimpanzee', 'gibbon', 'siamang', 'guenon', 'baboon', 'macaque', 'langur', 'marmoset', 'indri', 'eel', 'sturgeon', 'lionfish', 'abacus', 'abaya', 'accordion', 'airliner', 'airship', 'altar', 'ambulance', 'apiary', 'apron', 'backpack', 'bakery', 'balloon', 'banjo', 'barbell', 'barbershop', 'barn', 'barometer', 'barrel', 'baseball', 'basketball', 'bassinet', 'bassoon', 'bathtub', 'beaker', 'bikini', 'binoculars', 'birdhouse', 'boathouse', 'bookcase', 'breakwater', 'breastplate', 'broom', 'bucket', 'buckle', 'candle', 'cannon', 'canoe', 'cardigan', 'carousel', 'cassette', 'castle', 'catamaran', 'cello', 'chain', 'chiffonier', 'church', 'cleaver', 'cloak', 'convertible', 'corkscrew', 'cornet', 'cradle', 'crate', 'crutch', 'cuirass', 'dam', 'desk', 'diaper', 'dishwasher', 'dock', 'dome', 'doormat', 'drum', 'drumstick', 'dumbbell', 'envelope', 'fireboat', 'flagpole', 'flute', 'forklift', 'fountain', 'goblet', 'go-kart', 'gondola', 'gong', 'gown', 'greenhouse', 'guillotine', 'hammer', 'hamper', 'handkerchief', 'harmonica', 'harp', 'hatchet', 'holster', 'honeycomb', 'hook', 'hourglass', 'iPod', 'jeep', 'joystick', 'kimono', 'knot', 'ladle', 'lampshade', 'library', 'lifeboat', 'lighter', 'limousine', 'lipstick', 'lotion', 'mailbox', 'maraca', 'marimba', 'mask', 'matchstick', 'maypole', 'maze', 'megalith', 'microphone', 'minibus', 'miniskirt', 'minivan', 'missile', 'mitten', 'modem', 'monastery', 'monitor', 'moped', 'mosque', 'mousetrap', 'muzzle', 'necklace', 'obelisk', 'oboe', 'ocarina', 'odometer', 'oscilloscope', 'overskirt', 'paddle', 'padlock', 'paintbrush', 'palace', 'parachute', 'patio', 'pedestal', 'perfume', 'photocopier', 'pier', 'pillow', 'pinwheel', 'planetarium', 'plunger', 'pole', 'poncho', 'printer', 'prison', 'missile', 'projector', 'purse', 'quill', 'quilt', 'racket', 'radiator', 'radio', 'refrigerator', 'restaurant', 'revolver', 'rifle', 'rotisserie', 'safe', 'sandal', 'sarong', 'scabbard', 'schooner', 'scoreboard', 'screw', 'screwdriver', 'shield', 'shovel', 'ski', 'snorkel', 'snowmobile', 'snowplow', 'sock', 'sombrero', 'spatula', 'spindle', 'spotlight', 'stage', 'stethoscope', 'stopwatch', 'stove', 'strainer', 'stretcher', 'stupa', 'submarine', 'suit', 'sundial', 'sunglasses', 'sunglasses', 'sunscreen', 'sweatshirt', 'swing', 'syringe', 'tank', 'teapot', 'television', 'thimble', 'throne', 'toaster', 'torch', 'tractor', 'tray', 'tricycle', 'trimaran', 'tripod', 'trolleybus', 'trombone', 'turnstile', 'umbrella', 'unicycle', 'vase', 'vestment', 'viaduct', 'violin', 'volleyball', 'wallet', 'wardrobe', 'whistle', 'wok', 'wool', 'yurt', 'menu', 'plate', 'guacamole', 'consomme', 'trifle', 'bagel', 'pretzel', 'cheeseburger', 'broccoli', 'cauliflower', 'zucchini', 'cucumber', 'artichoke', 'cardoon', 'mushroom', 'strawberry', 'orange', 'lemon', 'fig', 'pineapple', 'banana', 'jackfruit', 'pomegranate', 'hay', 'carbonara', 'dough', 'pizza', 'burrito', 'espresso', 'eggnog', 'bubble', 'cliff', 'geyser', 'promontory', 'sandbar', 'valley', 'volcano', 'rapeseed', 'daisy', 'corn', 'acorn', 'agaric', 'gyromitra', 'bolete']\n",
            "Indices correspondants: [0, 1, 6, 8, 9, 10, 11, 13, 16, 17, 18, 19, 23, 29, 36, 42, 51, 69, 70, 71, 76, 78, 79, 81, 85, 86, 88, 90, 91, 93, 94, 95, 96, 99, 101, 102, 103, 104, 105, 106, 107, 110, 111, 112, 113, 114, 116, 124, 126, 129, 130, 135, 138, 142, 143, 144, 146, 149, 151, 169, 176, 178, 231, 234, 254, 258, 259, 272, 273, 274, 276, 286, 287, 288, 290, 291, 292, 293, 298, 299, 301, 307, 308, 309, 310, 311, 314, 316, 317, 318, 319, 320, 327, 331, 333, 334, 336, 337, 340, 343, 344, 345, 347, 351, 353, 355, 356, 357, 360, 361, 362, 363, 365, 366, 367, 368, 369, 370, 372, 373, 374, 377, 384, 390, 394, 396, 398, 399, 401, 404, 405, 406, 407, 410, 411, 414, 415, 417, 420, 422, 424, 425, 426, 427, 429, 430, 431, 432, 435, 438, 445, 447, 448, 449, 453, 460, 461, 462, 463, 464, 470, 471, 472, 474, 476, 481, 483, 484, 486, 488, 493, 497, 499, 501, 511, 512, 513, 516, 519, 523, 524, 525, 526, 529, 534, 536, 538, 539, 541, 542, 543, 549, 554, 557, 558, 561, 562, 572, 573, 576, 577, 578, 580, 583, 587, 588, 591, 593, 594, 596, 597, 599, 600, 604, 605, 609, 613, 614, 616, 618, 619, 624, 625, 626, 627, 629, 631, 637, 641, 642, 643, 644, 645, 646, 649, 650, 654, 655, 656, 657, 658, 662, 663, 664, 665, 668, 674, 676, 679, 682, 683, 684, 685, 688, 689, 693, 695, 696, 698, 701, 706, 708, 711, 713, 718, 721, 723, 727, 731, 733, 735, 742, 743, 657, 745, 748, 749, 750, 752, 753, 754, 760, 762, 763, 764, 766, 771, 774, 775, 777, 780, 781, 783, 784, 787, 792, 795, 801, 802, 803, 806, 808, 813, 816, 818, 819, 823, 826, 827, 828, 830, 832, 833, 834, 835, 837, 837, 838, 841, 843, 845, 847, 849, 851, 855, 857, 859, 862, 866, 868, 870, 871, 872, 874, 875, 877, 879, 880, 883, 887, 888, 889, 890, 893, 894, 902, 909, 911, 915, 922, 923, 924, 925, 927, 931, 932, 933, 937, 938, 939, 943, 944, 946, 947, 949, 950, 951, 952, 953, 954, 955, 957, 958, 959, 961, 963, 965, 967, 969, 971, 972, 974, 976, 977, 979, 980, 984, 985, 987, 988, 992, 993, 997]\n",
            "WordNet IDs: ['n01440764', 'n01443537', 'n01498041', 'n01514859', 'n01518878', 'n01530575', 'n01531178', 'n01534433', 'n01560419', 'n01580077', 'n01582220', 'n01592084', 'n01616318', 'n01632777', 'n01667778', 'n01687978', 'n01704323', 'n01768244', 'n01770081', 'n01770393', 'n01774750', 'n01776313', 'n01784675', 'n01796340', 'n01806567', 'n01807496', 'n01818515', 'n01820546', 'n01824575', 'n01829413', 'n01833805', 'n01843065', 'n01843383', 'n01855672', 'n01871265', 'n01872401', 'n01873310', 'n01877812', 'n01882714', 'n01883070', 'n01910747', 'n01924916', 'n01930112', 'n01943899', 'n01944390', 'n01945685', 'n01955084', 'n01985128', 'n01990800', 'n02006656', 'n02007558', 'n02013706', 'n02018795', 'n02033041', 'n02037110', 'n02051845', 'n02058221', 'n02074367', 'n02085620', 'n02090622', 'n02091831', 'n02092339', 'n02106030', 'n02106550', 'n02110958', 'n02111889', 'n02112018', 'n02114855', 'n02115641', 'n02115913', 'n02117135', 'n02125311', 'n02127052', 'n02128385', 'n02128925', 'n02129165', 'n02129604', 'n02130308', 'n02137549', 'n02138441', 'n02165456', 'n02177972', 'n02190166', 'n02206856', 'n02219486', 'n02226429', 'n02233338', 'n02256656', 'n02259212', 'n02264363', 'n02268443', 'n02268853', 'n02317335', 'n02326432', 'n02342885', 'n02346627', 'n02361337', 'n02363005', 'n02391049', 'n02397096', 'n02398521', 'n02403003', 'n02410509', 'n02422106', 'n02423022', 'n02437616', 'n02441942', 'n02442845', 'n02444819', 'n02445715', 'n02447366', 'n02454379', 'n02480495', 'n02480855', 'n02481823', 'n02483362', 'n02483708', 'n02484975', 'n02486410', 'n02487347', 'n02488291', 'n02490219', 'n02500267', 'n02526121', 'n02640242', 'n02643566', 'n02666196', 'n02667093', 'n02672831', 'n02690373', 'n02692877', 'n02699494', 'n02701002', 'n02727426', 'n02730930', 'n02769748', 'n02776631', 'n02782093', 'n02787622', 'n02790996', 'n02791270', 'n02793495', 'n02794156', 'n02795169', 'n02799071', 'n02802426', 'n02804414', 'n02804610', 'n02808440', 'n02815834', 'n02837789', 'n02841315', 'n02843684', 'n02859443', 'n02870880', 'n02894605', 'n02895154', 'n02906734', 'n02909870', 'n02910353', 'n02948072', 'n02950826', 'n02951358', 'n02963159', 'n02966193', 'n02978881', 'n02980441', 'n02981792', 'n02992211', 'n02999410', 'n03016953', 'n03028079', 'n03041632', 'n03045698', 'n03100240', 'n03109150', 'n03110669', 'n03125729', 'n03127925', 'n03141823', 'n03146219', 'n03160309', 'n03179701', 'n03188531', 'n03207941', 'n03216828', 'n03220513', 'n03223299', 'n03249569', 'n03250847', 'n03255030', 'n03291819', 'n03344393', 'n03355925', 'n03372029', 'n03384352', 'n03388043', 'n03443371', 'n03444034', 'n03447447', 'n03447721', 'n03450230', 'n03457902', 'n03467068', 'n03481172', 'n03482405', 'n03485794', 'n03494278', 'n03495258', 'n03498962', 'n03527444', 'n03530642', 'n03532672', 'n03544143', 'n03584254', 'n03594945', 'n03602883', 'n03617480', 'n03627232', 'n03633091', 'n03637318', 'n03661043', 'n03662601', 'n03666591', 'n03670208', 'n03676483', 'n03690938', 'n03710193', 'n03720891', 'n03721384', 'n03724870', 'n03729826', 'n03733131', 'n03733281', 'n03743016', 'n03759954', 'n03769881', 'n03770439', 'n03770679', 'n03773504', 'n03775071', 'n03777754', 'n03781244', 'n03782006', 'n03785016', 'n03788195', 'n03794056', 'n03803284', 'n03814906', 'n03837869', 'n03838899', 'n03840681', 'n03841143', 'n03857828', 'n03866082', 'n03873416', 'n03874599', 'n03876231', 'n03877845', 'n03888257', 'n03899768', 'n03903868', 'n03916031', 'n03924679', 'n03933933', 'n03938244', 'n03944341', 'n03956157', 'n03970156', 'n03976657', 'n03980874', 'n04004767', 'n04005630', 'n03773504', 'n04009552', 'n04026417', 'n04033901', 'n04033995', 'n04039381', 'n04040759', 'n04041544', 'n04070727', 'n04081281', 'n04086273', 'n04090263', 'n04111531', 'n04125021', 'n04133789', 'n04136333', 'n04141327', 'n04147183', 'n04149813', 'n04153751', 'n04154565', 'n04192698', 'n04208210', 'n04228054', 'n04251144', 'n04252077', 'n04252225', 'n04254777', 'n04259630', 'n04270147', 'n04277352', 'n04286575', 'n04296562', 'n04317175', 'n04328186', 'n04330267', 'n04332243', 'n04336792', 'n04346328', 'n04347754', 'n04350905', 'n04355338', 'n04356056', 'n04356056', 'n04357314', 'n04370456', 'n04371774', 'n04376876', 'n04389033', 'n04398044', 'n04404412', 'n04423845', 'n04429376', 'n04442312', 'n04456115', 'n04465501', 'n04476259', 'n04482393', 'n04483307', 'n04485082', 'n04487081', 'n04487394', 'n04501370', 'n04507155', 'n04509417', 'n04522168', 'n04532106', 'n04532670', 'n04536866', 'n04540053', 'n04548362', 'n04550184', 'n04579432', 'n04596742', 'n04599235', 'n04613696', 'n07565083', 'n07579787', 'n07583066', 'n07584110', 'n07613480', 'n07693725', 'n07695742', 'n07697313', 'n07714990', 'n07715103', 'n07716358', 'n07718472', 'n07718747', 'n07730033', 'n07734744', 'n07745940', 'n07747607', 'n07749582', 'n07753113', 'n07753275', 'n07753592', 'n07754684', 'n07768694', 'n07802026', 'n07831146', 'n07860988', 'n07873807', 'n07880968', 'n07920052', 'n07932039', 'n09229709', 'n09246464', 'n09288635', 'n09399592', 'n09421951', 'n09468604', 'n09472597', 'n11879895', 'n11939491', 'n12144580', 'n12267677', 'n12998815', 'n13037406', 'n13054560']\n",
            "\n",
            "Filtrage du dataset ImageNetV2 (matched-frequency)...\n",
            "Traité 0 images, sauvegardé 1 images\n",
            "Traité 1000 images, sauvegardé 380 images\n",
            "Traité 2000 images, sauvegardé 840 images\n",
            "Traité 3000 images, sauvegardé 1251 images\n",
            "Traité 4000 images, sauvegardé 1661 images\n",
            "Traité 5000 images, sauvegardé 1990 images\n",
            "Traité 6000 images, sauvegardé 2320 images\n",
            "Traité 7000 images, sauvegardé 2670 images\n",
            "Traité 8000 images, sauvegardé 3051 images\n",
            "Traité 9000 images, sauvegardé 3530 images\n",
            "\n",
            "=== Résultats ===\n",
            "Total d'images traitées: 10000\n",
            "Total d'images sauvegardées: 3910\n",
            "  tench (n01440764): 10 images\n",
            "  goldfish (n01443537): 10 images\n",
            "  stingray (n01498041): 10 images\n",
            "  hen (n01514859): 10 images\n",
            "  ostrich (n01518878): 10 images\n",
            "  brambling (n01530575): 10 images\n",
            "  goldfinch (n01531178): 10 images\n",
            "  junco (n01534433): 10 images\n",
            "  bulbul (n01560419): 10 images\n",
            "  jay (n01580077): 10 images\n",
            "  magpie (n01582220): 10 images\n",
            "  chickadee (n01592084): 10 images\n",
            "  vulture (n01616318): 10 images\n",
            "  axolotl (n01632777): 10 images\n",
            "  terrapin (n01667778): 10 images\n",
            "  agama (n01687978): 10 images\n",
            "  triceratops (n01704323): 10 images\n",
            "  trilobite (n01768244): 10 images\n",
            "  harvestman (n01770081): 10 images\n",
            "  scorpion (n01770393): 10 images\n",
            "  tarantula (n01774750): 10 images\n",
            "  tick (n01776313): 10 images\n",
            "  centipede (n01784675): 10 images\n",
            "  ptarmigan (n01796340): 10 images\n",
            "  quail (n01806567): 10 images\n",
            "  partridge (n01807496): 10 images\n",
            "  macaw (n01818515): 10 images\n",
            "  lorikeet (n01820546): 10 images\n",
            "  coucal (n01824575): 10 images\n",
            "  hornbill (n01829413): 10 images\n",
            "  hummingbird (n01833805): 10 images\n",
            "  jacamar (n01843065): 10 images\n",
            "  toucan (n01843383): 10 images\n",
            "  goose (n01855672): 10 images\n",
            "  tusker (n01871265): 10 images\n",
            "  echidna (n01872401): 10 images\n",
            "  platypus (n01873310): 10 images\n",
            "  wallaby (n01877812): 10 images\n",
            "  koala (n01882714): 10 images\n",
            "  wombat (n01883070): 10 images\n",
            "  jellyfish (n01910747): 10 images\n",
            "  flatworm (n01924916): 10 images\n",
            "  nematode (n01930112): 10 images\n",
            "  conch (n01943899): 10 images\n",
            "  snail (n01944390): 10 images\n",
            "  slug (n01945685): 10 images\n",
            "  chiton (n01955084): 10 images\n",
            "  crayfish (n01985128): 10 images\n",
            "  isopod (n01990800): 10 images\n",
            "  spoonbill (n02006656): 10 images\n",
            "  flamingo (n02007558): 10 images\n",
            "  limpkin (n02013706): 10 images\n",
            "  bustard (n02018795): 10 images\n",
            "  dowitcher (n02033041): 10 images\n",
            "  oystercatcher (n02037110): 10 images\n",
            "  pelican (n02051845): 10 images\n",
            "  albatross (n02058221): 10 images\n",
            "  dugong (n02074367): 10 images\n",
            "  Chihuahua (n02085620): 10 images\n",
            "  borzoi (n02090622): 10 images\n",
            "  Saluki (n02091831): 10 images\n",
            "  Weimaraner (n02092339): 10 images\n",
            "  collie (n02106030): 10 images\n",
            "  Rottweiler (n02106550): 10 images\n",
            "  pug (n02110958): 10 images\n",
            "  Samoyed (n02111889): 10 images\n",
            "  Pomeranian (n02112018): 10 images\n",
            "  coyote (n02114855): 10 images\n",
            "  dingo (n02115641): 10 images\n",
            "  dhole (n02115913): 10 images\n",
            "  hyena (n02117135): 10 images\n",
            "  cougar (n02125311): 10 images\n",
            "  lynx (n02127052): 10 images\n",
            "  leopard (n02128385): 10 images\n",
            "  jaguar (n02128925): 10 images\n",
            "  lion (n02129165): 10 images\n",
            "  tiger (n02129604): 10 images\n",
            "  cheetah (n02130308): 10 images\n",
            "  mongoose (n02137549): 10 images\n",
            "  meerkat (n02138441): 10 images\n",
            "  ladybug (n02165456): 10 images\n",
            "  weevil (n02177972): 10 images\n",
            "  fly (n02190166): 10 images\n",
            "  bee (n02206856): 10 images\n",
            "  ant (n02219486): 10 images\n",
            "  grasshopper (n02226429): 10 images\n",
            "  cockroach (n02233338): 10 images\n",
            "  cicada (n02256656): 10 images\n",
            "  leafhopper (n02259212): 10 images\n",
            "  lacewing (n02264363): 10 images\n",
            "  dragonfly (n02268443): 10 images\n",
            "  damselfly (n02268853): 10 images\n",
            "  starfish (n02317335): 10 images\n",
            "  hare (n02326432): 10 images\n",
            "  hamster (n02342885): 10 images\n",
            "  porcupine (n02346627): 10 images\n",
            "  marmot (n02361337): 10 images\n",
            "  beaver (n02363005): 10 images\n",
            "  zebra (n02391049): 10 images\n",
            "  warthog (n02397096): 10 images\n",
            "  hippopotamus (n02398521): 10 images\n",
            "  ox (n02403003): 10 images\n",
            "  bison (n02410509): 10 images\n",
            "  hartebeest (n02422106): 10 images\n",
            "  gazelle (n02423022): 10 images\n",
            "  llama (n02437616): 10 images\n",
            "  weasel (n02441942): 10 images\n",
            "  mink (n02442845): 10 images\n",
            "  otter (n02444819): 10 images\n",
            "  skunk (n02445715): 10 images\n",
            "  badger (n02447366): 10 images\n",
            "  armadillo (n02454379): 10 images\n",
            "  orangutan (n02480495): 10 images\n",
            "  gorilla (n02480855): 10 images\n",
            "  chimpanzee (n02481823): 10 images\n",
            "  gibbon (n02483362): 10 images\n",
            "  siamang (n02483708): 10 images\n",
            "  guenon (n02484975): 10 images\n",
            "  baboon (n02486410): 10 images\n",
            "  macaque (n02487347): 10 images\n",
            "  langur (n02488291): 10 images\n",
            "  marmoset (n02490219): 10 images\n",
            "  indri (n02500267): 10 images\n",
            "  eel (n02526121): 10 images\n",
            "  sturgeon (n02640242): 10 images\n",
            "  lionfish (n02643566): 10 images\n",
            "  abacus (n02666196): 10 images\n",
            "  abaya (n02667093): 10 images\n",
            "  accordion (n02672831): 10 images\n",
            "  airliner (n02690373): 10 images\n",
            "  airship (n02692877): 10 images\n",
            "  altar (n02699494): 10 images\n",
            "  ambulance (n02701002): 10 images\n",
            "  apiary (n02727426): 10 images\n",
            "  apron (n02730930): 10 images\n",
            "  backpack (n02769748): 10 images\n",
            "  bakery (n02776631): 10 images\n",
            "  balloon (n02782093): 10 images\n",
            "  banjo (n02787622): 10 images\n",
            "  barbell (n02790996): 10 images\n",
            "  barbershop (n02791270): 10 images\n",
            "  barn (n02793495): 10 images\n",
            "  barometer (n02794156): 10 images\n",
            "  barrel (n02795169): 10 images\n",
            "  baseball (n02799071): 10 images\n",
            "  basketball (n02802426): 10 images\n",
            "  bassinet (n02804414): 10 images\n",
            "  bassoon (n02804610): 10 images\n",
            "  bathtub (n02808440): 10 images\n",
            "  beaker (n02815834): 10 images\n",
            "  bikini (n02837789): 10 images\n",
            "  binoculars (n02841315): 10 images\n",
            "  birdhouse (n02843684): 10 images\n",
            "  boathouse (n02859443): 10 images\n",
            "  bookcase (n02870880): 10 images\n",
            "  breakwater (n02894605): 10 images\n",
            "  breastplate (n02895154): 10 images\n",
            "  broom (n02906734): 10 images\n",
            "  bucket (n02909870): 10 images\n",
            "  buckle (n02910353): 10 images\n",
            "  candle (n02948072): 10 images\n",
            "  cannon (n02950826): 10 images\n",
            "  canoe (n02951358): 10 images\n",
            "  cardigan (n02963159): 10 images\n",
            "  carousel (n02966193): 10 images\n",
            "  cassette (n02978881): 10 images\n",
            "  castle (n02980441): 10 images\n",
            "  catamaran (n02981792): 10 images\n",
            "  cello (n02992211): 10 images\n",
            "  chain (n02999410): 10 images\n",
            "  chiffonier (n03016953): 10 images\n",
            "  church (n03028079): 10 images\n",
            "  cleaver (n03041632): 10 images\n",
            "  cloak (n03045698): 10 images\n",
            "  convertible (n03100240): 10 images\n",
            "  corkscrew (n03109150): 10 images\n",
            "  cornet (n03110669): 10 images\n",
            "  cradle (n03125729): 10 images\n",
            "  crate (n03127925): 10 images\n",
            "  crutch (n03141823): 10 images\n",
            "  cuirass (n03146219): 10 images\n",
            "  dam (n03160309): 10 images\n",
            "  desk (n03179701): 10 images\n",
            "  diaper (n03188531): 10 images\n",
            "  dishwasher (n03207941): 10 images\n",
            "  dock (n03216828): 10 images\n",
            "  dome (n03220513): 10 images\n",
            "  doormat (n03223299): 10 images\n",
            "  drum (n03249569): 10 images\n",
            "  drumstick (n03250847): 10 images\n",
            "  dumbbell (n03255030): 10 images\n",
            "  envelope (n03291819): 10 images\n",
            "  fireboat (n03344393): 10 images\n",
            "  flagpole (n03355925): 10 images\n",
            "  flute (n03372029): 10 images\n",
            "  forklift (n03384352): 10 images\n",
            "  fountain (n03388043): 10 images\n",
            "  goblet (n03443371): 10 images\n",
            "  go-kart (n03444034): 10 images\n",
            "  gondola (n03447447): 10 images\n",
            "  gong (n03447721): 10 images\n",
            "  gown (n03450230): 10 images\n",
            "  greenhouse (n03457902): 10 images\n",
            "  guillotine (n03467068): 10 images\n",
            "  hammer (n03481172): 10 images\n",
            "  hamper (n03482405): 10 images\n",
            "  handkerchief (n03485794): 10 images\n",
            "  harmonica (n03494278): 10 images\n",
            "  harp (n03495258): 10 images\n",
            "  hatchet (n03498962): 10 images\n",
            "  holster (n03527444): 10 images\n",
            "  honeycomb (n03530642): 10 images\n",
            "  hook (n03532672): 10 images\n",
            "  hourglass (n03544143): 10 images\n",
            "  iPod (n03584254): 10 images\n",
            "  jeep (n03594945): 10 images\n",
            "  joystick (n03602883): 10 images\n",
            "  kimono (n03617480): 10 images\n",
            "  knot (n03627232): 10 images\n",
            "  ladle (n03633091): 10 images\n",
            "  lampshade (n03637318): 10 images\n",
            "  library (n03661043): 10 images\n",
            "  lifeboat (n03662601): 10 images\n",
            "  lighter (n03666591): 10 images\n",
            "  limousine (n03670208): 10 images\n",
            "  lipstick (n03676483): 10 images\n",
            "  lotion (n03690938): 10 images\n",
            "  mailbox (n03710193): 10 images\n",
            "  maraca (n03720891): 10 images\n",
            "  marimba (n03721384): 10 images\n",
            "  mask (n03724870): 10 images\n",
            "  matchstick (n03729826): 10 images\n",
            "  maypole (n03733131): 10 images\n",
            "  maze (n03733281): 10 images\n",
            "  megalith (n03743016): 10 images\n",
            "  microphone (n03759954): 10 images\n",
            "  minibus (n03769881): 10 images\n",
            "  miniskirt (n03770439): 10 images\n",
            "  minivan (n03770679): 10 images\n",
            "  missile (n03773504): 10 images\n",
            "  mitten (n03775071): 10 images\n",
            "  modem (n03777754): 10 images\n",
            "  monastery (n03781244): 10 images\n",
            "  monitor (n03782006): 10 images\n",
            "  moped (n03785016): 10 images\n",
            "  mosque (n03788195): 10 images\n",
            "  mousetrap (n03794056): 10 images\n",
            "  muzzle (n03803284): 10 images\n",
            "  necklace (n03814906): 10 images\n",
            "  obelisk (n03837869): 10 images\n",
            "  oboe (n03838899): 10 images\n",
            "  ocarina (n03840681): 10 images\n",
            "  odometer (n03841143): 10 images\n",
            "  oscilloscope (n03857828): 10 images\n",
            "  overskirt (n03866082): 10 images\n",
            "  paddle (n03873416): 10 images\n",
            "  padlock (n03874599): 10 images\n",
            "  paintbrush (n03876231): 10 images\n",
            "  palace (n03877845): 10 images\n",
            "  parachute (n03888257): 10 images\n",
            "  patio (n03899768): 10 images\n",
            "  pedestal (n03903868): 10 images\n",
            "  perfume (n03916031): 10 images\n",
            "  photocopier (n03924679): 10 images\n",
            "  pier (n03933933): 10 images\n",
            "  pillow (n03938244): 10 images\n",
            "  pinwheel (n03944341): 10 images\n",
            "  planetarium (n03956157): 10 images\n",
            "  plunger (n03970156): 10 images\n",
            "  pole (n03976657): 10 images\n",
            "  poncho (n03980874): 10 images\n",
            "  printer (n04004767): 10 images\n",
            "  prison (n04005630): 10 images\n",
            "  projector (n04009552): 10 images\n",
            "  purse (n04026417): 10 images\n",
            "  quill (n04033901): 10 images\n",
            "  quilt (n04033995): 10 images\n",
            "  racket (n04039381): 10 images\n",
            "  radiator (n04040759): 10 images\n",
            "  radio (n04041544): 10 images\n",
            "  refrigerator (n04070727): 10 images\n",
            "  restaurant (n04081281): 10 images\n",
            "  revolver (n04086273): 10 images\n",
            "  rifle (n04090263): 10 images\n",
            "  rotisserie (n04111531): 10 images\n",
            "  safe (n04125021): 10 images\n",
            "  sandal (n04133789): 10 images\n",
            "  sarong (n04136333): 10 images\n",
            "  scabbard (n04141327): 10 images\n",
            "  schooner (n04147183): 10 images\n",
            "  scoreboard (n04149813): 10 images\n",
            "  screw (n04153751): 10 images\n",
            "  screwdriver (n04154565): 10 images\n",
            "  shield (n04192698): 10 images\n",
            "  shovel (n04208210): 10 images\n",
            "  ski (n04228054): 10 images\n",
            "  snorkel (n04251144): 10 images\n",
            "  snowmobile (n04252077): 10 images\n",
            "  snowplow (n04252225): 10 images\n",
            "  sock (n04254777): 10 images\n",
            "  sombrero (n04259630): 10 images\n",
            "  spatula (n04270147): 10 images\n",
            "  spindle (n04277352): 10 images\n",
            "  spotlight (n04286575): 10 images\n",
            "  stage (n04296562): 10 images\n",
            "  stethoscope (n04317175): 10 images\n",
            "  stopwatch (n04328186): 10 images\n",
            "  stove (n04330267): 10 images\n",
            "  strainer (n04332243): 10 images\n",
            "  stretcher (n04336792): 10 images\n",
            "  stupa (n04346328): 10 images\n",
            "  submarine (n04347754): 10 images\n",
            "  suit (n04350905): 10 images\n",
            "  sundial (n04355338): 10 images\n",
            "  sunglasses (n04356056): 10 images\n",
            "  sunscreen (n04357314): 10 images\n",
            "  sweatshirt (n04370456): 10 images\n",
            "  swing (n04371774): 10 images\n",
            "  syringe (n04376876): 10 images\n",
            "  tank (n04389033): 10 images\n",
            "  teapot (n04398044): 10 images\n",
            "  television (n04404412): 10 images\n",
            "  thimble (n04423845): 10 images\n",
            "  throne (n04429376): 10 images\n",
            "  toaster (n04442312): 10 images\n",
            "  torch (n04456115): 10 images\n",
            "  tractor (n04465501): 10 images\n",
            "  tray (n04476259): 10 images\n",
            "  tricycle (n04482393): 10 images\n",
            "  trimaran (n04483307): 10 images\n",
            "  tripod (n04485082): 10 images\n",
            "  trolleybus (n04487081): 10 images\n",
            "  trombone (n04487394): 10 images\n",
            "  turnstile (n04501370): 10 images\n",
            "  umbrella (n04507155): 10 images\n",
            "  unicycle (n04509417): 10 images\n",
            "  vase (n04522168): 10 images\n",
            "  vestment (n04532106): 10 images\n",
            "  viaduct (n04532670): 10 images\n",
            "  violin (n04536866): 10 images\n",
            "  volleyball (n04540053): 10 images\n",
            "  wallet (n04548362): 10 images\n",
            "  wardrobe (n04550184): 10 images\n",
            "  whistle (n04579432): 10 images\n",
            "  wok (n04596742): 10 images\n",
            "  wool (n04599235): 10 images\n",
            "  yurt (n04613696): 10 images\n",
            "  menu (n07565083): 10 images\n",
            "  plate (n07579787): 10 images\n",
            "  guacamole (n07583066): 10 images\n",
            "  consomme (n07584110): 10 images\n",
            "  trifle (n07613480): 10 images\n",
            "  bagel (n07693725): 10 images\n",
            "  pretzel (n07695742): 10 images\n",
            "  cheeseburger (n07697313): 10 images\n",
            "  broccoli (n07714990): 10 images\n",
            "  cauliflower (n07715103): 10 images\n",
            "  zucchini (n07716358): 10 images\n",
            "  cucumber (n07718472): 10 images\n",
            "  artichoke (n07718747): 10 images\n",
            "  cardoon (n07730033): 10 images\n",
            "  mushroom (n07734744): 10 images\n",
            "  strawberry (n07745940): 10 images\n",
            "  orange (n07747607): 10 images\n",
            "  lemon (n07749582): 10 images\n",
            "  fig (n07753113): 10 images\n",
            "  pineapple (n07753275): 10 images\n",
            "  banana (n07753592): 10 images\n",
            "  jackfruit (n07754684): 10 images\n",
            "  pomegranate (n07768694): 10 images\n",
            "  hay (n07802026): 10 images\n",
            "  carbonara (n07831146): 10 images\n",
            "  dough (n07860988): 10 images\n",
            "  pizza (n07873807): 10 images\n",
            "  burrito (n07880968): 10 images\n",
            "  espresso (n07920052): 10 images\n",
            "  eggnog (n07932039): 10 images\n",
            "  bubble (n09229709): 10 images\n",
            "  cliff (n09246464): 10 images\n",
            "  geyser (n09288635): 10 images\n",
            "  promontory (n09399592): 10 images\n",
            "  sandbar (n09421951): 10 images\n",
            "  valley (n09468604): 10 images\n",
            "  volcano (n09472597): 10 images\n",
            "  rapeseed (n11879895): 10 images\n",
            "  daisy (n11939491): 10 images\n",
            "  corn (n12144580): 10 images\n",
            "  acorn (n12267677): 10 images\n",
            "  agaric (n12998815): 10 images\n",
            "  gyromitra (n13037406): 10 images\n",
            "  bolete (n13054560): 10 images\n",
            "Dataset sauvegardé dans: data\n",
            "\n",
            "DataLoader créé avec 3930 images\n",
            "Classes: ['tench', 'goldfish', 'stingray', 'hen', 'ostrich', 'brambling', 'goldfinch', 'junco', 'bulbul', 'jay', 'magpie', 'chickadee', 'vulture', 'axolotl', 'terrapin', 'agama', 'triceratops', 'trilobite', 'harvestman', 'scorpion', 'tarantula', 'tick', 'centipede', 'ptarmigan', 'quail', 'partridge', 'macaw', 'lorikeet', 'coucal', 'hornbill', 'hummingbird', 'jacamar', 'toucan', 'goose', 'tusker', 'echidna', 'platypus', 'wallaby', 'koala', 'wombat', 'jellyfish', 'flatworm', 'nematode', 'conch', 'snail', 'slug', 'chiton', 'crayfish', 'isopod', 'spoonbill', 'flamingo', 'limpkin', 'bustard', 'dowitcher', 'oystercatcher', 'pelican', 'albatross', 'dugong', 'Chihuahua', 'borzoi', 'Saluki', 'Weimaraner', 'collie', 'Rottweiler', 'pug', 'Samoyed', 'Pomeranian', 'coyote', 'dingo', 'dhole', 'hyena', 'cougar', 'lynx', 'leopard', 'jaguar', 'lion', 'tiger', 'cheetah', 'mongoose', 'meerkat', 'ladybug', 'weevil', 'fly', 'bee', 'ant', 'grasshopper', 'cockroach', 'cicada', 'leafhopper', 'lacewing', 'dragonfly', 'damselfly', 'starfish', 'hare', 'hamster', 'porcupine', 'marmot', 'beaver', 'zebra', 'warthog', 'hippopotamus', 'ox', 'bison', 'hartebeest', 'gazelle', 'llama', 'weasel', 'mink', 'otter', 'skunk', 'badger', 'armadillo', 'orangutan', 'gorilla', 'chimpanzee', 'gibbon', 'siamang', 'guenon', 'baboon', 'macaque', 'langur', 'marmoset', 'indri', 'eel', 'sturgeon', 'lionfish', 'abacus', 'abaya', 'accordion', 'airliner', 'airship', 'altar', 'ambulance', 'apiary', 'apron', 'backpack', 'bakery', 'balloon', 'banjo', 'barbell', 'barbershop', 'barn', 'barometer', 'barrel', 'baseball', 'basketball', 'bassinet', 'bassoon', 'bathtub', 'beaker', 'bikini', 'binoculars', 'birdhouse', 'boathouse', 'bookcase', 'breakwater', 'breastplate', 'broom', 'bucket', 'buckle', 'candle', 'cannon', 'canoe', 'cardigan', 'carousel', 'cassette', 'castle', 'catamaran', 'cello', 'chain', 'chiffonier', 'church', 'cleaver', 'cloak', 'convertible', 'corkscrew', 'cornet', 'cradle', 'crate', 'crutch', 'cuirass', 'dam', 'desk', 'diaper', 'dishwasher', 'dock', 'dome', 'doormat', 'drum', 'drumstick', 'dumbbell', 'envelope', 'fireboat', 'flagpole', 'flute', 'forklift', 'fountain', 'goblet', 'go-kart', 'gondola', 'gong', 'gown', 'greenhouse', 'guillotine', 'hammer', 'hamper', 'handkerchief', 'harmonica', 'harp', 'hatchet', 'holster', 'honeycomb', 'hook', 'hourglass', 'iPod', 'jeep', 'joystick', 'kimono', 'knot', 'ladle', 'lampshade', 'library', 'lifeboat', 'lighter', 'limousine', 'lipstick', 'lotion', 'mailbox', 'maraca', 'marimba', 'mask', 'matchstick', 'maypole', 'maze', 'megalith', 'microphone', 'minibus', 'miniskirt', 'minivan', 'missile', 'mitten', 'modem', 'monastery', 'monitor', 'moped', 'mosque', 'mousetrap', 'muzzle', 'necklace', 'obelisk', 'oboe', 'ocarina', 'odometer', 'oscilloscope', 'overskirt', 'paddle', 'padlock', 'paintbrush', 'palace', 'parachute', 'patio', 'pedestal', 'perfume', 'photocopier', 'pier', 'pillow', 'pinwheel', 'planetarium', 'plunger', 'pole', 'poncho', 'printer', 'prison', 'missile', 'projector', 'purse', 'quill', 'quilt', 'racket', 'radiator', 'radio', 'refrigerator', 'restaurant', 'revolver', 'rifle', 'rotisserie', 'safe', 'sandal', 'sarong', 'scabbard', 'schooner', 'scoreboard', 'screw', 'screwdriver', 'shield', 'shovel', 'ski', 'snorkel', 'snowmobile', 'snowplow', 'sock', 'sombrero', 'spatula', 'spindle', 'spotlight', 'stage', 'stethoscope', 'stopwatch', 'stove', 'strainer', 'stretcher', 'stupa', 'submarine', 'suit', 'sundial', 'sunglasses', 'sunglasses', 'sunscreen', 'sweatshirt', 'swing', 'syringe', 'tank', 'teapot', 'television', 'thimble', 'throne', 'toaster', 'torch', 'tractor', 'tray', 'tricycle', 'trimaran', 'tripod', 'trolleybus', 'trombone', 'turnstile', 'umbrella', 'unicycle', 'vase', 'vestment', 'viaduct', 'violin', 'volleyball', 'wallet', 'wardrobe', 'whistle', 'wok', 'wool', 'yurt', 'menu', 'plate', 'guacamole', 'consomme', 'trifle', 'bagel', 'pretzel', 'cheeseburger', 'broccoli', 'cauliflower', 'zucchini', 'cucumber', 'artichoke', 'cardoon', 'mushroom', 'strawberry', 'orange', 'lemon', 'fig', 'pineapple', 'banana', 'jackfruit', 'pomegranate', 'hay', 'carbonara', 'dough', 'pizza', 'burrito', 'espresso', 'eggnog', 'bubble', 'cliff', 'geyser', 'promontory', 'sandbar', 'valley', 'volcano', 'rapeseed', 'daisy', 'corn', 'acorn', 'agaric', 'gyromitra', 'bolete']\n",
            "Indices ImageNet: [0, 1, 6, 8, 9, 10, 11, 13, 16, 17, 18, 19, 23, 29, 36, 42, 51, 69, 70, 71, 76, 78, 79, 81, 85, 86, 88, 90, 91, 93, 94, 95, 96, 99, 101, 102, 103, 104, 105, 106, 107, 110, 111, 112, 113, 114, 116, 124, 126, 129, 130, 135, 138, 142, 143, 144, 146, 149, 151, 169, 176, 178, 231, 234, 254, 258, 259, 272, 273, 274, 276, 286, 287, 288, 290, 291, 292, 293, 298, 299, 301, 307, 308, 309, 310, 311, 314, 316, 317, 318, 319, 320, 327, 331, 333, 334, 336, 337, 340, 343, 344, 345, 347, 351, 353, 355, 356, 357, 360, 361, 362, 363, 365, 366, 367, 368, 369, 370, 372, 373, 374, 377, 384, 390, 394, 396, 398, 399, 401, 404, 405, 406, 407, 410, 411, 414, 415, 417, 420, 422, 424, 425, 426, 427, 429, 430, 431, 432, 435, 438, 445, 447, 448, 449, 453, 460, 461, 462, 463, 464, 470, 471, 472, 474, 476, 481, 483, 484, 486, 488, 493, 497, 499, 501, 511, 512, 513, 516, 519, 523, 524, 525, 526, 529, 534, 536, 538, 539, 541, 542, 543, 549, 554, 557, 558, 561, 562, 572, 573, 576, 577, 578, 580, 583, 587, 588, 591, 593, 594, 596, 597, 599, 600, 604, 605, 609, 613, 614, 616, 618, 619, 624, 625, 626, 627, 629, 631, 637, 641, 642, 643, 644, 645, 646, 649, 650, 654, 655, 656, 657, 658, 662, 663, 664, 665, 668, 674, 676, 679, 682, 683, 684, 685, 688, 689, 693, 695, 696, 698, 701, 706, 708, 711, 713, 718, 721, 723, 727, 731, 733, 735, 742, 743, 657, 745, 748, 749, 750, 752, 753, 754, 760, 762, 763, 764, 766, 771, 774, 775, 777, 780, 781, 783, 784, 787, 792, 795, 801, 802, 803, 806, 808, 813, 816, 818, 819, 823, 826, 827, 828, 830, 832, 833, 834, 835, 837, 837, 838, 841, 843, 845, 847, 849, 851, 855, 857, 859, 862, 866, 868, 870, 871, 872, 874, 875, 877, 879, 880, 883, 887, 888, 889, 890, 893, 894, 902, 909, 911, 915, 922, 923, 924, 925, 927, 931, 932, 933, 937, 938, 939, 943, 944, 946, 947, 949, 950, 951, 952, 953, 954, 955, 957, 958, 959, 961, 963, 965, 967, 969, 971, 972, 974, 976, 977, 979, 980, 984, 985, 987, 988, 992, 993, 997]\n",
            "WordNet IDs: ['n01440764', 'n01443537', 'n01498041', 'n01514859', 'n01518878', 'n01530575', 'n01531178', 'n01534433', 'n01560419', 'n01580077', 'n01582220', 'n01592084', 'n01616318', 'n01632777', 'n01667778', 'n01687978', 'n01704323', 'n01768244', 'n01770081', 'n01770393', 'n01774750', 'n01776313', 'n01784675', 'n01796340', 'n01806567', 'n01807496', 'n01818515', 'n01820546', 'n01824575', 'n01829413', 'n01833805', 'n01843065', 'n01843383', 'n01855672', 'n01871265', 'n01872401', 'n01873310', 'n01877812', 'n01882714', 'n01883070', 'n01910747', 'n01924916', 'n01930112', 'n01943899', 'n01944390', 'n01945685', 'n01955084', 'n01985128', 'n01990800', 'n02006656', 'n02007558', 'n02013706', 'n02018795', 'n02033041', 'n02037110', 'n02051845', 'n02058221', 'n02074367', 'n02085620', 'n02090622', 'n02091831', 'n02092339', 'n02106030', 'n02106550', 'n02110958', 'n02111889', 'n02112018', 'n02114855', 'n02115641', 'n02115913', 'n02117135', 'n02125311', 'n02127052', 'n02128385', 'n02128925', 'n02129165', 'n02129604', 'n02130308', 'n02137549', 'n02138441', 'n02165456', 'n02177972', 'n02190166', 'n02206856', 'n02219486', 'n02226429', 'n02233338', 'n02256656', 'n02259212', 'n02264363', 'n02268443', 'n02268853', 'n02317335', 'n02326432', 'n02342885', 'n02346627', 'n02361337', 'n02363005', 'n02391049', 'n02397096', 'n02398521', 'n02403003', 'n02410509', 'n02422106', 'n02423022', 'n02437616', 'n02441942', 'n02442845', 'n02444819', 'n02445715', 'n02447366', 'n02454379', 'n02480495', 'n02480855', 'n02481823', 'n02483362', 'n02483708', 'n02484975', 'n02486410', 'n02487347', 'n02488291', 'n02490219', 'n02500267', 'n02526121', 'n02640242', 'n02643566', 'n02666196', 'n02667093', 'n02672831', 'n02690373', 'n02692877', 'n02699494', 'n02701002', 'n02727426', 'n02730930', 'n02769748', 'n02776631', 'n02782093', 'n02787622', 'n02790996', 'n02791270', 'n02793495', 'n02794156', 'n02795169', 'n02799071', 'n02802426', 'n02804414', 'n02804610', 'n02808440', 'n02815834', 'n02837789', 'n02841315', 'n02843684', 'n02859443', 'n02870880', 'n02894605', 'n02895154', 'n02906734', 'n02909870', 'n02910353', 'n02948072', 'n02950826', 'n02951358', 'n02963159', 'n02966193', 'n02978881', 'n02980441', 'n02981792', 'n02992211', 'n02999410', 'n03016953', 'n03028079', 'n03041632', 'n03045698', 'n03100240', 'n03109150', 'n03110669', 'n03125729', 'n03127925', 'n03141823', 'n03146219', 'n03160309', 'n03179701', 'n03188531', 'n03207941', 'n03216828', 'n03220513', 'n03223299', 'n03249569', 'n03250847', 'n03255030', 'n03291819', 'n03344393', 'n03355925', 'n03372029', 'n03384352', 'n03388043', 'n03443371', 'n03444034', 'n03447447', 'n03447721', 'n03450230', 'n03457902', 'n03467068', 'n03481172', 'n03482405', 'n03485794', 'n03494278', 'n03495258', 'n03498962', 'n03527444', 'n03530642', 'n03532672', 'n03544143', 'n03584254', 'n03594945', 'n03602883', 'n03617480', 'n03627232', 'n03633091', 'n03637318', 'n03661043', 'n03662601', 'n03666591', 'n03670208', 'n03676483', 'n03690938', 'n03710193', 'n03720891', 'n03721384', 'n03724870', 'n03729826', 'n03733131', 'n03733281', 'n03743016', 'n03759954', 'n03769881', 'n03770439', 'n03770679', 'n03773504', 'n03775071', 'n03777754', 'n03781244', 'n03782006', 'n03785016', 'n03788195', 'n03794056', 'n03803284', 'n03814906', 'n03837869', 'n03838899', 'n03840681', 'n03841143', 'n03857828', 'n03866082', 'n03873416', 'n03874599', 'n03876231', 'n03877845', 'n03888257', 'n03899768', 'n03903868', 'n03916031', 'n03924679', 'n03933933', 'n03938244', 'n03944341', 'n03956157', 'n03970156', 'n03976657', 'n03980874', 'n04004767', 'n04005630', 'n03773504', 'n04009552', 'n04026417', 'n04033901', 'n04033995', 'n04039381', 'n04040759', 'n04041544', 'n04070727', 'n04081281', 'n04086273', 'n04090263', 'n04111531', 'n04125021', 'n04133789', 'n04136333', 'n04141327', 'n04147183', 'n04149813', 'n04153751', 'n04154565', 'n04192698', 'n04208210', 'n04228054', 'n04251144', 'n04252077', 'n04252225', 'n04254777', 'n04259630', 'n04270147', 'n04277352', 'n04286575', 'n04296562', 'n04317175', 'n04328186', 'n04330267', 'n04332243', 'n04336792', 'n04346328', 'n04347754', 'n04350905', 'n04355338', 'n04356056', 'n04356056', 'n04357314', 'n04370456', 'n04371774', 'n04376876', 'n04389033', 'n04398044', 'n04404412', 'n04423845', 'n04429376', 'n04442312', 'n04456115', 'n04465501', 'n04476259', 'n04482393', 'n04483307', 'n04485082', 'n04487081', 'n04487394', 'n04501370', 'n04507155', 'n04509417', 'n04522168', 'n04532106', 'n04532670', 'n04536866', 'n04540053', 'n04548362', 'n04550184', 'n04579432', 'n04596742', 'n04599235', 'n04613696', 'n07565083', 'n07579787', 'n07583066', 'n07584110', 'n07613480', 'n07693725', 'n07695742', 'n07697313', 'n07714990', 'n07715103', 'n07716358', 'n07718472', 'n07718747', 'n07730033', 'n07734744', 'n07745940', 'n07747607', 'n07749582', 'n07753113', 'n07753275', 'n07753592', 'n07754684', 'n07768694', 'n07802026', 'n07831146', 'n07860988', 'n07873807', 'n07880968', 'n07920052', 'n07932039', 'n09229709', 'n09246464', 'n09288635', 'n09399592', 'n09421951', 'n09468604', 'n09472597', 'n11879895', 'n11939491', 'n12144580', 'n12267677', 'n12998815', 'n13037406', 'n13054560']\n",
            "Répartition: {'tench': 10, 'goldfish': 10, 'stingray': 10, 'hen': 10, 'ostrich': 10, 'brambling': 10, 'goldfinch': 10, 'junco': 10, 'bulbul': 10, 'jay': 10, 'magpie': 10, 'chickadee': 10, 'vulture': 10, 'axolotl': 10, 'terrapin': 10, 'agama': 10, 'triceratops': 10, 'trilobite': 10, 'harvestman': 10, 'scorpion': 10, 'tarantula': 10, 'tick': 10, 'centipede': 10, 'ptarmigan': 10, 'quail': 10, 'partridge': 10, 'macaw': 10, 'lorikeet': 10, 'coucal': 10, 'hornbill': 10, 'hummingbird': 10, 'jacamar': 10, 'toucan': 10, 'goose': 10, 'tusker': 10, 'echidna': 10, 'platypus': 10, 'wallaby': 10, 'koala': 10, 'wombat': 10, 'jellyfish': 10, 'flatworm': 10, 'nematode': 10, 'conch': 10, 'snail': 10, 'slug': 10, 'chiton': 10, 'crayfish': 10, 'isopod': 10, 'spoonbill': 10, 'flamingo': 10, 'limpkin': 10, 'bustard': 10, 'dowitcher': 10, 'oystercatcher': 10, 'pelican': 10, 'albatross': 10, 'dugong': 10, 'Chihuahua': 10, 'borzoi': 10, 'Saluki': 10, 'Weimaraner': 10, 'collie': 10, 'Rottweiler': 10, 'pug': 10, 'Samoyed': 10, 'Pomeranian': 10, 'coyote': 10, 'dingo': 10, 'dhole': 10, 'hyena': 10, 'cougar': 10, 'lynx': 10, 'leopard': 10, 'jaguar': 10, 'lion': 10, 'tiger': 10, 'cheetah': 10, 'mongoose': 10, 'meerkat': 10, 'ladybug': 10, 'weevil': 10, 'fly': 10, 'bee': 10, 'ant': 10, 'grasshopper': 10, 'cockroach': 10, 'cicada': 10, 'leafhopper': 10, 'lacewing': 10, 'dragonfly': 10, 'damselfly': 10, 'starfish': 10, 'hare': 10, 'hamster': 10, 'porcupine': 10, 'marmot': 10, 'beaver': 10, 'zebra': 10, 'warthog': 10, 'hippopotamus': 10, 'ox': 10, 'bison': 10, 'hartebeest': 10, 'gazelle': 10, 'llama': 10, 'weasel': 10, 'mink': 10, 'otter': 10, 'skunk': 10, 'badger': 10, 'armadillo': 10, 'orangutan': 10, 'gorilla': 10, 'chimpanzee': 10, 'gibbon': 10, 'siamang': 10, 'guenon': 10, 'baboon': 10, 'macaque': 10, 'langur': 10, 'marmoset': 10, 'indri': 10, 'eel': 10, 'sturgeon': 10, 'lionfish': 10, 'abacus': 10, 'abaya': 10, 'accordion': 10, 'airliner': 10, 'airship': 10, 'altar': 10, 'ambulance': 10, 'apiary': 10, 'apron': 10, 'backpack': 10, 'bakery': 10, 'balloon': 10, 'banjo': 10, 'barbell': 10, 'barbershop': 10, 'barn': 10, 'barometer': 10, 'barrel': 10, 'baseball': 10, 'basketball': 10, 'bassinet': 10, 'bassoon': 10, 'bathtub': 10, 'beaker': 10, 'bikini': 10, 'binoculars': 10, 'birdhouse': 10, 'boathouse': 10, 'bookcase': 10, 'breakwater': 10, 'breastplate': 10, 'broom': 10, 'bucket': 10, 'buckle': 10, 'candle': 10, 'cannon': 10, 'canoe': 10, 'cardigan': 10, 'carousel': 10, 'cassette': 10, 'castle': 10, 'catamaran': 10, 'cello': 10, 'chain': 10, 'chiffonier': 10, 'church': 10, 'cleaver': 10, 'cloak': 10, 'convertible': 10, 'corkscrew': 10, 'cornet': 10, 'cradle': 10, 'crate': 10, 'crutch': 10, 'cuirass': 10, 'dam': 10, 'desk': 10, 'diaper': 10, 'dishwasher': 10, 'dock': 10, 'dome': 10, 'doormat': 10, 'drum': 10, 'drumstick': 10, 'dumbbell': 10, 'envelope': 10, 'fireboat': 10, 'flagpole': 10, 'flute': 10, 'forklift': 10, 'fountain': 10, 'goblet': 10, 'go-kart': 10, 'gondola': 10, 'gong': 10, 'gown': 10, 'greenhouse': 10, 'guillotine': 10, 'hammer': 10, 'hamper': 10, 'handkerchief': 10, 'harmonica': 10, 'harp': 10, 'hatchet': 10, 'holster': 10, 'honeycomb': 10, 'hook': 10, 'hourglass': 10, 'iPod': 10, 'jeep': 10, 'joystick': 10, 'kimono': 10, 'knot': 10, 'ladle': 10, 'lampshade': 10, 'library': 10, 'lifeboat': 10, 'lighter': 10, 'limousine': 10, 'lipstick': 10, 'lotion': 10, 'mailbox': 10, 'maraca': 10, 'marimba': 10, 'mask': 10, 'matchstick': 10, 'maypole': 10, 'maze': 10, 'megalith': 10, 'microphone': 10, 'minibus': 10, 'miniskirt': 10, 'minivan': 10, 'missile': 10, 'mitten': 10, 'modem': 10, 'monastery': 10, 'monitor': 10, 'moped': 10, 'mosque': 10, 'mousetrap': 10, 'muzzle': 10, 'necklace': 10, 'obelisk': 10, 'oboe': 10, 'ocarina': 10, 'odometer': 10, 'oscilloscope': 10, 'overskirt': 10, 'paddle': 10, 'padlock': 10, 'paintbrush': 10, 'palace': 10, 'parachute': 10, 'patio': 10, 'pedestal': 10, 'perfume': 10, 'photocopier': 10, 'pier': 10, 'pillow': 10, 'pinwheel': 10, 'planetarium': 10, 'plunger': 10, 'pole': 10, 'poncho': 10, 'printer': 10, 'prison': 10, 'projector': 10, 'purse': 10, 'quill': 10, 'quilt': 10, 'racket': 10, 'radiator': 10, 'radio': 10, 'refrigerator': 10, 'restaurant': 10, 'revolver': 10, 'rifle': 10, 'rotisserie': 10, 'safe': 10, 'sandal': 10, 'sarong': 10, 'scabbard': 10, 'schooner': 10, 'scoreboard': 10, 'screw': 10, 'screwdriver': 10, 'shield': 10, 'shovel': 10, 'ski': 10, 'snorkel': 10, 'snowmobile': 10, 'snowplow': 10, 'sock': 10, 'sombrero': 10, 'spatula': 10, 'spindle': 10, 'spotlight': 10, 'stage': 10, 'stethoscope': 10, 'stopwatch': 10, 'stove': 10, 'strainer': 10, 'stretcher': 10, 'stupa': 10, 'submarine': 10, 'suit': 10, 'sundial': 10, 'sunglasses': 10, 'sunscreen': 10, 'sweatshirt': 10, 'swing': 10, 'syringe': 10, 'tank': 10, 'teapot': 10, 'television': 10, 'thimble': 10, 'throne': 10, 'toaster': 10, 'torch': 10, 'tractor': 10, 'tray': 10, 'tricycle': 10, 'trimaran': 10, 'tripod': 10, 'trolleybus': 10, 'trombone': 10, 'turnstile': 10, 'umbrella': 10, 'unicycle': 10, 'vase': 10, 'vestment': 10, 'viaduct': 10, 'violin': 10, 'volleyball': 10, 'wallet': 10, 'wardrobe': 10, 'whistle': 10, 'wok': 10, 'wool': 10, 'yurt': 10, 'menu': 10, 'plate': 10, 'guacamole': 10, 'consomme': 10, 'trifle': 10, 'bagel': 10, 'pretzel': 10, 'cheeseburger': 10, 'broccoli': 10, 'cauliflower': 10, 'zucchini': 10, 'cucumber': 10, 'artichoke': 10, 'cardoon': 10, 'mushroom': 10, 'strawberry': 10, 'orange': 10, 'lemon': 10, 'fig': 10, 'pineapple': 10, 'banana': 10, 'jackfruit': 10, 'pomegranate': 10, 'hay': 10, 'carbonara': 10, 'dough': 10, 'pizza': 10, 'burrito': 10, 'espresso': 10, 'eggnog': 10, 'bubble': 10, 'cliff': 10, 'geyser': 10, 'promontory': 10, 'sandbar': 10, 'valley': 10, 'volcano': 10, 'rapeseed': 10, 'daisy': 10, 'corn': 10, 'acorn': 10, 'agaric': 10, 'gyromitra': 10, 'bolete': 10}\n",
            "Batch 0: torch.Size([16, 3, 224, 224]), Labels: tensor([316, 366, 332, 237, 323,  19, 319, 371,  68,  19, 363, 144, 136, 338,\n",
            "        106, 163])\n",
            "Batch 1: torch.Size([16, 3, 224, 224]), Labels: tensor([192, 196,  26, 255, 216, 288, 347, 124,  76,  58, 187, 247,  26, 288,\n",
            "        261, 336])\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torchvision.transforms as transforms\n",
        "from imagenetv2_pytorch import ImageNetV2Dataset\n",
        "import os\n",
        "from PIL import Image\n",
        "import json\n",
        "\n",
        "def load_imagenet_class_index(json_path=\"imagenet_class_index.json\"):\n",
        "    \"\"\"\n",
        "    Charge le fichier imagenet_class_index.json et retourne les mappings\n",
        "    \n",
        "    Args:\n",
        "        json_path (str): Chemin vers le fichier imagenet_class_index.json\n",
        "    \n",
        "    Returns:\n",
        "        tuple: (idx_to_class, class_to_idx, idx_to_wnid)\n",
        "    \"\"\"\n",
        "    try:\n",
        "        with open(json_path, 'r') as f:\n",
        "            class_index = json.load(f)\n",
        "    except FileNotFoundError:\n",
        "        print(f\"Fichier {json_path} non trouvé. Tentative de téléchargement...\")\n",
        "        # Télécharger le fichier depuis GitHub si pas trouvé\n",
        "        import urllib.request\n",
        "        url = \"https://raw.githubusercontent.com/pytorch/vision/main/torchvision/models/_utils.py\"\n",
        "        # Alternative: utiliser le fichier depuis Hugging Face\n",
        "        url = \"https://huggingface.co/datasets/imagenet-1k/raw/main/imagenet_class_index.json\"\n",
        "        try:\n",
        "            urllib.request.urlretrieve(url, json_path)\n",
        "            with open(json_path, 'r') as f:\n",
        "                class_index = json.load(f)\n",
        "            print(f\"Fichier téléchargé et sauvegardé: {json_path}\")\n",
        "        except:\n",
        "            print(\"Impossible de télécharger le fichier. Veuillez le fournir manuellement.\")\n",
        "            return None, None, None\n",
        "    \n",
        "    # Créer les mappings\n",
        "    idx_to_class = {}  # {0: \"tench\", 1: \"goldfish\", ...}\n",
        "    class_to_idx = {}  # {\"tench\": 0, \"goldfish\": 1, ...}\n",
        "    idx_to_wnid = {}   # {0: \"n01440764\", 1: \"n01443537\", ...}\n",
        "    \n",
        "    for idx_str, (wnid, class_name) in class_index.items():\n",
        "        idx = int(idx_str)\n",
        "        idx_to_class[idx] = class_name\n",
        "        class_to_idx[class_name] = idx\n",
        "        idx_to_wnid[idx] = wnid\n",
        "    \n",
        "    return idx_to_class, class_to_idx, idx_to_wnid\n",
        "\n",
        "def save_filtered_dataset(target_classes, save_dir=\"imagenetv2_filtered\", \n",
        "                         variant=\"matched-frequency\", class_index_path=\"imagenet_class_index.json\"):\n",
        "    \"\"\"\n",
        "    Sauvegarde uniquement les images des classes spécifiées\n",
        "    \n",
        "    Args:\n",
        "        target_classes (list): Liste des noms de classes à filtrer\n",
        "        save_dir (str): Dossier de destination\n",
        "        variant (str): Variante d'ImageNetV2\n",
        "        class_index_path (str): Chemin vers imagenet_class_index.json\n",
        "    \"\"\"\n",
        "    # Charger les mappings ImageNet\n",
        "    idx_to_class, class_to_idx, idx_to_wnid = load_imagenet_class_index(class_index_path)\n",
        "    \n",
        "    if class_to_idx is None:\n",
        "        print(\"Impossible de charger les classes ImageNet\")\n",
        "        return None\n",
        "    \n",
        "    # Vérifier que toutes les classes existent\n",
        "    missing_classes = [cls for cls in target_classes if cls not in class_to_idx]\n",
        "    if missing_classes:\n",
        "        print(f\"ATTENTION: Classes non trouvées dans ImageNet: {missing_classes}\")\n",
        "        print(\"Classes disponibles similaires:\")\n",
        "        for missing in missing_classes:\n",
        "            similar = [cls for cls in class_to_idx.keys() if missing.lower() in cls.lower()]\n",
        "            if similar:\n",
        "                print(f\"  Pour '{missing}': {similar[:5]}\")\n",
        "        \n",
        "        target_classes = [cls for cls in target_classes if cls in class_to_idx]\n",
        "        if not target_classes:\n",
        "            print(\"Aucune classe valide trouvée !\")\n",
        "            return None\n",
        "    \n",
        "    # Obtenir les indices des classes cibles\n",
        "    target_class_indices = [class_to_idx[cls] for cls in target_classes]\n",
        "    target_wnids = [idx_to_wnid[class_to_idx[cls]] for cls in target_classes]\n",
        "    \n",
        "    print(f\"Classes à filtrer: {target_classes}\")\n",
        "    print(f\"Indices correspondants: {target_class_indices}\")\n",
        "    print(f\"WordNet IDs: {target_wnids}\")\n",
        "    \n",
        "    # Créer le dataset sans transformation\n",
        "    dataset = ImageNetV2Dataset(variant=variant, transform=None)\n",
        "    \n",
        "    # Créer le dossier principal\n",
        "    os.makedirs(save_dir, exist_ok=True)\n",
        "    \n",
        "    # Créer des sous-dossiers pour chaque classe\n",
        "    for class_name in target_classes:\n",
        "        class_dir = os.path.join(save_dir, class_name)\n",
        "        os.makedirs(class_dir, exist_ok=True)\n",
        "    \n",
        "    # Compteurs pour chaque classe\n",
        "    class_counts = {idx: 0 for idx in target_class_indices}\n",
        "    total_saved = 0\n",
        "    total_processed = 0\n",
        "    \n",
        "    print(f\"\\nFiltrage du dataset ImageNetV2 ({variant})...\")\n",
        "    \n",
        "    # Parcourir le dataset et filtrer\n",
        "    for i, (image, label) in enumerate(dataset):\n",
        "        total_processed += 1\n",
        "        \n",
        "        if label in target_class_indices:\n",
        "            # Déterminer le nom de la classe\n",
        "            class_idx = target_class_indices.index(label)\n",
        "            class_name = target_classes[class_idx]\n",
        "            \n",
        "            # Chemin de sauvegarde\n",
        "            class_dir = os.path.join(save_dir, class_name)\n",
        "            image_path = os.path.join(class_dir, f\"{class_name}_{class_counts[label]:04d}.jpg\")\n",
        "            \n",
        "            # Sauvegarder l'image\n",
        "            image.save(image_path)\n",
        "            \n",
        "            class_counts[label] += 1\n",
        "            total_saved += 1\n",
        "        \n",
        "        if i % 1000 == 0:\n",
        "            print(f\"Traité {i} images, sauvegardé {total_saved} images\")\n",
        "    \n",
        "    # Sauvegarder les métadonnées\n",
        "    metadata = {\n",
        "        \"classes\": target_classes,\n",
        "        \"class_indices\": target_class_indices,\n",
        "        \"wordnet_ids\": target_wnids,\n",
        "        \"class_mapping\": {cls: {\"index\": class_to_idx[cls], \"wnid\": idx_to_wnid[class_to_idx[cls]]} \n",
        "                         for cls in target_classes},\n",
        "        \"counts\": {target_classes[target_class_indices.index(idx)]: count \n",
        "                  for idx, count in class_counts.items()},\n",
        "        \"total_images\": total_saved,\n",
        "        \"total_processed\": total_processed,\n",
        "        \"variant\": variant\n",
        "    }\n",
        "    \n",
        "    with open(os.path.join(save_dir, \"metadata.json\"), \"w\") as f:\n",
        "        json.dump(metadata, f, indent=2)\n",
        "    \n",
        "    print(f\"\\n=== Résultats ===\")\n",
        "    print(f\"Total d'images traitées: {total_processed}\")\n",
        "    print(f\"Total d'images sauvegardées: {total_saved}\")\n",
        "    for idx, count in class_counts.items():\n",
        "        class_name = target_classes[target_class_indices.index(idx)]\n",
        "        wnid = idx_to_wnid[idx]\n",
        "        print(f\"  {class_name} ({wnid}): {count} images\")\n",
        "    print(f\"Dataset sauvegardé dans: {save_dir}\")\n",
        "    \n",
        "    return save_dir\n",
        "\n",
        "def search_classes(search_term, class_index_path=\"imagenet_class_index.json\", max_results=20):\n",
        "    \"\"\"\n",
        "    Recherche des classes ImageNet par terme\n",
        "    \n",
        "    Args:\n",
        "        search_term (str): Terme de recherche\n",
        "        class_index_path (str): Chemin vers imagenet_class_index.json\n",
        "        max_results (int): Nombre maximum de résultats\n",
        "    \"\"\"\n",
        "    idx_to_class, class_to_idx, idx_to_wnid = load_imagenet_class_index(class_index_path)\n",
        "    \n",
        "    if class_to_idx is None:\n",
        "        return []\n",
        "    \n",
        "    # Recherche insensible à la casse\n",
        "    search_term = search_term.lower()\n",
        "    matches = []\n",
        "    \n",
        "    for class_name, idx in class_to_idx.items():\n",
        "        if search_term in class_name.lower():\n",
        "            wnid = idx_to_wnid[idx]\n",
        "            matches.append({\n",
        "                \"class_name\": class_name,\n",
        "                \"index\": idx,\n",
        "                \"wnid\": wnid\n",
        "            })\n",
        "    \n",
        "    # Trier par index\n",
        "    matches.sort(key=lambda x: x[\"index\"])\n",
        "    \n",
        "    print(f\"Classes contenant '{search_term}' ({len(matches)} trouvées):\")\n",
        "    for i, match in enumerate(matches[:max_results]):\n",
        "        print(f\"  {match['index']:3d}: {match['class_name']} ({match['wnid']})\")\n",
        "    \n",
        "    if len(matches) > max_results:\n",
        "        print(f\"  ... et {len(matches) - max_results} autres\")\n",
        "    \n",
        "    return matches\n",
        "\n",
        "def list_classes_by_category(categories, class_index_path=\"imagenet_class_index.json\"):\n",
        "    \"\"\"\n",
        "    Liste les classes par catégories (animaux, véhicules, etc.)\n",
        "    \n",
        "    Args:\n",
        "        categories (list): Liste de termes de catégorie à rechercher\n",
        "        class_index_path (str): Chemin vers imagenet_class_index.json\n",
        "    \"\"\"\n",
        "    results = {}\n",
        "    \n",
        "    for category in categories:\n",
        "        matches = search_classes(category, class_index_path, max_results=1000)\n",
        "        results[category] = [match[\"class_name\"] for match in matches]\n",
        "    \n",
        "    return results\n",
        "\n",
        "def create_filtered_dataloader(dataset_dir, batch_size=32, num_workers=2, transform=None):\n",
        "    \"\"\"\n",
        "    Crée un DataLoader à partir du dataset filtré sauvegardé\n",
        "    \"\"\"\n",
        "    from torch.utils.data import Dataset, DataLoader\n",
        "    \n",
        "    if transform is None:\n",
        "        transform = transforms.Compose([\n",
        "            transforms.Resize(256),\n",
        "            transforms.CenterCrop(224),\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize(mean=[0.485, 0.456, 0.406], \n",
        "                               std=[0.229, 0.224, 0.225])\n",
        "        ])\n",
        "    \n",
        "    class FilteredImageNetV2(Dataset):\n",
        "        def __init__(self, root_dir, transform=None):\n",
        "            self.root_dir = root_dir\n",
        "            self.transform = transform\n",
        "            self.samples = []\n",
        "            \n",
        "            # Charger les métadonnées\n",
        "            with open(os.path.join(root_dir, \"metadata.json\"), \"r\") as f:\n",
        "                self.metadata = json.load(f)\n",
        "            \n",
        "            self.classes = self.metadata[\"classes\"]\n",
        "            self.class_to_idx = {cls: idx for idx, cls in enumerate(self.classes)}\n",
        "            self.imagenet_indices = self.metadata[\"class_indices\"]\n",
        "            self.wordnet_ids = self.metadata[\"wordnet_ids\"]\n",
        "            \n",
        "            # Construire la liste des échantillons\n",
        "            for class_name in self.classes:\n",
        "                class_dir = os.path.join(root_dir, class_name)\n",
        "                if os.path.exists(class_dir):\n",
        "                    class_idx = self.class_to_idx[class_name]\n",
        "                    \n",
        "                    for img_name in os.listdir(class_dir):\n",
        "                        if img_name.endswith(('.jpg', '.jpeg', '.png')):\n",
        "                            img_path = os.path.join(class_dir, img_name)\n",
        "                            self.samples.append((img_path, class_idx))\n",
        "        \n",
        "        def __len__(self):\n",
        "            return len(self.samples)\n",
        "        \n",
        "        def __getitem__(self, idx):\n",
        "            img_path, label = self.samples[idx]\n",
        "            image = Image.open(img_path).convert('RGB')\n",
        "            \n",
        "            if self.transform:\n",
        "                image = self.transform(image)\n",
        "            \n",
        "            return image, label\n",
        "        \n",
        "        def get_class_info(self):\n",
        "            \"\"\"Retourne les informations détaillées sur les classes\"\"\"\n",
        "            return {\n",
        "                \"classes\": self.classes,\n",
        "                \"imagenet_indices\": self.imagenet_indices,\n",
        "                \"wordnet_ids\": self.wordnet_ids,\n",
        "                \"counts\": self.metadata.get(\"counts\", {}),\n",
        "                \"class_mapping\": self.metadata.get(\"class_mapping\", {})\n",
        "            }\n",
        "    \n",
        "    # Créer le dataset et le dataloader\n",
        "    dataset = FilteredImageNetV2(dataset_dir, transform=transform)\n",
        "    loader = DataLoader(dataset, batch_size=batch_size, num_workers=num_workers, shuffle=True)\n",
        "    \n",
        "    return loader, dataset\n",
        "\n",
        "# Exemples d'utilisation\n",
        "if __name__ == \"__main__\":\n",
        "    # Assurer que le fichier imagenet_class_index.json existe\n",
        "    class_index_file = \"imagenet_class_index.json\"\n",
        "    \n",
        "    # Exemple de contenu du fichier (vous devez créer ce fichier)\n",
        "    if not os.path.exists(class_index_file):\n",
        "        sample_data = {\n",
        "            \"0\": [\"n01440764\", \"tench\"],\n",
        "            \"1\": [\"n01443537\", \"goldfish\"],\n",
        "            \"2\": [\"n01484850\", \"great_white_shark\"],\n",
        "            # ... Ajoutez toutes les 1000 classes ici\n",
        "        }\n",
        "        with open(class_index_file, 'w') as f:\n",
        "            json.dump(sample_data, f, indent=2)\n",
        "        print(f\"Fichier exemple créé: {class_index_file}\")\n",
        "        print(\"Veuillez remplacer par le fichier complet avec les 1000 classes\")\n",
        "    \n",
        "    # Recherche de classes\n",
        "    print(\"=== Recherche de poissons ===\")\n",
        "    search_classes(\"fish\", class_index_file)\n",
        "    \n",
        "    print(\"\\n=== Recherche d'oiseaux ===\")\n",
        "    search_classes(\"bird\", class_index_file)\n",
        "    \n",
        "    # Votre liste de classes dynamique\n",
        "    my_classes =imagenet_classes\n",
        "    \n",
        "    print(f\"\\n=== Filtrage avec les classes: {my_classes} ===\")\n",
        "    save_dir = save_filtered_dataset(my_classes, \"data\", class_index_path=class_index_file)\n",
        "    \n",
        "    if save_dir:\n",
        "        # Créer un DataLoader\n",
        "        loader, dataset = create_filtered_dataloader(save_dir, batch_size=16)\n",
        "        \n",
        "        print(f\"\\nDataLoader créé avec {len(dataset)} images\")\n",
        "        class_info = dataset.get_class_info()\n",
        "        print(f\"Classes: {class_info['classes']}\")\n",
        "        print(f\"Indices ImageNet: {class_info['imagenet_indices']}\")\n",
        "        print(f\"WordNet IDs: {class_info['wordnet_ids']}\")\n",
        "        print(f\"Répartition: {class_info['counts']}\")\n",
        "        \n",
        "        # Test du DataLoader\n",
        "        for batch_idx, (images, labels) in enumerate(loader):\n",
        "            print(f\"Batch {batch_idx}: {images.shape}, Labels: {labels}\")\n",
        "            if batch_idx >= 1:\n",
        "                break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=== INFORMATIONS DATASETS ===\n",
            "CIFAR-10: 10 classes, 60k images (32x32)\n",
            "CIFAR-100: 100 classes, 60k images (32x32)\n",
            "ImageNet: 1000 classes, 1.2M images (train), 50k (val)\n",
            "Open Images: 600+ classes, millions d'images\n",
            "Places365: 365 lieux, 10M images\n",
            "COCO: 80 classes objets + captions, 330k images\n",
            "Food-101: 101 plats, 101k images\n",
            "\n",
            "=== ESPACE DISQUE REQUIS ===\n",
            "CIFAR-10/100: 1 GB\n",
            "Food-101: 5 GB\n",
            "ImageNet (val): 6 GB\n",
            "Open Images (subset): 10 GB\n",
            "Places365: 24 GB\n",
            "COCO 2017: 25 GB\n",
            "ImageNet (complet): 150 GB\n",
            "\n",
            "Mode complet - Peut prendre plusieurs heures et beaucoup d'espace disque!\n",
            "=== TÉLÉCHARGEMENT DES DATASETS ===\n",
            "\n",
            "1. CIFAR-10/100...\n",
            "Téléchargement CIFAR-10...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 170M/170M [00:05<00:00, 32.4MB/s] \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Téléchargement CIFAR-100...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 169M/169M [00:05<00:00, 31.7MB/s] \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CIFAR téléchargé dans './data'\n",
            "\n",
            "2. ImageNet labels...\n",
            "\n",
            "3. Food-101...\n",
            "\n",
            "4. ImageNet validation...\n",
            "Téléchargement d'ImageNet validation set...\n",
            "Téléchargement de https://image-net.org/data/ILSVRC/2012/ILSVRC2012_img_val.tar...\n",
            "Extraction en cours...\n",
            "ImageNet validation téléchargé dans './imagenet_val'\n",
            "\n",
            "5. Open Images subset...\n",
            "\n",
            "6. Places365...\n",
            "\n",
            "7. COCO 2017...\n",
            "\n",
            "8. Setup Kaggle (manuel)...\n",
            "\n",
            "    Pour utiliser Kaggle API:\n",
            "    1. Créez un compte sur kaggle.com\n",
            "    2. Allez dans Account > API > Create New API Token\n",
            "    3. Téléchargez kaggle.json\n",
            "    4. Placez-le dans ~/.kaggle/ (Linux/Mac) ou C:\\Users\\<username>\\.kaggle\\ (Windows)\n",
            "    5. Exécutez: chmod 600 ~/.kaggle/kaggle.json (Linux/Mac)\n",
            "    \n",
            "\n",
            "=== TÉLÉCHARGEMENT TERMINÉ ===\n",
            "Datasets disponibles:\n",
            "- ./data/ : CIFAR-10/100\n",
            "- ./food-101/ : Food-101 (101 classes)\n",
            "- imagenet_labels.txt : Labels ImageNet\n",
            "- ./imagenet_val/ : ImageNet validation\n",
            "- ./open_images/ : Open Images\n",
            "- ./places365/ : Places365\n",
            "- ./coco/ : COCO 2017\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import requests\n",
        "import tarfile\n",
        "import zipfile\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader\n",
        "import wget\n",
        "import kaggle\n",
        "\n",
        "# ===============================\n",
        "# 1. IMAGENET (1000 classes)\n",
        "# ===============================\n",
        "\n",
        "def download_imagenet_val():\n",
        "    \"\"\"\n",
        "    Télécharge ImageNet validation set (50k images, 1000 classes)\n",
        "    Plus petit et plus rapide que le dataset complet\n",
        "    \"\"\"\n",
        "    print(\"Téléchargement d'ImageNet validation set...\")\n",
        "    \n",
        "    # URL pour ImageNet validation\n",
        "    url = \"https://image-net.org/data/ILSVRC/2012/ILSVRC2012_img_val.tar\"\n",
        "    filename = \"ILSVRC2012_img_val.tar\"\n",
        "    \n",
        "    if not os.path.exists(filename):\n",
        "        print(f\"Téléchargement de {url}...\")\n",
        "        wget.download(url, filename)\n",
        "    \n",
        "    # Extraction\n",
        "    if not os.path.exists(\"imagenet_val\"):\n",
        "        print(\"Extraction en cours...\")\n",
        "        with tarfile.open(filename, \"r\") as tar:\n",
        "            tar.extractall(\"imagenet_val\")\n",
        "    \n",
        "    print(\"ImageNet validation téléchargé dans './imagenet_val'\")\n",
        "\n",
        "def download_imagenet_labels():\n",
        "    \"\"\"Télécharge les labels ImageNet\"\"\"\n",
        "    labels_url = \"https://raw.githubusercontent.com/pytorch/hub/master/imagenet_classes.txt\"\n",
        "    \n",
        "    if not os.path.exists(\"imagenet_labels.txt\"):\n",
        "        response = requests.get(labels_url)\n",
        "        with open(\"imagenet_labels.txt\", \"w\") as f:\n",
        "            f.write(response.text)\n",
        "        print(\"Labels ImageNet téléchargés\")\n",
        "\n",
        "# ===============================\n",
        "# 2. CIFAR-10/100 (via torchvision)\n",
        "# ===============================\n",
        "\n",
        "def download_cifar():\n",
        "    \"\"\"Télécharge CIFAR-10 et CIFAR-100\"\"\"\n",
        "    print(\"Téléchargement CIFAR-10...\")\n",
        "    datasets.CIFAR10(root='./data', train=True, download=True)\n",
        "    datasets.CIFAR10(root='./data', train=False, download=True)\n",
        "    \n",
        "    print(\"Téléchargement CIFAR-100...\")\n",
        "    datasets.CIFAR100(root='./data', train=True, download=True)\n",
        "    datasets.CIFAR100(root='./data', train=False, download=True)\n",
        "    \n",
        "    print(\"CIFAR téléchargé dans './data'\")\n",
        "\n",
        "# ===============================\n",
        "# 3. OPEN IMAGES (600 classes)\n",
        "# ===============================\n",
        "\n",
        "def download_open_images_v6():\n",
        "    \"\"\"\n",
        "    Télécharge Open Images V6 (subset)\n",
        "    Plus de 600 classes avec annotations\n",
        "    \"\"\"\n",
        "    print(\"Téléchargement d'Open Images V6...\")\n",
        "    \n",
        "    # URLs pour Open Images\n",
        "    base_url = \"https://storage.googleapis.com/openimages/v6/\"\n",
        "    \n",
        "    files_to_download = [\n",
        "        \"oidv6-train-annotations-bbox.csv\",\n",
        "        \"oidv6-train-images-with-rotation.csv\", \n",
        "        \"class-descriptions-boxable.csv\"\n",
        "    ]\n",
        "    \n",
        "    os.makedirs(\"open_images\", exist_ok=True)\n",
        "    \n",
        "    for file in files_to_download:\n",
        "        if not os.path.exists(f\"open_images/{file}\"):\n",
        "            print(f\"Téléchargement {file}...\")\n",
        "            wget.download(f\"{base_url}{file}\", f\"open_images/{file}\")\n",
        "    \n",
        "    print(\"Open Images métadonnées téléchargées dans './open_images'\")\n",
        "\n",
        "def download_open_images_subset(num_images=1000):\n",
        "    \"\"\"\n",
        "    Télécharge un subset d'images Open Images\n",
        "    \"\"\"\n",
        "    import pandas as pd\n",
        "    \n",
        "    # Lire les annotations\n",
        "    if os.path.exists(\"open_images/oidv6-train-annotations-bbox.csv\"):\n",
        "        df = pd.read_csv(\"open_images/oidv6-train-annotations-bbox.csv\")\n",
        "        \n",
        "        # Prendre les premières images uniques\n",
        "        unique_images = df['ImageID'].unique()[:num_images]\n",
        "        \n",
        "        os.makedirs(\"open_images/images\", exist_ok=True)\n",
        "        \n",
        "        for i, img_id in enumerate(unique_images):\n",
        "            img_url = f\"https://storage.googleapis.com/openimages/v6/train/{img_id}.jpg\"\n",
        "            img_path = f\"open_images/images/{img_id}.jpg\"\n",
        "            \n",
        "            if not os.path.exists(img_path):\n",
        "                try:\n",
        "                    wget.download(img_url, img_path)\n",
        "                    if i % 100 == 0:\n",
        "                        print(f\"Téléchargé {i}/{len(unique_images)} images\")\n",
        "                except:\n",
        "                    continue\n",
        "        \n",
        "        print(f\"Téléchargé {len(unique_images)} images dans './open_images/images'\")\n",
        "\n",
        "# ===============================\n",
        "# 4. PLACES365 (365 classes de lieux)\n",
        "# ===============================\n",
        "\n",
        "def download_places365():\n",
        "    \"\"\"Télécharge Places365 dataset\"\"\"\n",
        "    print(\"Téléchargement de Places365...\")\n",
        "    \n",
        "    # URL pour Places365 (version petite)\n",
        "    url = \"http://data.csail.mit.edu/places/places365/places365standard_easyformat.tar\"\n",
        "    filename = \"places365.tar\"\n",
        "    \n",
        "    if not os.path.exists(filename):\n",
        "        print(\"Téléchargement en cours (peut prendre du temps)...\")\n",
        "        wget.download(url, filename)\n",
        "    \n",
        "    if not os.path.exists(\"places365\"):\n",
        "        print(\"Extraction...\")\n",
        "        with tarfile.open(filename, \"r\") as tar:\n",
        "            tar.extractall(\"places365\")\n",
        "    \n",
        "    print(\"Places365 téléchargé dans './places365'\")\n",
        "\n",
        "# ===============================\n",
        "# 5. COCO (80 classes + captions)\n",
        "# ===============================\n",
        "\n",
        "def download_coco_2017():\n",
        "    \"\"\"Télécharge COCO 2017\"\"\"\n",
        "    print(\"Téléchargement de COCO 2017...\")\n",
        "    \n",
        "    base_url = \"http://images.cocodataset.org/zips/\"\n",
        "    files = [\n",
        "        \"train2017.zip\",\n",
        "        \"val2017.zip\", \n",
        "        \"annotations_trainval2017.zip\"\n",
        "    ]\n",
        "    \n",
        "    os.makedirs(\"coco\", exist_ok=True)\n",
        "    \n",
        "    for file in files:\n",
        "        filepath = f\"coco/{file}\"\n",
        "        if not os.path.exists(filepath):\n",
        "            print(f\"Téléchargement {file}...\")\n",
        "            wget.download(f\"{base_url}{file}\", filepath)\n",
        "            \n",
        "            # Extraction\n",
        "            print(f\"Extraction {file}...\")\n",
        "            with zipfile.ZipFile(filepath, 'r') as zip_ref:\n",
        "                zip_ref.extractall(\"coco\")\n",
        "    \n",
        "    print(\"COCO 2017 téléchargé dans './coco'\")\n",
        "\n",
        "# ===============================\n",
        "# 6. FOOD-101 (101 classes de nourriture)\n",
        "# ===============================\n",
        "\n",
        "def download_food101():\n",
        "    \"\"\"Télécharge Food-101 dataset\"\"\"\n",
        "    print(\"Téléchargement de Food-101...\")\n",
        "    \n",
        "    url = \"http://data.vision.ee.ethz.ch/cvl/food-101.tar.gz\"\n",
        "    filename = \"food-101.tar.gz\"\n",
        "    \n",
        "    if not os.path.exists(filename):\n",
        "        wget.download(url, filename)\n",
        "    \n",
        "    if not os.path.exists(\"food-101\"):\n",
        "        print(\"Extraction...\")\n",
        "        with tarfile.open(filename, \"r:gz\") as tar:\n",
        "            tar.extractall()\n",
        "    \n",
        "    print(\"Food-101 téléchargé dans './food-101'\")\n",
        "\n",
        "# ===============================\n",
        "# 7. KAGGLE DATASETS\n",
        "# ===============================\n",
        "\n",
        "def setup_kaggle():\n",
        "    \"\"\"Instructions pour setup Kaggle API\"\"\"\n",
        "    print(\"\"\"\n",
        "    Pour utiliser Kaggle API:\n",
        "    1. Créez un compte sur kaggle.com\n",
        "    2. Allez dans Account > API > Create New API Token\n",
        "    3. Téléchargez kaggle.json\n",
        "    4. Placez-le dans ~/.kaggle/ (Linux/Mac) ou C:\\\\Users\\\\<username>\\\\.kaggle\\\\ (Windows)\n",
        "    5. Exécutez: chmod 600 ~/.kaggle/kaggle.json (Linux/Mac)\n",
        "    \"\"\")\n",
        "\n",
        "def download_kaggle_datasets():\n",
        "    \"\"\"Télécharge des datasets populaires de Kaggle\"\"\"\n",
        "    popular_datasets = [\n",
        "        \"jessicali9530/stanford-dogs-dataset\",  # 120 races de chiens\n",
        "        \"gpiosenka/100-bird-species\",           # 525 espèces d'oiseaux\n",
        "        \"ashishsaxena2209/animal-image-datasetdog-cat-and-panda\", # Animaux\n",
        "        \"puneet6060/intel-image-classification\", # 6 catégories de paysages\n",
        "        \"alessiocorrado99/animals10\"            # 10 classes d'animaux\n",
        "    ]\n",
        "    \n",
        "    print(\"Téléchargement des datasets Kaggle...\")\n",
        "    \n",
        "    for dataset in popular_datasets:\n",
        "        try:\n",
        "            dataset_name = dataset.split(\"/\")[1]\n",
        "            print(f\"Téléchargement {dataset_name}...\")\n",
        "            kaggle.api.dataset_download_files(dataset, path=f\"kaggle_{dataset_name}\", unzip=True)\n",
        "            print(f\"✓ {dataset_name} téléchargé\")\n",
        "        except Exception as e:\n",
        "            print(f\"✗ Erreur pour {dataset}: {e}\")\n",
        "\n",
        "# ===============================\n",
        "# FONCTION PRINCIPALE\n",
        "# ===============================\n",
        "\n",
        "def download_all_datasets(quick_mode=True):\n",
        "    \"\"\"\n",
        "    Télécharge tous les datasets\n",
        "    \n",
        "    Args:\n",
        "        quick_mode: Si True, télécharge seulement les petits datasets\n",
        "    \"\"\"\n",
        "    print(\"=== TÉLÉCHARGEMENT DES DATASETS ===\\n\")\n",
        "    \n",
        "    # Datasets rapides\n",
        "    print(\"1. CIFAR-10/100...\")\n",
        "    download_cifar()\n",
        "    \n",
        "    print(\"\\n2. ImageNet labels...\")\n",
        "    download_imagenet_labels()\n",
        "    \n",
        "    print(\"\\n3. Food-101...\")\n",
        "    #download_food101()\n",
        "    \n",
        "    if not quick_mode:\n",
        "        print(\"\\n4. ImageNet validation...\")\n",
        "        download_imagenet_val()\n",
        "        \n",
        "        print(\"\\n5. Open Images subset...\")\n",
        "        #download_open_images_v6()\n",
        "        #download_open_images_subset(1000)\n",
        "        \n",
        "        print(\"\\n6. Places365...\")\n",
        "        #download_places365()\n",
        "        \n",
        "        print(\"\\n7. COCO 2017...\")\n",
        "        #download_coco_2017()\n",
        "    \n",
        "    print(\"\\n8. Setup Kaggle (manuel)...\")\n",
        "    setup_kaggle()\n",
        "    \n",
        "    print(\"\\n=== TÉLÉCHARGEMENT TERMINÉ ===\")\n",
        "    print(\"Datasets disponibles:\")\n",
        "    print(\"- ./data/ : CIFAR-10/100\")\n",
        "    print(\"- ./food-101/ : Food-101 (101 classes)\")\n",
        "    print(\"- imagenet_labels.txt : Labels ImageNet\")\n",
        "    \n",
        "    if not quick_mode:\n",
        "        print(\"- ./imagenet_val/ : ImageNet validation\")\n",
        "        print(\"- ./open_images/ : Open Images\")\n",
        "        print(\"- ./places365/ : Places365\")\n",
        "        print(\"- ./coco/ : COCO 2017\")\n",
        "\n",
        "# ===============================\n",
        "# UTILITAIRES\n",
        "# ===============================\n",
        "\n",
        "def list_dataset_info():\n",
        "    \"\"\"Affiche les informations sur les datasets\"\"\"\n",
        "    datasets_info = {\n",
        "        \"CIFAR-10\": \"10 classes, 60k images (32x32)\",\n",
        "        \"CIFAR-100\": \"100 classes, 60k images (32x32)\", \n",
        "        \"ImageNet\": \"1000 classes, 1.2M images (train), 50k (val)\",\n",
        "        \"Open Images\": \"600+ classes, millions d'images\",\n",
        "        \"Places365\": \"365 lieux, 10M images\",\n",
        "        \"COCO\": \"80 classes objets + captions, 330k images\",\n",
        "        \"Food-101\": \"101 plats, 101k images\"\n",
        "    }\n",
        "    \n",
        "    print(\"=== INFORMATIONS DATASETS ===\")\n",
        "    for name, info in datasets_info.items():\n",
        "        print(f\"{name}: {info}\")\n",
        "\n",
        "def estimate_disk_space():\n",
        "    \"\"\"Estime l'espace disque nécessaire\"\"\"\n",
        "    sizes = {\n",
        "        \"CIFAR-10/100\": \"1 GB\",\n",
        "        \"Food-101\": \"5 GB\", \n",
        "        \"ImageNet (val)\": \"6 GB\",\n",
        "        \"Open Images (subset)\": \"10 GB\",\n",
        "        \"Places365\": \"24 GB\",\n",
        "        \"COCO 2017\": \"25 GB\",\n",
        "        \"ImageNet (complet)\": \"150 GB\"\n",
        "    }\n",
        "    \n",
        "    print(\"=== ESPACE DISQUE REQUIS ===\")\n",
        "    for dataset, size in sizes.items():\n",
        "        print(f\"{dataset}: {size}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # Afficher les infos\n",
        "    list_dataset_info()\n",
        "    print()\n",
        "    estimate_disk_space()\n",
        "    print()\n",
        "    \n",
        "    # Choix de téléchargement\n",
        "    choice = input(\"Télécharger en mode rapide (r) ou complet (c) ? [r/c]: \").lower()\n",
        "    \n",
        "    if choice == 'c':\n",
        "        print(\"Mode complet - Peut prendre plusieurs heures et beaucoup d'espace disque!\")\n",
        "        confirm = input(\"Continuer ? [y/n]: \")\n",
        "        if confirm.lower() == 'y':\n",
        "            download_all_datasets(quick_mode=False)\n",
        "    else:\n",
        "        print(\"Mode rapide - Datasets légers seulement\")\n",
        "        download_all_datasets(quick_mode=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting wget\n",
            "  Downloading wget-3.2.zip (10 kB)\n",
            "  Installing build dependencies ... \u001b[?25ldone\n",
            "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
            "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
            "\u001b[?25hBuilding wheels for collected packages: wget\n",
            "  Building wheel for wget (pyproject.toml) ... \u001b[?25ldone\n",
            "\u001b[?25h  Created wheel for wget: filename=wget-3.2-py3-none-any.whl size=9685 sha256=665b98b188758cd085ba5ebdc7d3ce81dccec5f1c3c464e5f5eacb146b88f9bc\n",
            "  Stored in directory: /home/infres/pmbathe-24/.cache/pip/wheels/01/46/3b/e29ffbe4ebe614ff224bad40fc6a5773a67a163251585a13a9\n",
            "Successfully built wget\n",
            "Installing collected packages: wget\n",
            "Successfully installed wget-3.2\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "pip install wget"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🖼️  === TÉLÉCHARGEUR IMAGENET COMPLET ===\n",
            "\n",
            "ImageNet complet contient:\n",
            "- Training: ~1.28M images (1000+ images/classe)\n",
            "- Validation: 50K images (50 images/classe)\n",
            "- Taille totale: ~150 GB\n",
            "\n",
            "Options de téléchargement:\n",
            "1. 🎯 Télécharger via Kaggle (RECOMMANDÉ)\n",
            "2. 🌐 Télécharger depuis le site officiel\n",
            "3. 🔗 Créer script de téléchargement torrent\n",
            "4. 📝 Télécharger échantillon (test)\n",
            "5. 🔍 Vérifier dataset existant\n",
            "6. ℹ️  Créer fichier d'informations\n",
            "7. ❌ Quitter\n",
            "\n",
            "=== TÉLÉCHARGEMENT VIA KAGGLE ===\n",
            "Prérequis:\n",
            "1. pip install kaggle\n",
            "2. Configurer ~/.kaggle/kaggle.json avec votre API key\n",
            "3. Accepter les règles du dataset sur Kaggle\n",
            "🔄 Téléchargement via Kaggle...\n",
            "Dataset URL: https://www.kaggle.com/datasets/c/imagenet-object-localization-challenge\n",
            "❌ Erreur Kaggle: 403 Client Error: Forbidden for url: https://www.kaggle.com/api/v1/datasets/download/c/imagenet-object-localization-challenge?raw=false\n",
            "\n",
            "==================================================\n",
            "\n",
            "Options de téléchargement:\n",
            "1. 🎯 Télécharger via Kaggle (RECOMMANDÉ)\n",
            "2. 🌐 Télécharger depuis le site officiel\n",
            "3. 🔗 Créer script de téléchargement torrent\n",
            "4. 📝 Télécharger échantillon (test)\n",
            "5. 🔍 Vérifier dataset existant\n",
            "6. ℹ️  Créer fichier d'informations\n",
            "7. ❌ Quitter\n",
            "\n",
            "=== TÉLÉCHARGEMENT VIA KAGGLE ===\n",
            "Prérequis:\n",
            "1. pip install kaggle\n",
            "2. Configurer ~/.kaggle/kaggle.json avec votre API key\n",
            "3. Accepter les règles du dataset sur Kaggle\n",
            "\n",
            "==================================================\n",
            "\n",
            "Options de téléchargement:\n",
            "1. 🎯 Télécharger via Kaggle (RECOMMANDÉ)\n",
            "2. 🌐 Télécharger depuis le site officiel\n",
            "3. 🔗 Créer script de téléchargement torrent\n",
            "4. 📝 Télécharger échantillon (test)\n",
            "5. 🔍 Vérifier dataset existant\n",
            "6. ℹ️  Créer fichier d'informations\n",
            "7. ❌ Quitter\n",
            "Option invalide!\n",
            "\n",
            "==================================================\n",
            "\n",
            "Options de téléchargement:\n",
            "1. 🎯 Télécharger via Kaggle (RECOMMANDÉ)\n",
            "2. 🌐 Télécharger depuis le site officiel\n",
            "3. 🔗 Créer script de téléchargement torrent\n",
            "4. 📝 Télécharger échantillon (test)\n",
            "5. 🔍 Vérifier dataset existant\n",
            "6. ℹ️  Créer fichier d'informations\n",
            "7. ❌ Quitter\n",
            "Option invalide!\n",
            "\n",
            "==================================================\n",
            "\n",
            "Options de téléchargement:\n",
            "1. 🎯 Télécharger via Kaggle (RECOMMANDÉ)\n",
            "2. 🌐 Télécharger depuis le site officiel\n",
            "3. 🔗 Créer script de téléchargement torrent\n",
            "4. 📝 Télécharger échantillon (test)\n",
            "5. 🔍 Vérifier dataset existant\n",
            "6. ℹ️  Créer fichier d'informations\n",
            "7. ❌ Quitter\n",
            "\n",
            "=== TÉLÉCHARGEMENT VIA KAGGLE ===\n",
            "Prérequis:\n",
            "1. pip install kaggle\n",
            "2. Configurer ~/.kaggle/kaggle.json avec votre API key\n",
            "3. Accepter les règles du dataset sur Kaggle\n",
            "\n",
            "==================================================\n",
            "\n",
            "Options de téléchargement:\n",
            "1. 🎯 Télécharger via Kaggle (RECOMMANDÉ)\n",
            "2. 🌐 Télécharger depuis le site officiel\n",
            "3. 🔗 Créer script de téléchargement torrent\n",
            "4. 📝 Télécharger échantillon (test)\n",
            "5. 🔍 Vérifier dataset existant\n",
            "6. ℹ️  Créer fichier d'informations\n",
            "7. ❌ Quitter\n",
            "Option invalide!\n",
            "\n",
            "==================================================\n",
            "\n",
            "Options de téléchargement:\n",
            "1. 🎯 Télécharger via Kaggle (RECOMMANDÉ)\n",
            "2. 🌐 Télécharger depuis le site officiel\n",
            "3. 🔗 Créer script de téléchargement torrent\n",
            "4. 📝 Télécharger échantillon (test)\n",
            "5. 🔍 Vérifier dataset existant\n",
            "6. ℹ️  Créer fichier d'informations\n",
            "7. ❌ Quitter\n",
            "\n",
            "=== TÉLÉCHARGEMENT VIA KAGGLE ===\n",
            "Prérequis:\n",
            "1. pip install kaggle\n",
            "2. Configurer ~/.kaggle/kaggle.json avec votre API key\n",
            "3. Accepter les règles du dataset sur Kaggle\n",
            "🔄 Téléchargement via Kaggle...\n",
            "Dataset URL: https://www.kaggle.com/datasets/c/imagenet-object-localization-challenge\n",
            "❌ Erreur Kaggle: 403 Client Error: Forbidden for url: https://www.kaggle.com/api/v1/datasets/download/c/imagenet-object-localization-challenge?raw=false\n",
            "\n",
            "==================================================\n",
            "\n",
            "Options de téléchargement:\n",
            "1. 🎯 Télécharger via Kaggle (RECOMMANDÉ)\n",
            "2. 🌐 Télécharger depuis le site officiel\n",
            "3. 🔗 Créer script de téléchargement torrent\n",
            "4. 📝 Télécharger échantillon (test)\n",
            "5. 🔍 Vérifier dataset existant\n",
            "6. ℹ️  Créer fichier d'informations\n",
            "7. ❌ Quitter\n",
            "\n",
            "=== TÉLÉCHARGEMENT VIA KAGGLE ===\n",
            "Prérequis:\n",
            "1. pip install kaggle\n",
            "2. Configurer ~/.kaggle/kaggle.json avec votre API key\n",
            "3. Accepter les règles du dataset sur Kaggle\n",
            "\n",
            "==================================================\n",
            "\n",
            "Options de téléchargement:\n",
            "1. 🎯 Télécharger via Kaggle (RECOMMANDÉ)\n",
            "2. 🌐 Télécharger depuis le site officiel\n",
            "3. 🔗 Créer script de téléchargement torrent\n",
            "4. 📝 Télécharger échantillon (test)\n",
            "5. 🔍 Vérifier dataset existant\n",
            "6. ℹ️  Créer fichier d'informations\n",
            "7. ❌ Quitter\n",
            "\n",
            "=== TÉLÉCHARGEMENT VIA KAGGLE ===\n",
            "Prérequis:\n",
            "1. pip install kaggle\n",
            "2. Configurer ~/.kaggle/kaggle.json avec votre API key\n",
            "3. Accepter les règles du dataset sur Kaggle\n",
            "\n",
            "==================================================\n",
            "\n",
            "Options de téléchargement:\n",
            "1. 🎯 Télécharger via Kaggle (RECOMMANDÉ)\n",
            "2. 🌐 Télécharger depuis le site officiel\n",
            "3. 🔗 Créer script de téléchargement torrent\n",
            "4. 📝 Télécharger échantillon (test)\n",
            "5. 🔍 Vérifier dataset existant\n",
            "6. ℹ️  Créer fichier d'informations\n",
            "7. ❌ Quitter\n",
            "Option invalide!\n",
            "\n",
            "==================================================\n",
            "\n",
            "Options de téléchargement:\n",
            "1. 🎯 Télécharger via Kaggle (RECOMMANDÉ)\n",
            "2. 🌐 Télécharger depuis le site officiel\n",
            "3. 🔗 Créer script de téléchargement torrent\n",
            "4. 📝 Télécharger échantillon (test)\n",
            "5. 🔍 Vérifier dataset existant\n",
            "6. ℹ️  Créer fichier d'informations\n",
            "7. ❌ Quitter\n",
            "Option invalide!\n",
            "\n",
            "==================================================\n",
            "\n",
            "Options de téléchargement:\n",
            "1. 🎯 Télécharger via Kaggle (RECOMMANDÉ)\n",
            "2. 🌐 Télécharger depuis le site officiel\n",
            "3. 🔗 Créer script de téléchargement torrent\n",
            "4. 📝 Télécharger échantillon (test)\n",
            "5. 🔍 Vérifier dataset existant\n",
            "6. ℹ️  Créer fichier d'informations\n",
            "7. ❌ Quitter\n",
            "Option invalide!\n",
            "\n",
            "==================================================\n",
            "\n",
            "Options de téléchargement:\n",
            "1. 🎯 Télécharger via Kaggle (RECOMMANDÉ)\n",
            "2. 🌐 Télécharger depuis le site officiel\n",
            "3. 🔗 Créer script de téléchargement torrent\n",
            "4. 📝 Télécharger échantillon (test)\n",
            "5. 🔍 Vérifier dataset existant\n",
            "6. ℹ️  Créer fichier d'informations\n",
            "7. ❌ Quitter\n",
            "Option invalide!\n",
            "\n",
            "==================================================\n",
            "\n",
            "Options de téléchargement:\n",
            "1. 🎯 Télécharger via Kaggle (RECOMMANDÉ)\n",
            "2. 🌐 Télécharger depuis le site officiel\n",
            "3. 🔗 Créer script de téléchargement torrent\n",
            "4. 📝 Télécharger échantillon (test)\n",
            "5. 🔍 Vérifier dataset existant\n",
            "6. ℹ️  Créer fichier d'informations\n",
            "7. ❌ Quitter\n",
            "Option invalide!\n",
            "\n",
            "==================================================\n",
            "\n",
            "Options de téléchargement:\n",
            "1. 🎯 Télécharger via Kaggle (RECOMMANDÉ)\n",
            "2. 🌐 Télécharger depuis le site officiel\n",
            "3. 🔗 Créer script de téléchargement torrent\n",
            "4. 📝 Télécharger échantillon (test)\n",
            "5. 🔍 Vérifier dataset existant\n",
            "6. ℹ️  Créer fichier d'informations\n",
            "7. ❌ Quitter\n",
            "Option invalide!\n",
            "\n",
            "==================================================\n",
            "\n",
            "Options de téléchargement:\n",
            "1. 🎯 Télécharger via Kaggle (RECOMMANDÉ)\n",
            "2. 🌐 Télécharger depuis le site officiel\n",
            "3. 🔗 Créer script de téléchargement torrent\n",
            "4. 📝 Télécharger échantillon (test)\n",
            "5. 🔍 Vérifier dataset existant\n",
            "6. ℹ️  Créer fichier d'informations\n",
            "7. ❌ Quitter\n",
            "Option invalide!\n",
            "\n",
            "==================================================\n",
            "\n",
            "Options de téléchargement:\n",
            "1. 🎯 Télécharger via Kaggle (RECOMMANDÉ)\n",
            "2. 🌐 Télécharger depuis le site officiel\n",
            "3. 🔗 Créer script de téléchargement torrent\n",
            "4. 📝 Télécharger échantillon (test)\n",
            "5. 🔍 Vérifier dataset existant\n",
            "6. ℹ️  Créer fichier d'informations\n",
            "7. ❌ Quitter\n",
            "Option invalide!\n",
            "\n",
            "==================================================\n",
            "\n",
            "Options de téléchargement:\n",
            "1. 🎯 Télécharger via Kaggle (RECOMMANDÉ)\n",
            "2. 🌐 Télécharger depuis le site officiel\n",
            "3. 🔗 Créer script de téléchargement torrent\n",
            "4. 📝 Télécharger échantillon (test)\n",
            "5. 🔍 Vérifier dataset existant\n",
            "6. ℹ️  Créer fichier d'informations\n",
            "7. ❌ Quitter\n",
            "Option invalide!\n",
            "\n",
            "==================================================\n",
            "\n",
            "Options de téléchargement:\n",
            "1. 🎯 Télécharger via Kaggle (RECOMMANDÉ)\n",
            "2. 🌐 Télécharger depuis le site officiel\n",
            "3. 🔗 Créer script de téléchargement torrent\n",
            "4. 📝 Télécharger échantillon (test)\n",
            "5. 🔍 Vérifier dataset existant\n",
            "6. ℹ️  Créer fichier d'informations\n",
            "7. ❌ Quitter\n",
            "\n",
            "=== TÉLÉCHARGEMENT VIA KAGGLE ===\n",
            "Prérequis:\n",
            "1. pip install kaggle\n",
            "2. Configurer ~/.kaggle/kaggle.json avec votre API key\n",
            "3. Accepter les règles du dataset sur Kaggle\n",
            "\n",
            "==================================================\n",
            "\n",
            "Options de téléchargement:\n",
            "1. 🎯 Télécharger via Kaggle (RECOMMANDÉ)\n",
            "2. 🌐 Télécharger depuis le site officiel\n",
            "3. 🔗 Créer script de téléchargement torrent\n",
            "4. 📝 Télécharger échantillon (test)\n",
            "5. 🔍 Vérifier dataset existant\n",
            "6. ℹ️  Créer fichier d'informations\n",
            "7. ❌ Quitter\n",
            "\n",
            "=== TÉLÉCHARGEMENT VIA KAGGLE ===\n",
            "Prérequis:\n",
            "1. pip install kaggle\n",
            "2. Configurer ~/.kaggle/kaggle.json avec votre API key\n",
            "3. Accepter les règles du dataset sur Kaggle\n",
            "🔄 Téléchargement via Kaggle...\n",
            "Dataset URL: https://www.kaggle.com/datasets/c/imagenet-object-localization-challenge\n",
            "❌ Erreur Kaggle: 403 Client Error: Forbidden for url: https://www.kaggle.com/api/v1/datasets/download/c/imagenet-object-localization-challenge?raw=false\n",
            "\n",
            "==================================================\n",
            "\n",
            "Options de téléchargement:\n",
            "1. 🎯 Télécharger via Kaggle (RECOMMANDÉ)\n",
            "2. 🌐 Télécharger depuis le site officiel\n",
            "3. 🔗 Créer script de téléchargement torrent\n",
            "4. 📝 Télécharger échantillon (test)\n",
            "5. 🔍 Vérifier dataset existant\n",
            "6. ℹ️  Créer fichier d'informations\n",
            "7. ❌ Quitter\n",
            "\n",
            "=== TÉLÉCHARGEMENT OFFICIEL ===\n",
            "🔄 Téléchargement ImageNet val (site officiel)...\n",
            "⚠️  IMPORTANT: Vous devez:\n",
            "   1. Créer un compte sur image-net.org\n",
            "   2. Accepter les termes d'utilisation\n",
            "   3. Obtenir l'autorisation de téléchargement\n",
            "📦 Extraction du validation set...\n",
            "✓ Validation set extrait et organisé\n",
            "\n",
            "==================================================\n",
            "\n",
            "Options de téléchargement:\n",
            "1. 🎯 Télécharger via Kaggle (RECOMMANDÉ)\n",
            "2. 🌐 Télécharger depuis le site officiel\n",
            "3. 🔗 Créer script de téléchargement torrent\n",
            "4. 📝 Télécharger échantillon (test)\n",
            "5. 🔍 Vérifier dataset existant\n",
            "6. ℹ️  Créer fichier d'informations\n",
            "7. ❌ Quitter\n",
            "Option invalide!\n",
            "\n",
            "==================================================\n",
            "\n",
            "Options de téléchargement:\n",
            "1. 🎯 Télécharger via Kaggle (RECOMMANDÉ)\n",
            "2. 🌐 Télécharger depuis le site officiel\n",
            "3. 🔗 Créer script de téléchargement torrent\n",
            "4. 📝 Télécharger échantillon (test)\n",
            "5. 🔍 Vérifier dataset existant\n",
            "6. ℹ️  Créer fichier d'informations\n",
            "7. ❌ Quitter\n",
            "Option invalide!\n",
            "\n",
            "==================================================\n",
            "\n",
            "Options de téléchargement:\n",
            "1. 🎯 Télécharger via Kaggle (RECOMMANDÉ)\n",
            "2. 🌐 Télécharger depuis le site officiel\n",
            "3. 🔗 Créer script de téléchargement torrent\n",
            "4. 📝 Télécharger échantillon (test)\n",
            "5. 🔍 Vérifier dataset existant\n",
            "6. ℹ️  Créer fichier d'informations\n",
            "7. ❌ Quitter\n",
            "Option invalide!\n",
            "\n",
            "==================================================\n",
            "\n",
            "Options de téléchargement:\n",
            "1. 🎯 Télécharger via Kaggle (RECOMMANDÉ)\n",
            "2. 🌐 Télécharger depuis le site officiel\n",
            "3. 🔗 Créer script de téléchargement torrent\n",
            "4. 📝 Télécharger échantillon (test)\n",
            "5. 🔍 Vérifier dataset existant\n",
            "6. ℹ️  Créer fichier d'informations\n",
            "7. ❌ Quitter\n",
            "Option invalide!\n",
            "\n",
            "==================================================\n",
            "\n",
            "Options de téléchargement:\n",
            "1. 🎯 Télécharger via Kaggle (RECOMMANDÉ)\n",
            "2. 🌐 Télécharger depuis le site officiel\n",
            "3. 🔗 Créer script de téléchargement torrent\n",
            "4. 📝 Télécharger échantillon (test)\n",
            "5. 🔍 Vérifier dataset existant\n",
            "6. ℹ️  Créer fichier d'informations\n",
            "7. ❌ Quitter\n",
            "Option invalide!\n",
            "\n",
            "==================================================\n",
            "\n",
            "Options de téléchargement:\n",
            "1. 🎯 Télécharger via Kaggle (RECOMMANDÉ)\n",
            "2. 🌐 Télécharger depuis le site officiel\n",
            "3. 🔗 Créer script de téléchargement torrent\n",
            "4. 📝 Télécharger échantillon (test)\n",
            "5. 🔍 Vérifier dataset existant\n",
            "6. ℹ️  Créer fichier d'informations\n",
            "7. ❌ Quitter\n",
            "Option invalide!\n",
            "\n",
            "==================================================\n",
            "\n",
            "Options de téléchargement:\n",
            "1. 🎯 Télécharger via Kaggle (RECOMMANDÉ)\n",
            "2. 🌐 Télécharger depuis le site officiel\n",
            "3. 🔗 Créer script de téléchargement torrent\n",
            "4. 📝 Télécharger échantillon (test)\n",
            "5. 🔍 Vérifier dataset existant\n",
            "6. ℹ️  Créer fichier d'informations\n",
            "7. ❌ Quitter\n",
            "Option invalide!\n",
            "\n",
            "==================================================\n",
            "\n",
            "Options de téléchargement:\n",
            "1. 🎯 Télécharger via Kaggle (RECOMMANDÉ)\n",
            "2. 🌐 Télécharger depuis le site officiel\n",
            "3. 🔗 Créer script de téléchargement torrent\n",
            "4. 📝 Télécharger échantillon (test)\n",
            "5. 🔍 Vérifier dataset existant\n",
            "6. ℹ️  Créer fichier d'informations\n",
            "7. ❌ Quitter\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import requests\n",
        "import tarfile\n",
        "import zipfile\n",
        "import json\n",
        "from pathlib import Path\n",
        "import shutil\n",
        "import wget\n",
        "from PIL import Image\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "import concurrent.futures\n",
        "import time\n",
        "\n",
        "class ImageNetDownloader:\n",
        "    def __init__(self):\n",
        "        self.base_dir = Path(\"imagenet_full\")\n",
        "        self.base_dir.mkdir(exist_ok=True)\n",
        "        \n",
        "        # URLs officielles ImageNet (nécessitent inscription)\n",
        "        self.imagenet_urls = {\n",
        "            \"train\": \"https://image-net.org/data/ILSVRC/2012/ILSVRC2012_img_train.tar\",\n",
        "            \"val\": \"https://image-net.org/data/ILSVRC/2012/ILSVRC2012_img_val.tar\",\n",
        "            \"test\": \"https://image-net.org/data/ILSVRC/2012/ILSVRC2012_img_test_v10102019.tar\"\n",
        "        }\n",
        "        \n",
        "        # URLs alternatives (Academic Torrents - plus fiables)\n",
        "        self.academic_torrents_urls = {\n",
        "            \"train\": \"https://academictorrents.com/download/a306397ccf9c2ead27155983c254227c0fd938e2.torrent\",\n",
        "            \"val\": \"https://academictorrents.com/download/5d6d0df7ed81efd49ca99ea4737e0ae5e3a5f2e5.torrent\"\n",
        "        }\n",
        "\n",
        "    def download_imagenet_labels(self):\n",
        "        \"\"\"Télécharge les labels et métadonnées ImageNet\"\"\"\n",
        "        print(\"📋 Téléchargement des labels ImageNet...\")\n",
        "        \n",
        "        # Labels des classes\n",
        "        labels_url = \"https://raw.githubusercontent.com/pytorch/hub/master/imagenet_classes.txt\"\n",
        "        if not os.path.exists(\"imagenet_classes.txt\"):\n",
        "            response = requests.get(labels_url)\n",
        "            with open(\"imagenet_classes.txt\", \"w\") as f:\n",
        "                f.write(response.text)\n",
        "        \n",
        "        # Mapping WordNet ID -> nom de classe\n",
        "        synsets_url = \"https://raw.githubusercontent.com/HoldenCaulfieldRye/caffe/master/data/ilsvrc12/synsets.txt\" \n",
        "        if not os.path.exists(\"synsets.txt\"):\n",
        "            try:\n",
        "                response = requests.get(synsets_url)\n",
        "                with open(\"synsets.txt\", \"w\") as f:\n",
        "                    f.write(response.text)\n",
        "            except:\n",
        "                # Créer manuellement si l'URL ne marche pas\n",
        "                self.create_synsets_file()\n",
        "        \n",
        "        # Charger les labels\n",
        "        with open(\"imagenet_classes.txt\", \"r\") as f:\n",
        "            class_names = [line.strip() for line in f.readlines()]\n",
        "        \n",
        "        print(f\"✓ {len(class_names)} classes chargées\")\n",
        "        return class_names\n",
        "\n",
        "    def create_synsets_file(self):\n",
        "        \"\"\"Crée le fichier synsets.txt avec les WordNet IDs\"\"\"\n",
        "        # Liste des 1000 classes ImageNet avec leurs WordNet IDs\n",
        "        # Ici une version simplifiée - normalement il faut les vrais IDs\n",
        "        synsets = []\n",
        "        for i in range(1000):\n",
        "            synsets.append(f\"n{i+1:08d}\\n\")\n",
        "        \n",
        "        with open(\"synsets.txt\", \"w\") as f:\n",
        "            f.writelines(synsets)\n",
        "\n",
        "    def download_via_kaggle(self):\n",
        "        \"\"\"\n",
        "        Télécharge ImageNet via Kaggle (plus simple et fiable)\n",
        "        Nécessite: pip install kaggle et configuration API\n",
        "        \"\"\"\n",
        "        try:\n",
        "            import kaggle\n",
        "            print(\"🔄 Téléchargement via Kaggle...\")\n",
        "            \n",
        "            # Dataset ImageNet sur Kaggle\n",
        "            kaggle.api.dataset_download_files(\n",
        "                \"c/imagenet-object-localization-challenge\",\n",
        "                path=str(self.base_dir),\n",
        "                unzip=True\n",
        "            )\n",
        "            print(\"✓ ImageNet téléchargé via Kaggle\")\n",
        "            return True\n",
        "            \n",
        "        except Exception as e:\n",
        "            print(f\"❌ Erreur Kaggle: {e}\")\n",
        "            return False\n",
        "\n",
        "    def download_official_imagenet(self, subset=\"val\"):\n",
        "        \"\"\"\n",
        "        Télécharge ImageNet depuis le site officiel\n",
        "        ATTENTION: Nécessite un compte et acceptation des termes\n",
        "        \"\"\"\n",
        "        print(f\"🔄 Téléchargement ImageNet {subset} (site officiel)...\")\n",
        "        print(\"⚠️  IMPORTANT: Vous devez:\")\n",
        "        print(\"   1. Créer un compte sur image-net.org\")\n",
        "        print(\"   2. Accepter les termes d'utilisation\")\n",
        "        print(\"   3. Obtenir l'autorisation de téléchargement\")\n",
        "        \n",
        "        url = self.imagenet_urls[subset]\n",
        "        filename = f\"ILSVRC2012_img_{subset}.tar\"\n",
        "        \n",
        "        if not os.path.exists(filename):\n",
        "            print(f\"Tentative de téléchargement de {filename}...\")\n",
        "            print(\"Si cela échoue, téléchargez manuellement depuis image-net.org\")\n",
        "            \n",
        "            try:\n",
        "                # Téléchargement avec wget (plus robuste pour gros fichiers)\n",
        "                os.system(f\"wget -c {url} -O {filename}\")\n",
        "                \n",
        "                if not os.path.exists(filename) or os.path.getsize(filename) < 1000:\n",
        "                    print(\"❌ Téléchargement échoué - fichier manquant ou corrompu\")\n",
        "                    return False\n",
        "                    \n",
        "            except Exception as e:\n",
        "                print(f\"❌ Erreur: {e}\")\n",
        "                return False\n",
        "        \n",
        "        return True\n",
        "\n",
        "    def extract_and_organize_train_set(self, tar_path):\n",
        "        \"\"\"\n",
        "        Extrait et organise le training set ImageNet\n",
        "        Le training set est déjà organisé par classe (n01440764/, n01443537/, etc.)\n",
        "        \"\"\"\n",
        "        print(\"📦 Extraction du training set...\")\n",
        "        \n",
        "        output_dir = self.base_dir / \"train\"\n",
        "        output_dir.mkdir(exist_ok=True)\n",
        "        \n",
        "        try:\n",
        "            with tarfile.open(tar_path, \"r\") as tar:\n",
        "                # Extraire dans un dossier temporaire\n",
        "                temp_dir = \"temp_train_extract\"\n",
        "                tar.extractall(temp_dir)\n",
        "                \n",
        "                # Le training set contient des tar individuels pour chaque classe\n",
        "                class_tars = list(Path(temp_dir).glob(\"*.tar\"))\n",
        "                print(f\"Trouvé {len(class_tars)} classes à extraire\")\n",
        "                \n",
        "                for class_tar in tqdm(class_tars, desc=\"Extraction classes\"):\n",
        "                    class_name = class_tar.stem  # ex: n01440764\n",
        "                    class_dir = output_dir / class_name\n",
        "                    class_dir.mkdir(exist_ok=True)\n",
        "                    \n",
        "                    # Extraire les images de cette classe\n",
        "                    with tarfile.open(class_tar, \"r\") as class_tar_file:\n",
        "                        class_tar_file.extractall(class_dir)\n",
        "                \n",
        "                # Nettoyer\n",
        "                shutil.rmtree(temp_dir)\n",
        "                print(\"✓ Training set extrait et organisé\")\n",
        "                return True\n",
        "                \n",
        "        except Exception as e:\n",
        "            print(f\"❌ Erreur extraction: {e}\")\n",
        "            return False\n",
        "\n",
        "    def extract_and_organize_val_set(self, tar_path):\n",
        "        \"\"\"\n",
        "        Extrait et organise le validation set ImageNet\n",
        "        Le validation set nécessite le fichier de labels pour l'organisation\n",
        "        \"\"\"\n",
        "        print(\"📦 Extraction du validation set...\")\n",
        "        \n",
        "        # Télécharger les labels de validation\n",
        "        val_labels_url = \"https://raw.githubusercontent.com/soumith/imagenetloader.torch/master/valprep.sh\"\n",
        "        \n",
        "        output_dir = self.base_dir / \"val\"\n",
        "        output_dir.mkdir(exist_ok=True)\n",
        "        \n",
        "        try:\n",
        "            # Extraire toutes les images\n",
        "            with tarfile.open(tar_path, \"r\") as tar:\n",
        "                tar.extractall(output_dir)\n",
        "            \n",
        "            # Télécharger le script de réorganisation\n",
        "            if not os.path.exists(\"valprep.sh\"):\n",
        "                response = requests.get(val_labels_url)\n",
        "                with open(\"valprep.sh\", \"w\") as f:\n",
        "                    f.write(response.text)\n",
        "            \n",
        "            # Exécuter le script de réorganisation\n",
        "            os.system(f\"chmod +x valprep.sh\")\n",
        "            os.system(f\"cd {output_dir} && ../../valprep.sh\")\n",
        "            \n",
        "            print(\"✓ Validation set extrait et organisé\")\n",
        "            return True\n",
        "            \n",
        "        except Exception as e:\n",
        "            print(f\"❌ Erreur extraction validation: {e}\")\n",
        "            return False\n",
        "\n",
        "    def create_alternative_download_script(self):\n",
        "        \"\"\"\n",
        "        Crée un script bash pour téléchargement via Academic Torrents\n",
        "        \"\"\"\n",
        "        script_content = \"\"\"#!/bin/bash\n",
        "\n",
        "# Script de téléchargement ImageNet via Academic Torrents\n",
        "# Plus fiable que le site officiel\n",
        "\n",
        "echo \"=== TÉLÉCHARGEMENT IMAGENET VIA ACADEMIC TORRENTS ===\"\n",
        "echo \"Installation des dépendances...\"\n",
        "\n",
        "# Installer aria2 (client torrent)\n",
        "if ! command -v aria2c &> /dev/null; then\n",
        "    echo \"Installation d'aria2...\"\n",
        "    # Ubuntu/Debian\n",
        "    sudo apt-get update && sudo apt-get install -y aria2\n",
        "    # MacOS\n",
        "    # brew install aria2\n",
        "fi\n",
        "\n",
        "echo \"Téléchargement des fichiers torrent...\"\n",
        "\n",
        "# Télécharger les torrents\n",
        "wget -O imagenet_train.torrent \"https://academictorrents.com/download/a306397ccf9c2ead27155983c254227c0fd938e2.torrent\"\n",
        "wget -O imagenet_val.torrent \"https://academictorrents.com/download/5d6d0df7ed81efd49ca99ea4737e0ae5e3a5f2e5.torrent\"\n",
        "\n",
        "echo \"Démarrage du téléchargement (peut prendre plusieurs heures)...\"\n",
        "\n",
        "# Télécharger via torrent\n",
        "aria2c --seed-time=0 imagenet_train.torrent\n",
        "aria2c --seed-time=0 imagenet_val.torrent\n",
        "\n",
        "echo \"Téléchargement terminé!\"\n",
        "echo \"Exécutez ensuite le script Python pour organiser les fichiers.\"\n",
        "\"\"\"\n",
        "        \n",
        "        with open(\"download_imagenet_torrents.sh\", \"w\") as f:\n",
        "            f.write(script_content)\n",
        "        \n",
        "        os.chmod(\"download_imagenet_torrents.sh\", 0o755)\n",
        "        print(\"✓ Script de téléchargement torrent créé: download_imagenet_torrents.sh\")\n",
        "\n",
        "    def download_sample_dataset(self, num_classes=100, images_per_class=50):\n",
        "        \"\"\"\n",
        "        Télécharge un échantillon d'ImageNet pour tester\n",
        "        Utilise l'API Flickr pour obtenir des images similaires\n",
        "        \"\"\"\n",
        "        print(f\"🔄 Téléchargement d'un échantillon ({num_classes} classes, {images_per_class} images/classe)...\")\n",
        "        \n",
        "        # Charger les noms de classes\n",
        "        class_names = self.download_imagenet_labels()\n",
        "        \n",
        "        sample_dir = Path(\"imagenet_sample\")\n",
        "        sample_dir.mkdir(exist_ok=True)\n",
        "        \n",
        "        # Prendre les premières classes\n",
        "        selected_classes = class_names[:num_classes]\n",
        "        \n",
        "        for i, class_name in enumerate(tqdm(selected_classes, desc=\"Classes\")):\n",
        "            class_dir = sample_dir / f\"{i:03d}_{class_name.replace(' ', '_')}\"\n",
        "            class_dir.mkdir(exist_ok=True)\n",
        "            \n",
        "            # Simuler le téléchargement (placeholder)\n",
        "            # Dans un vrai script, on utiliserait Flickr API ou autre source\n",
        "            print(f\"Classe {i+1}/{num_classes}: {class_name}\")\n",
        "            \n",
        "            # Ici vous pourriez intégrer une vraie API de téléchargement d'images\n",
        "            # Pour l'instant, on crée juste la structure\n",
        "            \n",
        "        print(f\"✓ Structure d'échantillon créée dans {sample_dir}\")\n",
        "\n",
        "    def verify_dataset(self, dataset_path):\n",
        "        \"\"\"Vérifie l'intégrité du dataset téléchargé\"\"\"\n",
        "        print(\"🔍 Vérification du dataset...\")\n",
        "        \n",
        "        dataset_path = Path(dataset_path)\n",
        "        if not dataset_path.exists():\n",
        "            print(f\"❌ Le dossier {dataset_path} n'existe pas\")\n",
        "            return False\n",
        "        \n",
        "        # Compter les classes et images\n",
        "        class_dirs = [d for d in dataset_path.iterdir() if d.is_dir()]\n",
        "        total_images = 0\n",
        "        class_info = []\n",
        "        \n",
        "        for class_dir in class_dirs:\n",
        "            images = list(class_dir.glob(\"*.JPEG\")) + list(class_dir.glob(\"*.jpg\")) + list(class_dir.glob(\"*.png\"))\n",
        "            total_images += len(images)\n",
        "            class_info.append({\n",
        "                \"class\": class_dir.name,\n",
        "                \"images\": len(images)\n",
        "            })\n",
        "        \n",
        "        print(f\"📊 Statistiques:\")\n",
        "        print(f\"   Classes: {len(class_dirs)}\")\n",
        "        print(f\"   Images totales: {total_images}\")\n",
        "        print(f\"   Moyenne par classe: {total_images/len(class_dirs):.1f}\")\n",
        "        \n",
        "        # Afficher quelques exemples\n",
        "        print(f\"📋 Exemples de classes:\")\n",
        "        for info in class_info[:5]:\n",
        "            print(f\"   {info['class']}: {info['images']} images\")\n",
        "        \n",
        "        return True\n",
        "\n",
        "    def create_dataset_info(self):\n",
        "        \"\"\"Crée un fichier d'informations sur le dataset\"\"\"\n",
        "        info = {\n",
        "            \"dataset_name\": \"ImageNet ILSVRC2012\",\n",
        "            \"description\": \"Dataset complet ImageNet avec toutes les images par classe\",\n",
        "            \"num_classes\": 1000,\n",
        "            \"total_train_images\": \"~1,281,167\",\n",
        "            \"total_val_images\": 50000,\n",
        "            \"images_per_val_class\": 50,\n",
        "            \"avg_images_per_train_class\": \"~1,281\",\n",
        "            \"image_format\": \"JPEG\",\n",
        "            \"organization\": {\n",
        "                \"train\": \"train/n{wnid}/{image}.JPEG\", \n",
        "                \"val\": \"val/n{wnid}/{image}.JPEG\"\n",
        "            },\n",
        "            \"source\": \"http://www.image-net.org/\",\n",
        "            \"paper\": \"ImageNet: A Large-Scale Hierarchical Image Database (Deng et al., 2009)\",\n",
        "            \"download_methods\": [\n",
        "                \"Site officiel (nécessite inscription)\",\n",
        "                \"Academic Torrents (recommandé)\",\n",
        "                \"Kaggle (simplifié)\"\n",
        "            ]\n",
        "        }\n",
        "        \n",
        "        with open(\"imagenet_full_info.json\", \"w\") as f:\n",
        "            json.dump(info, f, indent=2)\n",
        "        \n",
        "        print(\"✓ Informations sauvegardées dans imagenet_full_info.json\")\n",
        "\n",
        "def main():\n",
        "    \"\"\"Fonction principale avec menu interactif\"\"\"\n",
        "    downloader = ImageNetDownloader()\n",
        "    \n",
        "    print(\"🖼️  === TÉLÉCHARGEUR IMAGENET COMPLET ===\\n\")\n",
        "    print(\"ImageNet complet contient:\")\n",
        "    print(\"- Training: ~1.28M images (1000+ images/classe)\")\n",
        "    print(\"- Validation: 50K images (50 images/classe)\")\n",
        "    print(\"- Taille totale: ~150 GB\")\n",
        "    print()\n",
        "    \n",
        "    while True:\n",
        "        print(\"Options de téléchargement:\")\n",
        "        print(\"1. 🎯 Télécharger via Kaggle (RECOMMANDÉ)\")\n",
        "        print(\"2. 🌐 Télécharger depuis le site officiel\") \n",
        "        print(\"3. 🔗 Créer script de téléchargement torrent\")\n",
        "        print(\"4. 📝 Télécharger échantillon (test)\")\n",
        "        print(\"5. 🔍 Vérifier dataset existant\")\n",
        "        print(\"6. ℹ️  Créer fichier d'informations\")\n",
        "        print(\"7. ❌ Quitter\")\n",
        "        \n",
        "        choice = input(\"\\nChoisissez une option (1-7): \").strip()\n",
        "        \n",
        "        if choice == \"1\":\n",
        "            print(\"\\n=== TÉLÉCHARGEMENT VIA KAGGLE ===\")\n",
        "            print(\"Prérequis:\")\n",
        "            print(\"1. pip install kaggle\")\n",
        "            print(\"2. Configurer ~/.kaggle/kaggle.json avec votre API key\")\n",
        "            print(\"3. Accepter les règles du dataset sur Kaggle\")\n",
        "            \n",
        "            if input(\"Continuer ? (y/n): \").lower() == 'y':\n",
        "                downloader.download_via_kaggle()\n",
        "        \n",
        "        elif choice == \"2\":\n",
        "            print(\"\\n=== TÉLÉCHARGEMENT OFFICIEL ===\")\n",
        "            subset = input(\"Quel subset ? (train/val/test): \").lower()\n",
        "            if subset in [\"train\", \"val\", \"test\"]:\n",
        "                if downloader.download_official_imagenet(subset):\n",
        "                    # Organiser selon le subset\n",
        "                    tar_file = f\"ILSVRC2012_img_{subset}.tar\"\n",
        "                    if subset == \"train\":\n",
        "                        downloader.extract_and_organize_train_set(tar_file)\n",
        "                    elif subset == \"val\":\n",
        "                        downloader.extract_and_organize_val_set(tar_file)\n",
        "        \n",
        "        elif choice == \"3\":\n",
        "            print(\"\\n=== CRÉATION SCRIPT TORRENT ===\")\n",
        "            downloader.create_alternative_download_script()\n",
        "            print(\"Exécutez: ./download_imagenet_torrents.sh\")\n",
        "        \n",
        "        elif choice == \"4\":\n",
        "            print(\"\\n=== ÉCHANTILLON DE TEST ===\")\n",
        "            num_classes = int(input(\"Nombre de classes (défaut 10): \") or \"10\")\n",
        "            images_per_class = int(input(\"Images par classe (défaut 20): \") or \"20\")\n",
        "            downloader.download_sample_dataset(num_classes, images_per_class)\n",
        "        \n",
        "        elif choice == \"5\":\n",
        "            print(\"\\n=== VÉRIFICATION DATASET ===\")\n",
        "            path = input(\"Chemin du dataset: \").strip() or \"imagenet_full\"\n",
        "            downloader.verify_dataset(path)\n",
        "        \n",
        "        elif choice == \"6\":\n",
        "            print(\"\\n=== CRÉATION INFOS ===\")\n",
        "            downloader.create_dataset_info()\n",
        "        \n",
        "        elif choice == \"7\":\n",
        "            print(\"Au revoir!\")\n",
        "            break\n",
        "        \n",
        "        else:\n",
        "            print(\"Option invalide!\")\n",
        "        \n",
        "        print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "Prompt Engineering for ImageNet.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "085d5388abda4202bfa66d0c088452f8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": "initial"
          }
        },
        "179b8ae1eb7f4a828f953e889b141725": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": "initial"
          }
        },
        "392656f01b2945f3bd7903783ed8cc96": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "412dd15f0d8542f5ab2730f8616fb582": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "100%",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f75124b64aa147c693c67a78f8e3a231",
            "max": 1000,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_085d5388abda4202bfa66d0c088452f8",
            "value": 1000
          }
        },
        "41b1ed6b0a9745c1a595377670b15ff4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8764308b948745f1a677332fd21fcaf0",
            "placeholder": "​",
            "style": "IPY_MODEL_800e30f5b4f24475a2b0046da0703631",
            "value": " 313/313 [02:31&lt;00:00,  2.07it/s]"
          }
        },
        "5e6315f36b4e4eeea5c6294b024e0c97": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_dc6d1416c01a4047935ee15c3fd2eb1c",
            "placeholder": "​",
            "style": "IPY_MODEL_6e5676a054874243b55fc6d120a07d01",
            "value": " 1000/1000 [16:51&lt;00:00,  1.01s/it]"
          }
        },
        "610b775178c645e2b4663b77cc0c67b6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "66a1639713ae441d8a9b873381f9d774": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_412dd15f0d8542f5ab2730f8616fb582",
              "IPY_MODEL_5e6315f36b4e4eeea5c6294b024e0c97"
            ],
            "layout": "IPY_MODEL_610b775178c645e2b4663b77cc0c67b6"
          }
        },
        "6e5676a054874243b55fc6d120a07d01": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "800e30f5b4f24475a2b0046da0703631": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "84f80a7f3e764346969a347b0f71b24e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_8e47a435519b4ce090879b4be2f61f99",
              "IPY_MODEL_41b1ed6b0a9745c1a595377670b15ff4"
            ],
            "layout": "IPY_MODEL_392656f01b2945f3bd7903783ed8cc96"
          }
        },
        "8764308b948745f1a677332fd21fcaf0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8e47a435519b4ce090879b4be2f61f99": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "100%",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d8708e8414fd44f4abd6590c9b57996f",
            "max": 313,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_179b8ae1eb7f4a828f953e889b141725",
            "value": 313
          }
        },
        "d8708e8414fd44f4abd6590c9b57996f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dc6d1416c01a4047935ee15c3fd2eb1c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f75124b64aa147c693c67a78f8e3a231": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
