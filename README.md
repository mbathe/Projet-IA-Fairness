# Grad-ECLIP: Explainable CLIP via Gradient-based Attention Analysis

Ce projet reproduit et impl√©mente la m√©thode **Grad-ECLIP** d√©crite dans l'article scientifique 2502.18816v1.pdf, qui propose une approche novatrice pour expliquer les d√©cisions du mod√®le CLIP (Contrastive Language-Image Pre-Training) en utilisant les gradients des couches d'attention.

## Liste des auteurs par ordre de contribution au projet
Les contributeurs sont pr√©sent√©s ci-dessous par ordre d√©croissant de leur niveau d'implication dans le projet :

* Mbathe Mekontchou Paul (Contributeur principal)
* Ouhiba Aymen
* Wande Wula Alfred
* Vu Julien
* Garra Nohalia


##  Table des mati√®res

- Vue d'ensemble
- Structure du projet
- Installation
- T√©l√©chargement des donn√©es
- Notebooks principaux
- M√©thodes d'explication compar√©es
- √âvaluation sur ImageNet
- Documentation et rapport
- Contribution
- R√©f√©rences

##  Vue d'ensemble

### Qu'est-ce que Grad-ECLIP ?

**Grad-ECLIP** est une m√©thode d'explicabilit√© pour les mod√®les vision-langage, sp√©cifiquement con√ßue pour CLIP. Elle utilise les **gradients des couches d'attention** pour g√©n√©rer des cartes de saillance qui expliquent :

- **Pourquoi** une image correspond √† un texte donn√©
- **Quelles parties** de l'image sont importantes pour cette correspondance
- **Comment** le mod√®le interpr√®te la relation image-texte
- **Quels mots** du texte sont les plus pertinents pour l'image

### Avantages de Grad-ECLIP

-  **Simplicit√©** : M√©thode directe bas√©e sur les gradients
-  **Efficacit√©** : Pas de r√©entra√Ænement n√©cessaire
-  **Polyvalence** : Applicable aux branches image ET texte
-  **Performance** : Surpasse les m√©thodes existantes sur les benchmarks
-  **Interpr√©tabilit√©** : Visualisations claires et intuitives

##  Structure du projet

```
‚îú‚îÄ‚îÄ 2502.18816v1.pdf                    #  Article scientifique de r√©f√©rence
‚îú‚îÄ‚îÄ rapport_projet_bgdia708_grad_clip.pdf  #  Rapport complet du projet
‚îú‚îÄ‚îÄ README.md                           #  Ce fichier
‚îú‚îÄ‚îÄ requirements.txt                    #  D√©pendances Python
‚îú‚îÄ‚îÄ download_dataset.ipynb              # Notebook pour le t√©l√©chargement des datasets
‚îú‚îÄ‚îÄ valprep.sh                         #  Script d'organisation ImageNet
‚îú‚îÄ‚îÄ imagenet_class_index.json          #  Index des classes ImageNet
‚îú‚îÄ‚îÄ imagenet_labels.txt                #  Labels ImageNet
‚îú‚îÄ‚îÄ textual_explanation.png            #  Explications textuelles
‚îú‚îÄ‚îÄ whippet.png                        #  Image d'exemple
‚îÇ
‚îú‚îÄ‚îÄ CLIP/                              # Implementation CLIP originale
‚îÇ   ‚îú‚îÄ‚îÄ clip/                          # Module CLIP core
‚îÇ   ‚îú‚îÄ‚îÄ notebooks/                     # Notebooks d'exemple CLIP
‚îÇ   ‚îî‚îÄ‚îÄ requirements.txt               # D√©pendances CLIP
‚îÇ
‚îú‚îÄ‚îÄ Grad_ECLIP/                         # üöÄ Notre implementation principale
‚îÇ   ‚îú‚îÄ‚îÄ  Notebooks d'explication
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ grad_eclip_image.ipynb     # Explication image‚Üítexte
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ grad_eclip_text.ipynb      # Explication texte‚Üíimage
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ compare_visualize.ipynb     # Comparaison des m√©thodes
‚îÇ   ‚îÇ
‚îÇ   ‚îú‚îÄ‚îÄ  Notebooks d'√©valuation
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ imagenet_eval_deletion.ipynb    # Test de suppression
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ imagenet_eval_insertion.ipynb   # Test d'insertion
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ grad_eclip_finetuning.ipynb               # Fine-tuning des mod√®les
‚îÇ   ‚îÇ
‚îÇ   ‚îú‚îÄ‚îÄ  Scripts utilitaires
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ clip_utils.py               # Utilitaires CLIP
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ generate_emap.py            # G√©n√©ration des cartes d'explication
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ imagenet_metadata.py        # M√©tadonn√©es ImageNet
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ insertion_evaluation_results.csv # R√©sultats √©valuation
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ test.py                     # Scripts de test
‚îÇ   ‚îÇ
‚îÇ   ‚îú‚îÄ‚îÄ  M√©thodes compar√©es
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ BLIP/                       # BLIP implementation
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ blip_vit.py
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ med.py
‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ vit.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ CLIP_Surgery/               # CLIP Surgery method
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ clip_utils.py
‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ pytorch_clip_guided_diffusion/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ Game_MM_CLIP/              # GAME-MM method
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ models/
‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ utils/
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ M2IB/                      # M2IB method
‚îÇ   ‚îÇ       ‚îú‚îÄ‚îÄ model.py
‚îÇ   ‚îÇ       ‚îî‚îÄ‚îÄ utils.py
‚îÇ   ‚îÇ
‚îÇ   ‚îú‚îÄ‚îÄ  Donn√©es et r√©sultats
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ data/val/                   # Dataset de validation ImageNet
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ images/                     # Images d'exemple
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ outfile/                    # R√©sultats de sortie
‚îÇ   ‚îÇ
‚îÇ   ‚îî‚îÄ‚îÄ  Notebooks de d√©veloppement
‚îÇ       ‚îú‚îÄ‚îÄ pynvml_checkpoints/         # Points de contr√¥le
‚îÇ       ‚îî‚îÄ‚îÄ adaptation_vit.ipynb        # Adaptation Vision Transformer
‚îÇ
‚îî‚îÄ‚îÄ outfile/                           #  R√©sultats globaux du projet
```

## üõ† Installation

### Pr√©requis

- **Python 3.8+**
- **CUDA 11.0+** (recommand√© pour GPU)
- **Git**
- **Jupyter Notebook**
- **8GB+ RAM** (16GB recommand√©)
- **GPU avec 4GB+ VRAM** (optionnel mais recommand√©)

### Installation des d√©pendances

```bash
# Cloner le repository
git clone https://github.com/mbathe/Projet-IA-Fairness.git
cd Projet-IA-Fairness

# Cr√©er un environnement virtuel (recommand√©)
python -m venv grad_eclip_env
source grad_eclip_env/bin/activate  # Linux/Mac
# ou
grad_eclip_env\Scripts\activate     # Windows

# Installer les d√©pendances principales
pip install -r requirements.txt

# Installer CLIP
cd CLIP
pip install -r requirements.txt
cd ..

# Installer les d√©pendances sp√©cifiques Grad-ECLIP
cd Grad_CLIP
pip install torch torchvision torchaudio
pip install transformers
pip install opencv-python
pip install matplotlib seaborn
pip install numpy pandas
pip install scikit-learn
pip install Pillow
pip install tqdm
cd ..
```

### V√©rification de l'installation

```bash
# Test rapide
python -c "import torch; import clip; print('Installation r√©ussie!')"
```

##  T√©l√©chargement des donn√©es

### Dataset principal : ImageNet

Le projet utilise **ImageNet ILSVRC2012** pour l'√©valuation quantitative. Utilisez le notebook download_dataset.ipynb pour t√©l√©charger automatiquement les donn√©es :

```bash
# Lancer le notebook de t√©l√©chargement
jupyter notebook download_dataset.ipynb
```

### Options de t√©l√©chargement disponibles

#### 1.  **Kaggle** (Recommand√©)
```python
# Configuration requise
kaggle_username = "votre_username"
kaggle_key = "votre_api_key"

# T√©l√©chargement automatique via API Kaggle
# Le notebook g√®re automatiquement l'extraction et l'organisation
```

#### 2.  **Site officiel ImageNet**
```python
# N√©cessite inscription sur image-net.org
# T√©l√©chargement manuel puis traitement automatique
```

#### 3.  **Academic Torrents**
```python
# Plus fiable pour de gros volumes
# T√©l√©chargement via protocole torrent
```

#### 4.  **√âchantillon de test**
```python
# Dataset r√©duit pour d√©veloppement et tests rapides
# ~100 images par classe sur 10 classes
```

### Organisation automatique des donn√©es

Une fois t√©l√©charg√©, utilisez le script valprep.sh pour organiser le validation set :

```bash
# Rendre le script ex√©cutable
chmod +x valprep.sh

# Organiser les donn√©es de validation ImageNet
bash valprep.sh

# Structure finale attendue :
# Grad_CLIP/data/val/
# ‚îú‚îÄ‚îÄ n01440764/  # tench
# ‚îú‚îÄ‚îÄ n01443537/  # goldfish  
# ‚îú‚îÄ‚îÄ n01484850/  # great white shark
# ‚îî‚îÄ‚îÄ ... (1000 classes au total)
```

### Datasets suppl√©mentaires

Le projet supporte √©galement :
- **MS-COCO** : Pour l'√©valuation sur des sc√®nes complexes
- **ImageNet-V2** : Version am√©lior√©e d'ImageNet
- **Conceptual Captions** : Paires image-texte

## üìì Notebooks principaux

### 1. `grad_eclip_image.ipynb` 
** Explication des images par le texte**

Ce notebook impl√©mente l'algorithme principal de Grad-ECLIP pour expliquer pourquoi une image correspond √† un texte donn√©.

**Fonctionnalit√©s :**
- G√©n√©ration de cartes de saillance pour les images
- Visualisation des r√©gions importantes avec heatmaps
- Superposition des explications sur l'image originale
- Comparaison avec les m√©thodes baseline
- Export des r√©sultats en haute r√©solution

**Exemple d'utilisation :**
```python
# Charger une image et un texte
image = load_image("whippet.png")
text = "a photo of a whippet dog"

# G√©n√©rer l'explication Grad-ECLIP
explanation_map = grad_eclip_explain_image(model, image, text)

# Visualiser avec diff√©rents modes
visualize_explanation(image, explanation_map, mode='heatmap')
visualize_explanation(image, explanation_map, mode='overlay')
visualize_explanation(image, explanation_map, mode='masked')
```

**Sorties g√©n√©r√©es :**
- Cartes de saillance color√©es
- Images avec r√©gions importantes surlign√©es  
- Graphiques de distribution des scores d'attention
- Comparaisons c√¥te-√†-c√¥te avec autres m√©thodes

### 2. `grad_eclip_text.ipynb`
**üìù Explication du texte par l'image**

Ce notebook impl√©mente l'explication inverse : quels mots du texte sont importants pour la correspondance avec l'image.

**Fonctionnalit√©s :**
- Attribution d'importance aux tokens textuels
- Visualisation des mots-cl√©s avec codes couleur
- Analyse de la contribution de chaque mot
- G√©n√©ration de nuages de mots pond√©r√©s
- Export des explications textuelles

**Exemple d'utilisation :**
```python
# Expliquer l'importance des mots
text = "a small brown and white dog running in the grass"
image = load_image("dog_running.jpg")

# G√©n√©rer l'explication textuelle
text_explanation = grad_eclip_explain_text(model, image, text)

# Visualiser les mots importants
visualize_text_importance(text, text_explanation)
# Sortie : "a small [BROWN] and [WHITE] [DOG] running in the [GRASS]"
# (mots en majuscules = plus importants)
```

**Analyses disponibles :**
- Heatmap des tokens par importance
- Graphiques de contribution relative
- Analyse syntaxique des mots importants
- Comparaison avec les mod√®les de langue

### 3. `compare_visualize.ipynb`
**üîç Comparaison des m√©thodes d'explication**

Ce notebook compare Grad-ECLIP avec les autres m√©thodes d'explicabilit√© disponibles sur les m√™mes exemples.

**M√©thodes compar√©es :**
- **Grad-ECLIP** (notre m√©thode)
- **BLIP** : Bootstrapping Language-Image Pre-training
- **CLIP Surgery** : Modification architecturale de CLIP
- **GAME-MM** : Gradient-weighted Class Activation Mapping
- **M2IB** : Multi-Modal Information Bottleneck



##  M√©thodes d'explication compar√©es

### Grad-ECLIP (Notre m√©thode) üèÜ
**Localisation :** generate_emap.py

- **Principe** : Utilise les gradients des couches d'attention de CLIP
- **Innovation** : Premi√®re m√©thode √† exploiter sp√©cifiquement les gradients d'attention cross-modale
- **Avantages** : 
  - Simple √† impl√©menter
  - Pas de modification du mod√®le original
  - Applicable aux deux modalit√©s (image et texte)
  - R√©sultats interpr√©tables
- **Algorithme** :
  ```python
  def grad_eclip(model, image, text):
      # 1. Forward pass avec gradient tracking
      logits = model(image, text)
      
      # 2. Backward pass pour calculer les gradients
      grad = torch.autograd.grad(logits, model.attention_weights)
      
      # 3. Pond√©ration des cartes d'attention par les gradients
      explanation = grad * model.attention_weights
      
      return explanation
  ```

### BLIP üîµ
**Localisation :** BLIP

- **Principe** : Bootstrap vision-language understanding avec captioning
- **Architecture** : Vision Transformer + BERT multimodal
- **Fichiers principaux** :
  - `blip_vit.py` : Vision Transformer adapt√©
  - `med.py` : Encodeur multimodal
  - `vit.py` : Implementation ViT

### CLIP Surgery 
**Localisation :** CLIP_Surgery

- **Principe** : Modification architecturale de CLIP pour am√©liorer la localisation
- **M√©thode** : Remplace les couches d'attention par des versions "chirurgicales"
- **Fichiers** :
  - `clip_utils.py` : Utilitaires modifi√©s
  - `pytorch_clip_guided_diffusion/` : Integration avec diffusion

### GAME-MM 
**Localisation :** Game_MM_CLIP

- **Principe** : Gradient-weighted Class Activation Mapping pour le multimodal
- **Extension** : Adapte Grad-CAM aux mod√®les vision-langage
- **Structure** :
  - `models/` : Architectures de mod√®les
  - `utils/` : Fonctions utilitaires

### M2IB 
**Localisation :** M2IB

- **Principe** : Multi-Modal Information Bottleneck
- **Th√©orie** : Minimise l'information mutuelle tout en pr√©servant la performance
- **Impl√©mentation** :
  - `model.py` : Architecture M2IB
  - `utils.py` : Fonctions de support

##  √âvaluation sur ImageNet

### Classes et templates ImageNet

Le projet utilise les **1000 classes standard d'ImageNet** avec **80 templates d'augmentation** optimis√©s pour CLIP :

```python
# Exemples de templates utilis√©s dans l'√©valuation
imagenet_templates = [
    'a bad photo of a {}.',
    'a photo of many {}.',
    'a sculpture of a {}.',
    'a photo of the hard to see {}.',
    'a low resolution photo of the {}.',
    'a rendering of a {}.',
    'graffiti of a {}.',
    'a bad photo of the {}.',
    'a cropped photo of the {}.',
    'a tattoo of a {}.',
    # ... 80 templates au total pour robusesse
]

# Classes ImageNet (extrait)
classes = [
    'tench',           # n01440764
    'goldfish',        # n01443537  
    'great white shark', # n01484850
    # ... 1000 classes au total
]
```

### Tests de performance quantitative

#### 1. `imagenet_eval_deletion.ipynb`
** Test de suppression (Deletion Test)**

Ce test mesure la **baisse de performance** quand on supprime progressivement les r√©gions les plus importantes identifi√©es par chaque m√©thode.



#### 2. `imagenet_eval_insertion.ipynb`
**‚ûï Test d'insertion (Insertion Test)**

Ce test mesure l'**am√©lioration de performance** quand on r√©v√®le progressivement les r√©gions importantes sur une image initialement masqu√©e.






## üìä Documentation et rapport

### Documents principaux

#### rapport_projet_bgdia708_grad_clip.pdf
**Rapport complet du projet** (8 pages) incluant :

1. **Introduction et motivation**
   - Contexte des mod√®les vision-langage
   - Probl√©matique de l'explicabilit√©
   - Objectifs du projet

2. **√âtat de l'art**
   - M√©thodes d'explicabilit√© existantes
   - Limites des approches actuelles
   - Positionnement de Grad-ECLIP

3. **M√©thodologie**
   - Description d√©taill√©e de l'algorithme
   - Choix de conception
   - Implementation technique

4. **Exp√©rimentations**
   - Protocole d'√©valuation
   - Datasets utilis√©s
   - M√©triques de performance

5. **R√©sultats et analyse**
   - Comparaisons quantitatives
   - √âtudes qualitatives
   - √âtudes d'ablation

6. **Discussion et perspectives**
   - Limites identifi√©es
   - Am√©liorations possibles
   - Applications futures


#### 2502.18816v1.pdf
**Article scientifique de r√©f√©rence** :
- Theoretical foundations
- Algorithmic details
- Experimental validation

### M√©tadonn√©es du projet

```python
# Configuration du projet
PROJECT_INFO = {
    'name': 'Grad-ECLIP',
    'version': '1.0.0',
    'authors': ['pmbathe-24'],
    'institution': 'INFRES',
    'year': 2024,
    'license': 'MIT',
    'dependencies': {
        'torch': '>=1.12.0',
        'clip': '>=1.0',
        'transformers': '>=4.20.0',
        'opencv-python': '>=4.5.0'
    }
}
```

## üî¨ Recherche et d√©veloppement

### Notebooks de d√©veloppement

#### `adaptation_vit.ipynb`
Exp√©rimentations sur l'adaptation des Vision Transformers :
- Modifications architecturales test√©es
- Impact sur la performance d'explication
- Optimisations computationnelles

#### `finetuning.ipynb`






## üìö R√©f√©rences

### Citations principales

#### Article original
```bibtex
@article{zhao2024gradient,
  title={Gradient-based Visual Explanation for CLIP},
  author={Zhao, Chenyang and Wang, Kun and others},
  journal={arXiv preprint arXiv:2502.18816},
  year={2024}
}
```

#### Notre impl√©mentation
```bibtex
@misc{pmbathe2024gradeclip,
  title={Grad-ECLIP: Implementation and Comparative Study},
  author={pmbathe-24},
  institution={INFRES},
  year={2024},
  url={https://github.com/username/Projet-IA-Fairness}
}
```

### R√©f√©rences connexes

1. **CLIP Original** : Radford et al., "Learning Transferable Visual Representations from Natural Language Supervision"
2. **Vision Transformers** : Dosovitskiy et al., "An Image is Worth 16x16 Words"
3. **Grad-CAM** : Selvaraju et al., "Grad-CAM: Visual Explanations from Deep Networks"
4. **BLIP** : Li et al., "BLIP: Bootstrapping Language-Image Pre-training"
5. **Attention Visualization** : Abnar & Zuidema, "Quantifying Attention Flow"

### Datasets et benchmarks

- **ImageNet** : http://www.image-net.org/
- **MS-COCO** : https://cocodataset.org/
- **Conceptual Captions** : https://ai.google.com/research/ConceptualCaptions/

---


**üéØ Objectif** : Ce README fournit une documentation compl√®te pour comprendre, utiliser et √©tendre le projet Grad-ECLIP. Pour toute question sp√©cifique, consultez les notebooks ou ouvrez une issue GitHub.