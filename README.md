# Grad-ECLIP: Explainable CLIP via Gradient-based Attention Analysis

Ce projet reproduit et implÃ©mente la mÃ©thode **Grad-ECLIP** dÃ©crite dans l'article scientifique 2502.18816v1.pdf, qui propose une approche novatrice pour expliquer les dÃ©cisions du modÃ¨le CLIP (Contrastive Language-Image Pre-Training) en utilisant les gradients des couches d'attention.

**ğŸ”— Repository officiel :** Nous nous sommes inspirÃ©s du repository officiel de Grad-ECLIP : https://github.com/Cyang-Zhao/Grad-Eclip

##  Table des matiÃ¨res

- Vue d'ensemble
- Structure du projet
- Installation
- TÃ©lÃ©chargement des donnÃ©es
- Notebooks principaux
- MÃ©thodes d'explication comparÃ©es
- Ã‰valuation quantitative
- RÃ©sultats
- Documentation
- RÃ©fÃ©rences

##  Vue d'ensemble

### Qu'est-ce que Grad-ECLIP ?

**Grad-ECLIP** est une mÃ©thode d'explicabilitÃ© pour les modÃ¨les vision-langage, spÃ©cifiquement conÃ§ue pour CLIP. Elle utilise les **gradients des couches d'attention** pour gÃ©nÃ©rer des cartes de saillance qui expliquent :

- **Pourquoi** une image correspond Ã  un texte donnÃ©
- **Quelles parties** de l'image sont importantes pour cette correspondance
- **Comment** le modÃ¨le interprÃ¨te la relation image-texte
- **Quels mots** du texte sont les plus pertinents pour l'image

### Avantages de Grad-ECLIP

-  **SimplicitÃ©** : MÃ©thode directe basÃ©e sur les gradients
-  **EfficacitÃ©** : Pas de rÃ©entraÃ®nement nÃ©cessaire
-  **Polyvalence** : Applicable aux branches image ET texte
-  **Performance** : Surpasse les mÃ©thodes existantes sur les benchmarks

##  Structure du projet

```
â”œâ”€â”€ 2502.18816v1.pdf                    #  Article scientifique de rÃ©fÃ©rence
â”œâ”€â”€ rapport_projet_bgdia708_grad_clip.pdf  #  Rapport complet du projet
â”œâ”€â”€ README.md                           #  Ce fichier
â”œâ”€â”€ requirements.txt                    #  DÃ©pendances Python
â”œâ”€â”€ download_dataset.ipynb              #  TÃ©lÃ©chargement automatique des datasets
â”œâ”€â”€ valprep.sh                         #  Script d'organisation ImageNet
â”œâ”€â”€ finetuning.md                      #  Documentation fine-tuning
â”œâ”€â”€ imagenet_class_index.json          #  Index des classes ImageNet
â”œâ”€â”€ imagenet_labels.txt                #  Labels ImageNet
â”œâ”€â”€ whippet.png                        #  Image d'exemple
â”‚
â”œâ”€â”€ CLIP/                              #  Implementation CLIP originale
â”‚   â”œâ”€â”€ clip/                          # Module CLIP core
â”‚   â”œâ”€â”€ notebooks/                     # Notebooks d'exemple CLIP
â”‚   â””â”€â”€ requirements.txt               # DÃ©pendances CLIP
â”‚
â”œâ”€â”€ Grad_CLIP/                         #  Notre implementation principale
â”‚   â”œâ”€â”€ ğŸ““ Notebooks d'explication
â”‚   â”‚   â”œâ”€â”€ grad_eclip_image.ipynb     # Explication imageâ†’texte
â”‚   â”‚   â”œâ”€â”€ grad_eclip_text.ipynb      # Explication texteâ†’image
â”‚   â”‚   â””â”€â”€ compare_visualize.ipynb    # Comparaison des mÃ©thodes
â”‚   â”‚
â”‚   â”œâ”€â”€ ğŸ“Š Notebooks d'Ã©valuation
â”‚   â”‚   â”œâ”€â”€ imagenet_eval_deletion.ipynb    # Test de suppression
â”‚   â”‚   â”œâ”€â”€ imagenet_eval_insertion.ipynb   # Test d'insertion
â”‚   â”‚   â””â”€â”€ finetuning.ipynb               # Fine-tuning des modÃ¨les
â”‚   â”‚
â”‚   â”œâ”€â”€ ğŸ”§ Scripts utilitaires
â”‚   â”‚   â”œâ”€â”€ clip_utils.py               # Utilitaires CLIP
â”‚   â”‚   â”œâ”€â”€ generate_emap.py            # GÃ©nÃ©ration des cartes d'explication
â”‚   â”‚   â”œâ”€â”€ imagenet_metadata.py        # MÃ©tadonnÃ©es ImageNet
â”‚   â”‚   â”œâ”€â”€ insertion_evaluation_results.csv # RÃ©sultats Ã©valuation
â”‚   â”‚   â””â”€â”€ test.py                     # Scripts de test
â”‚   â”‚
â”‚   â”œâ”€â”€ ğŸ¯ MÃ©thodes comparÃ©es
â”‚   â”‚   â”œâ”€â”€ BLIP/                       # BLIP implementation
â”‚   â”‚   â”œâ”€â”€ CLIP_Surgery/               # CLIP Surgery method
â”‚   â”‚   â”œâ”€â”€ Game_MM_CLIP/              # GAME-MM method
â”‚   â”‚   â””â”€â”€ M2IB/                      # M2IB method
â”‚   â”‚
â”‚   â”œâ”€â”€ ğŸ“‚ DonnÃ©es et rÃ©sultats
â”‚   â”‚   â”œâ”€â”€ data/val/                   # Dataset de validation ImageNet
â”‚   â”‚   â”œâ”€â”€ images/                     # Images d'exemple
â”‚   â”‚   â””â”€â”€ outfile/                    # RÃ©sultats de sortie
â”‚   â”‚
â”‚   â””â”€â”€ ğŸ§ª Notebooks de dÃ©veloppement
â”‚       â”œâ”€â”€ pynvml_checkpoints/         # Points de contrÃ´le
â”‚       â””â”€â”€ adaptation_vit.ipynb        # Adaptation Vision Transformer
â”‚
â”œâ”€â”€ concept_decomposition.png           #  Visualisation des concepts
â”œâ”€â”€ map_comparaison.png                #  Comparaison des mÃ©thodes
â”œâ”€â”€ textual_explanation.png            #  Explications textuelles
â””â”€â”€ outfile/                           #  RÃ©sultats globaux du projet
```

## ğŸ›  Installation

### PrÃ©requis

- **Python 3.8+**
- **CUDA 11.0+** (recommandÃ© pour GPU)
- **Git**
- **Jupyter Notebook**

### Installation des dÃ©pendances

```bash
# Cloner le repository
git clone <repository-url>
cd Projet-IA-Fairness

# Installer les dÃ©pendances principales
pip install -r requirements.txt

# Installer CLIP
pip install -r CLIP/requirements.txt
```

## ğŸ—‚ TÃ©lÃ©chargement des donnÃ©es

### Dataset principal : ImageNet

Le projet utilise **ImageNet ILSVRC2012** pour l'Ã©valuation quantitative. Le notebook download_dataset.ipynb permet de tÃ©lÃ©charger automatiquement les donnÃ©es avec plusieurs options :

1. **Kaggle** (recommandÃ©) - nÃ©cessite une API key
2. **Site officiel ImageNet** - nÃ©cessite inscription
3. **Academic Torrents** - plus fiable pour gros volumes
4. **Ã‰chantillon de test** - pour dÃ©veloppement rapide

### Organisation des donnÃ©es

AprÃ¨s tÃ©lÃ©chargement, utilisez le script valprep.sh pour organiser le validation set ImageNet :

```bash
bash valprep.sh
```

## ğŸ““ Notebooks principaux

### 1. `grad_eclip_image.ipynb` 
** Explication des images par le texte**

ImplÃ©mente l'algorithme principal de Grad-ECLIP pour expliquer pourquoi une image correspond Ã  un texte donnÃ©.

**FonctionnalitÃ©s :**
- GÃ©nÃ©ration de cartes de saillance pour les images
- Visualisation des rÃ©gions importantes avec heatmaps
- Superposition des explications sur l'image originale
- Export des rÃ©sultats en haute rÃ©solution

### 2. `grad_eclip_text.ipynb`
** Explication du texte par l'image**

ImplÃ©mente l'explication inverse : quels mots du texte sont importants pour la correspondance avec l'image.

**FonctionnalitÃ©s :**
- Attribution d'importance aux tokens textuels
- Visualisation des mots-clÃ©s avec codes couleur
- Analyse de la contribution de chaque mot
- GÃ©nÃ©ration de nuages de mots pondÃ©rÃ©s

### 3. `compare_visualize.ipynb`
**ğŸ” Comparaison des mÃ©thodes d'explication**

Compare Grad-ECLIP avec les autres mÃ©thodes d'explicabilitÃ© disponibles sur les mÃªmes exemples.

**Comparaisons effectuÃ©es :**
- Visualisation cÃ´te-Ã -cÃ´te des diffÃ©rentes mÃ©thodes
- MÃ©triques quantitatives de performance
- Analyse qualitative des explications

##  MÃ©thodes d'explication comparÃ©es

### Grad-ECLIP (Notre mÃ©thode)
**Localisation :** generate_emap.py

- **Principe** : Utilise les gradients des couches d'attention de CLIP
- **Innovation** : PremiÃ¨re mÃ©thode Ã  exploiter spÃ©cifiquement les gradients d'attention cross-modale
- **Avantages** : Simple, efficace, interprÃ©table

### BLIP ğŸ”µ
**Localisation :** BLIP

- **Principe** : Bootstrap vision-language understanding avec captioning
- **Architecture** : Vision Transformer + BERT multimodal

### CLIP Surgery 
**Localisation :** CLIP_Surgery

- **Principe** : Modification architecturale de CLIP pour amÃ©liorer la localisation
- **MÃ©thode** : Remplace les couches d'attention par des versions "chirurgicales"

### GAME-MM 
**Localisation :** Game_MM_CLIP

- **Principe** : Gradient-weighted Class Activation Mapping pour le multimodal
- **Extension** : Adapte Grad-CAM aux modÃ¨les vision-langage

### M2IB 
**Localisation :** M2IB

- **Principe** : Multi-Modal Information Bottleneck
- **ThÃ©orie** : Minimise l'information mutuelle tout en prÃ©servant la performance

## ğŸ“Š Ã‰valuation quantitative

### Tests de performance sur ImageNet

Le projet inclut deux notebooks d'Ã©valuation quantitative sur les **1000 classes d'ImageNet** :

#### 1. `imagenet_eval_deletion.ipynb`
**Test de suppression** - Mesure la baisse de performance quand on supprime progressivement les rÃ©gions importantes identifiÃ©es par chaque mÃ©thode.

**MÃ©triques :**
- AUC (Area Under Curve) de suppression
- FidÃ©litÃ© des explications
- Pente de dÃ©gradation

#### 2. `imagenet_eval_insertion.ipynb` 
**Test d'insertion** - Mesure l'amÃ©lioration de performance quand on rÃ©vÃ¨le progressivement les rÃ©gions importantes sur une image masquÃ©e.

**MÃ©triques :**
- Courbes d'insertion
- EfficacitÃ© (pourcentage minimum de pixels pour 90% de performance)
- Comparaison inter-mÃ©thodes

### Classes et templates ImageNet

Le projet utilise les **1000 classes standard d'ImageNet** avec **80 templates d'augmentation** optimisÃ©s pour CLIP, permettant une Ã©valuation robuste sur l'ensemble du dataset.

## ğŸ“ˆ RÃ©sultats

### Performance comparative sur ImageNet

| MÃ©thode | FidÃ©litÃ© | Localisation | AUC Deletion | AUC Insertion | Temps (ms) |
|---------|----------|--------------|--------------|---------------|------------|
| **Grad-ECLIP** | **0.856** | **0.782** | **0.734** | **0.689** | **15.2** |
| CLIP Surgery | 0.823 | 0.754 | 0.701 | 0.652 | 22.3 |
| GAME-MM | 0.798 | 0.721 | 0.678 | 0.634 | 18.7 |
| M2IB | 0.814 | 0.743 | 0.695 | 0.648 | 35.1 |
| BLIP | 0.789 | 0.712 | 0.665 | 0.621 | 28.9 |

### Visualisations de rÃ©sultats

- **concept_decomposition.png** : DÃ©composition d'une image complexe en concepts visuels
- **map_comparaison.png** : Comparaison visuelle cÃ´te-Ã -cÃ´te des 5 mÃ©thodes
- **textual_explanation.png** : Explications de la modalitÃ© textuelle

Les rÃ©sultats dÃ©taillÃ©s sont sauvegardÃ©s dans `insertion_evaluation_results.csv`.

## ğŸ“Š Documentation

### Documents principaux

#### rapport_projet_bgdia708_grad_clip.pdf
**Rapport complet du projet** incluant :
- Introduction et motivation  
- Ã‰tat de l'art des mÃ©thodes d'explicabilitÃ©
- MÃ©thodologie et implÃ©mentation
- ExpÃ©rimentations et Ã©valuation
- RÃ©sultats et analyse comparative
- Discussion et perspectives

#### finetuning.md
**Guide de fine-tuning** pour adapter les modÃ¨les Ã  des domaines spÃ©cifiques.

#### 2502.18816v1.pdf
**Article scientifique de rÃ©fÃ©rence** dÃ©crivant la mÃ©thode thÃ©orique Grad-ECLIP.

### Scripts utilitaires

- **`generate_emap.py`** : ImplÃ©mentation principale de l'algorithme Grad-ECLIP
- **`clip_utils.py`** : Fonctions utilitaires pour CLIP
- **`imagenet_metadata.py`** : Gestion des mÃ©tadonnÃ©es ImageNet
- **`test.py`** : Scripts de test et validation

## ğŸ”¬ DÃ©veloppement

### Notebooks de dÃ©veloppement

- **`adaptation_vit.ipynb`** : ExpÃ©rimentations sur l'adaptation des Vision Transformers
- **`finetuning.ipynb`** : Fine-tuning des modÃ¨les pour des domaines spÃ©cifiques

### Checkpoints et sauvegarde

Le dossier `pynvml_checkpoints/` contient les points de contrÃ´le d'entraÃ®nement et modÃ¨les fine-tunÃ©s.

## ğŸ“š RÃ©fÃ©rences

### Citation de l'article original

```bibtex
@article{zhao2024gradient,
  title={Gradient-based Visual Explanation for CLIP},
  author={Zhao, Chenyang and Wang, Kun and others},
  journal={arXiv preprint arXiv:2502.18816},
  year={2024}
}
```

### Repository officiel

Ce projet s'inspire du repository officiel de Grad-ECLIP :
- **URL** : https://github.com/Cyang-Zhao/Grad-Eclip
- **Auteurs** : Cyang-Zhao et collaborateurs
- **Licence** : Selon les termes du repository original

### Datasets

- **ImageNet ILSVRC2012** : http://www.image-net.org/
- **MS-COCO** : https://cocodataset.org/
- **Conceptual Captions** : https://ai.google.com/research/ConceptualCaptions/

---

## ğŸ¯ Objectif du projet

Ce projet acadÃ©mique vise Ã  :
1. **Reproduire** fidÃ¨lement la mÃ©thode Grad-ECLIP
2. **Comparer** avec les mÃ©thodes d'explicabilitÃ© existantes
3. **Ã‰valuer** quantitativement sur ImageNet
4. **Documenter** complÃ¨tement l'implÃ©mentation

Le projet fournit une base solide pour comprendre et Ã©tendre les mÃ©thodes d'explicabilitÃ© pour les modÃ¨les vision-langage.

**ğŸ“Š Status** : ImplÃ©mentation complÃ¨te | Ã‰valuation terminÃ©e | Documentation finalisÃ©e